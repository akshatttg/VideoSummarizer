{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd \n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-11-02T10:35:50.337440Z","iopub.execute_input":"2023-11-02T10:35:50.338383Z","iopub.status.idle":"2023-11-02T10:35:50.685717Z","shell.execute_reply.started":"2023-11-02T10:35:50.338350Z","shell.execute_reply":"2023-11-02T10:35:50.684694Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"/kaggle/input/videonptel/videoplayback.mp4\n","output_type":"stream"}]},{"cell_type":"code","source":"pip install moviepy","metadata":{"execution":{"iopub.status.busy":"2023-11-02T10:35:57.341875Z","iopub.execute_input":"2023-11-02T10:35:57.342602Z","iopub.status.idle":"2023-11-02T10:36:24.083644Z","shell.execute_reply.started":"2023-11-02T10:35:57.342567Z","shell.execute_reply":"2023-11-02T10:36:24.082447Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Collecting moviepy\n  Downloading moviepy-1.0.3.tar.gz (388 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m388.3/388.3 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hCollecting decorator<5.0,>=4.0.2 (from moviepy)\n  Downloading decorator-4.4.2-py2.py3-none-any.whl (9.2 kB)\nRequirement already satisfied: tqdm<5.0,>=4.11.2 in /opt/conda/lib/python3.10/site-packages (from moviepy) (4.66.1)\nRequirement already satisfied: requests<3.0,>=2.8.1 in /opt/conda/lib/python3.10/site-packages (from moviepy) (2.31.0)\nCollecting proglog<=1.0.0 (from moviepy)\n  Downloading proglog-0.1.10-py3-none-any.whl (6.1 kB)\nRequirement already satisfied: numpy>=1.17.3 in /opt/conda/lib/python3.10/site-packages (from moviepy) (1.23.5)\nRequirement already satisfied: imageio<3.0,>=2.5 in /opt/conda/lib/python3.10/site-packages (from moviepy) (2.31.1)\nCollecting imageio_ffmpeg>=0.2.0 (from moviepy)\n  Downloading imageio_ffmpeg-0.4.9-py3-none-manylinux2010_x86_64.whl (26.9 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.9/26.9 MB\u001b[0m \u001b[31m45.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: pillow>=8.3.2 in /opt/conda/lib/python3.10/site-packages (from imageio<3.0,>=2.5->moviepy) (9.5.0)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from imageio_ffmpeg>=0.2.0->moviepy) (68.0.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3.0,>=2.8.1->moviepy) (3.1.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3.0,>=2.8.1->moviepy) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3.0,>=2.8.1->moviepy) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3.0,>=2.8.1->moviepy) (2023.7.22)\nBuilding wheels for collected packages: moviepy\n  Building wheel for moviepy (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for moviepy: filename=moviepy-1.0.3-py3-none-any.whl size=110730 sha256=420a63d32b54012b08616eff5028247cad5e0b28d93508d137c7a73caf9e7599\n  Stored in directory: /root/.cache/pip/wheels/96/32/2d/e10123bd88fbfc02fed53cc18c80a171d3c87479ed845fa7c1\nSuccessfully built moviepy\nInstalling collected packages: proglog, imageio_ffmpeg, decorator, moviepy\n  Attempting uninstall: decorator\n    Found existing installation: decorator 5.1.1\n    Uninstalling decorator-5.1.1:\n      Successfully uninstalled decorator-5.1.1\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ngcsfs 2023.6.0 requires fsspec==2023.6.0, but you have fsspec 2023.9.0 which is incompatible.\njupyterlab-lsp 4.2.0 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed decorator-4.4.2 imageio_ffmpeg-0.4.9 moviepy-1.0.3 proglog-0.1.10\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"code","source":"import moviepy.editor\nvid = \"/kaggle/input/videonptel/videoplayback.mp4\"\nvideo = moviepy.editor.VideoFileClip(vid)","metadata":{"execution":{"iopub.status.busy":"2023-11-02T10:36:24.086017Z","iopub.execute_input":"2023-11-02T10:36:24.086468Z","iopub.status.idle":"2023-11-02T10:36:24.930410Z","shell.execute_reply.started":"2023-11-02T10:36:24.086430Z","shell.execute_reply":"2023-11-02T10:36:24.929578Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"! pip install -U git+https://github.com/linto-ai/whisper-timestamped","metadata":{"execution":{"iopub.status.busy":"2023-11-02T10:36:24.934422Z","iopub.execute_input":"2023-11-02T10:36:24.935490Z","iopub.status.idle":"2023-11-02T10:37:24.404207Z","shell.execute_reply.started":"2023-11-02T10:36:24.935435Z","shell.execute_reply":"2023-11-02T10:37:24.402935Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Collecting git+https://github.com/linto-ai/whisper-timestamped\n  Cloning https://github.com/linto-ai/whisper-timestamped to /tmp/pip-req-build-02_mu5h8\n  Running command git clone --filter=blob:none --quiet https://github.com/linto-ai/whisper-timestamped /tmp/pip-req-build-02_mu5h8\n  Resolved https://github.com/linto-ai/whisper-timestamped to commit 127e8b738756420487210490d09938593244b3dd\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: Cython in /opt/conda/lib/python3.10/site-packages (from whisper-timestamped==1.12.20) (0.29.35)\nCollecting dtw-python (from whisper-timestamped==1.12.20)\n  Downloading dtw_python-1.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (645 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m645.5/645.5 kB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting openai-whisper (from whisper-timestamped==1.12.20)\n  Downloading openai-whisper-20230918.tar.gz (794 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m794.3/794.3 kB\u001b[0m \u001b[31m48.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: numpy>=1.19 in /opt/conda/lib/python3.10/site-packages (from dtw-python->whisper-timestamped==1.12.20) (1.23.5)\nRequirement already satisfied: scipy>=1.1 in /opt/conda/lib/python3.10/site-packages (from dtw-python->whisper-timestamped==1.12.20) (1.11.2)\nCollecting triton==2.0.0 (from openai-whisper->whisper-timestamped==1.12.20)\n  Downloading triton-2.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (63.3 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.3/63.3 MB\u001b[0m \u001b[31m18.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: numba in /opt/conda/lib/python3.10/site-packages (from openai-whisper->whisper-timestamped==1.12.20) (0.57.1)\nRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from openai-whisper->whisper-timestamped==1.12.20) (2.0.0+cpu)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from openai-whisper->whisper-timestamped==1.12.20) (4.66.1)\nRequirement already satisfied: more-itertools in /opt/conda/lib/python3.10/site-packages (from openai-whisper->whisper-timestamped==1.12.20) (9.1.0)\nCollecting tiktoken==0.3.3 (from openai-whisper->whisper-timestamped==1.12.20)\n  Downloading tiktoken-0.3.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m68.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: regex>=2022.1.18 in /opt/conda/lib/python3.10/site-packages (from tiktoken==0.3.3->openai-whisper->whisper-timestamped==1.12.20) (2023.6.3)\nRequirement already satisfied: requests>=2.26.0 in /opt/conda/lib/python3.10/site-packages (from tiktoken==0.3.3->openai-whisper->whisper-timestamped==1.12.20) (2.31.0)\nCollecting cmake (from triton==2.0.0->openai-whisper->whisper-timestamped==1.12.20)\n  Downloading cmake-3.27.7-py2.py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (26.0 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.0/26.0 MB\u001b[0m \u001b[31m49.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from triton==2.0.0->openai-whisper->whisper-timestamped==1.12.20) (3.12.2)\nCollecting lit (from triton==2.0.0->openai-whisper->whisper-timestamped==1.12.20)\n  Downloading lit-17.0.4.tar.gz (153 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m153.1/153.1 kB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n\u001b[?25h  Installing backend dependencies ... \u001b[?25ldone\n\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: llvmlite<0.41,>=0.40.0dev0 in /opt/conda/lib/python3.10/site-packages (from numba->openai-whisper->whisper-timestamped==1.12.20) (0.40.1)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch->openai-whisper->whisper-timestamped==1.12.20) (4.6.3)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch->openai-whisper->whisper-timestamped==1.12.20) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch->openai-whisper->whisper-timestamped==1.12.20) (3.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->openai-whisper->whisper-timestamped==1.12.20) (3.1.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken==0.3.3->openai-whisper->whisper-timestamped==1.12.20) (3.1.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken==0.3.3->openai-whisper->whisper-timestamped==1.12.20) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken==0.3.3->openai-whisper->whisper-timestamped==1.12.20) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken==0.3.3->openai-whisper->whisper-timestamped==1.12.20) (2023.7.22)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch->openai-whisper->whisper-timestamped==1.12.20) (2.1.3)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch->openai-whisper->whisper-timestamped==1.12.20) (1.3.0)\nBuilding wheels for collected packages: whisper-timestamped, openai-whisper, lit\n  Building wheel for whisper-timestamped (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for whisper-timestamped: filename=whisper_timestamped-1.12.20-py3-none-any.whl size=44514 sha256=ab2c6ac81de350e70f8ab3cde5cc0f375ccd1bf4dbb3df8df01076f8109c81bd\n  Stored in directory: /tmp/pip-ephem-wheel-cache-vgtatl5s/wheels/9d/fb/03/ae0b1c8b71edda71e33da77333c78117d879361bdd35de48e4\n  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for openai-whisper: filename=openai_whisper-20230918-py3-none-any.whl size=798400 sha256=f6bb60d0bb40c055e5b8aaa1f7bcd699e96f80a337ca22acfdbc9436e83f485a\n  Stored in directory: /root/.cache/pip/wheels/5d/37/b1/9aea93201fe91e3561719120da92cc23e77b7ef6f3d0d9491a\n  Building wheel for lit (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for lit: filename=lit-17.0.4-py3-none-any.whl size=93257 sha256=0f7947d61e6d893f99738b8b4c02a4fa3571ebe2ac08b1f1e26660fa05960b6c\n  Stored in directory: /root/.cache/pip/wheels/be/ae/00/696c57d438bfc7c0e89c4c379083ea08b1c2e54d85a5f7cd7c\nSuccessfully built whisper-timestamped openai-whisper lit\nInstalling collected packages: lit, cmake, tiktoken, dtw-python, triton, openai-whisper, whisper-timestamped\nSuccessfully installed cmake-3.27.7 dtw-python-1.3.0 lit-17.0.4 openai-whisper-20230918 tiktoken-0.3.3 triton-2.0.0 whisper-timestamped-1.12.20\n","output_type":"stream"}]},{"cell_type":"code","source":"\nimport whisper_timestamped as whisper\n\naudio = whisper.load_audio('/kaggle/input/videonptel/videoplayback.mp4')\nmodel = whisper.load_model(\"base\")\n\nresult = whisper.transcribe(model, audio, language=\"en\")\n\nimport json\n# print(json.dumps(result, indent = 2, ensure_ascii = False))","metadata":{"execution":{"iopub.status.busy":"2023-11-02T10:37:24.406882Z","iopub.execute_input":"2023-11-02T10:37:24.407280Z","iopub.status.idle":"2023-11-02T10:44:51.352534Z","shell.execute_reply.started":"2023-11-02T10:37:24.407250Z","shell.execute_reply":"2023-11-02T10:44:51.351517Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"Importing the dtw module. When using in academic works please cite:\n  T. Giorgino. Computing and Visualizing Dynamic Time Warping Alignments in R: The dtw Package.\n  J. Stat. Soft., doi:10.18637/jss.v031.i07.\n\n","output_type":"stream"},{"name":"stderr","text":"100%|███████████████████████████████████████| 139M/139M [00:01<00:00, 91.1MiB/s]\n100%|██████████| 312433/312433 [07:08<00:00, 729.14frames/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"\nmaintext = json.dumps(result['text'] , indent = 2, ensure_ascii = False)\n\nprint(maintext)","metadata":{"execution":{"iopub.status.busy":"2023-11-02T10:44:51.353949Z","iopub.execute_input":"2023-11-02T10:44:51.354614Z","iopub.status.idle":"2023-11-02T10:44:51.362453Z","shell.execute_reply.started":"2023-11-02T10:44:51.354573Z","shell.execute_reply":"2023-11-02T10:44:51.361261Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"\" Welcome to this new course on Principles of Compiler Design. So, in this lecture I will give you an overview of a compiler, but before that we will also see how exactly the course is organized and then the motivation for studying compiler design and of course, then go on to the details of a compiler with block diagrams. So, the course is actually a first level course. In other words, this takes a detail look at the internals of a compiler and I do not assume any background for this particular course, but it is a very intensive course. So, the pace of the course is going to be you know not very slow, but at the same time it is not going to be Ray C either, but the students who are actually going to take this course seriously are requested to do the programming assignments. They are also supposed to solve theoretical problems, which I am going to suggest. Otherwise, this course will not be understood you know properly. The reason is a compiler is an excellent example of the theory being translated into practice and this is a wonderful example of that. So, let us see the motivation for studying a compiler. So, compilers are really everywhere. So, if you look at the applications of modern compiler technology pick up the browser, open it and then immediately you know there would be HTML files which are displayed on the homepage and that you are going to visit and so on. So, the HTML parsers are based on compiler technology and then behind the scene there is JavaScript, there is flash etcetera running inside the browser and the interpreters for this JavaScript script and flash etcetera are also based on the modern compiler technology. Then of course, for the compiler itself we require machine code generation and for high level languages whenever we need code generation we you know we need to use compiler technology anyway. But then apart from that it has uses in software engineering as well. For example, software testing and then program optimization then in the security domain malicious code detection design of new computer architectures. So, why are these important? For example, if you look at the development of a new processor nobody builds a processor you know right away even if the design is 100 percent accurate and all that the performance etcetera will all be known only after the hardware is built. Therefore, there is a simulator which is built for a new CPU and then people also build compiler for that particular CPU. So, once the compiler is built you can compile write programs in C or C++ or any other language compile those programs and then run them on the simulator see what kind of performance it has is giving if necessary make changes in the hardware. So, that is called the compiler in the loop hardware development and it is very useful perhaps very widely used by chip designers in various companies. Then again in the area of hardware synthesis nobody really writes you know the low level assembly type of code for generating VLSI designs and so on and so forth that is called RTL register transfer logic. People really write it in very high description you know high level description languages called VHDL or VDL and so on and then the compilers really generate RTL from VHDL again compiler technology is involved here and then the novel application of compiler technology is compiled simulation. Suppose you write a program in VHDL how do you really find out the performance of the chip or whatever is designed using that VHDL. So, typically a compiler is used to generate a simulator and the simulator is actually a computer program which is generated for that particular program which is being simulated. So, this is called simulation of the design and it is an example of compiled simulation. There is no interpretation of the design here and hence such simulations are much faster than interpretations. So, about the complexity of compiler technology it is also necessary to say few words about this aspect. If you look at the compiler it is possibly the most complex system software and writing it is a substantial exercise in software engineering. So, in fact in our institutes whenever somebody teaches courses on compiler design the associated assignments are really small compilers themselves and writing this is a fairly large software engineering exercise. The complexity of a compiler really arises from the fact that it is required to map a programmers requirements which are written in high level languages to architectural details. So, we are really talking about a C program and then it is translated into machine level program. So, in between you know the compiler has to actually travel a long distance it is not as if it is a very simple operation. So, there is a huge amount of complexity here. So, we are going to discuss this particular complexity and the complex operation in its details in our course. A compiler uses you know algorithms and techniques from a very large number of areas in computer science. We are going to see some examples very soon. So, it is not in that compiler technology is a subject on its own. It has to borrow a huge number of techniques and algorithms from other areas in computer science. And compiler translates I already mentioned this intricate theory into practice. So, you take a for example, a context free grammar specification which is very formal, very precise and absolutely essential for writing a you know describing a language. It can be translated into a parser with minimal effort there are tools such as Yoc which do this. So, this enable in this enables tool building. So, tools take very abstract specifications and generate programs from these specifications. So, now let us look at the type of algorithms which are used inside a compiler and see and let me show you how we require many types of algorithms here. So, we require results from mathematical logic lattice theory linear algebra probability etcetera. So, where are these used? For example, mathematical logic is used to you know in developing type checking theory. Then lattice theory is used in developing static analysis. Design analysis is heavily based on linear algebra and group parallelization is based on loop dependance analysis. So, cache analysis uses both static analysis and probability theory. So, in other words a very deep mathematical background is required to develop new compiler algorithms. In our course, we are going to study the existing compiler algorithms, but we will also look at some of the you know the basis which actually make up this particular topic. Then there are practical applications of many algorithms. For example, greedy algorithms are used in register location. So, heuristic search is used in list scheduling which is a part of a code generator. Graph algorithms are used in that code elimination register location etcetera etcetera. Dynamic programming is used in instruction selection that is how to generate machine code. Optimization techniques are used in instruction scheduling. Finite automata play a part in lexical analysis, post-event automata are very helpful for parsing, fixed point algorithms are used for data flow analysis, very complex data structures such as symbol tables, parse trees, data dependence graphs are going to be built. So, we use trees, balance to trees, graphs etcetera for such applications. Computer architecture itself uses machine co you know the is used in the knowledge of computer architecture is used in machine code generation. And then what are the other uses of some parts of compiler technology some aspects of compiler technology. For example, scanning and parsing techniques are of course, used in compilers, but they are also useful for a similar implementation they are useful for online text searching. For example, graph and dog which are available in UNIX are based on you know the scanning techniques word processing website filtering command language interpreters that is for UNIX for example, shell you know. So, is a command language comes scripting language. So, interpreters for such languages are useful scripting language interpretation again pearl, python, annex shell, XML parsing, documentary construction, database interpreters the list is very big. So, I have mentioned only a few of them which are very important. What about program analysis? So, one part of a compiler is scanning and you know performs scanning and parsing and another part of a compiler performs program analysis. So, program analysis techniques are useful in converting sequential programs to parallel programs. And very important it can be used to determine if programs are data raise, free in other words are there two parts of the program two threads actually accessing the same locations etcetera etcetera can all be decided using program analysis. Profiling programs to determine busy regions of the code well if this is done then we can possibly make that particular region of the code much more efficient. Program slicing techniques are used in debugging. So, a slice of a program is one small part of a program. So, data flow analysis approach to software testing is again based on program analysis. For example, uncovering errors along all parts dereferencing well pointers, buffer overflows, memory leaks these are all common errors which actually occur in programs. And to a some extent taking detecting such problems using software testing requires the data flow analysis approach. Then worst case execution time estimation and energy analysis. If you look at a program it is very difficult to say what is the worst case time that it requires because time of execution for a particular program is based on its input it depends on the input. So, finding out the worst case input is a very hard problem and worst case execution time estimation is also equally hard and uses it uses program analysis techniques. Energy analysis implies the detection you know rather computation of the amount of energy that a program takes. This is as difficult or more difficult than time time analysis. So, program analysis techniques are used in energy analysis as well. So, that is about you know the motivation to study this subject called compiler design. So, let us begin with this block diagram which talks about a general language processing system. So, to begin with we have for example, here a pre processor which takes a source program as input and then outputs modified source program. So, even in the C compiler we have such pre processors. So, for example, you write define hash defined macros or hash include you know direct use inside a program. Then such macros are expanded by the pre processor and the pre processor expands and provides the source program as input to the compiler. A compiler itself takes a clean you know expanded source program in a high level language such as C or C plus plus or any other language and outputs this assembly program for the particular machine. So, we will see the details of a compiler in short while. The target assembly program is input to the assembler which takes the mnemonics in the assembly language and translate them to actual binary machine code. Finally, the assembler output is called as the relocatable machine code which is combined with library files and relocatable you know object files from other sources by the linker and loader to provide the target machine code which can run on a particular machine. So, now we 0 in on the compiler itself. So, compiler consists of many blocks they are all listed here. Lexical analyzer is the first one as output of that goes to a syntax analyzer the output of which is again fed to a semantic analyzer following that is the intermediate code generator and then comes the machine independent code optimizer the machine code generator and finally, the machine dependent code optimizer. And all these parts of a compiler use a data structure called as a symbol table which is actually somewhere in the middle. So, we now have for example, let us look at a Lexical analyzer and see what it does. A Lexical analyzer takes as input a character stream. So, we are now going to take each of these blocks and study them in detail. So, let us begin with this Lexical analyzer. But before we begin with Lexical analyzer I must hasten to add that there is a difference between what are known as compilers and interpreters. So, if we look at the previous slide the compiler consists of this entire you know seven blocks along with the symbol table. Whereas, an interpreter stops after the intermediate code generation stage and the output of the intermediate code generator is fed to an interpreter. So, let us see the difference between these two. Compilers generate machine code whereas, interpreters generate you know interpret intermediate code. Of course, interpreters are only 50 percent of a compiler. So, they are easier to write and can provide better error messages because we still have access to the symbol table and so on. But the catch is interpreters are 5 times lower or more actually more than 5 times lower than machine code generated by compilers. So, running machine code is much faster, but interpreters are easier to build. So, people tend to write you know interpreters for certain types of languages whereas, they try to write compilers for languages which are used to write professional programs. Interpreters also require much more memory. And then you know even the compilation, lexical analysis parsing etcetera is all the time required by the interpreter itself is added to the time required by the interpreter. So, they require much more memory much more time than machine code generated by compilers and there are very famous examples per Python, Unixel, Java, Basic, List etcetera are all you know interpreter based languages. Now, let us get back to the block diagram and let us look at the lexical analyzer in some detail. A lexical analyzer takes source program. For example, here there is a line far and high equal to centigrade star 1.8 plus 32. This is an assignment statement in any particular language you know there is no need to talk about a particular C or C plus plus such assignments are available in every language. So, now a the lexical analyzer takes as input such sentences from a source program and then it generates what is known as a token stream. So, in this particular case the two names far and high and centigrade are all are both called identifiers. So, far and high is coded as identifier 1 and centigrade is coded as identifier 2. The equal to sign which corresponds to assignment is actually made an assign co is made into a token of kind of sign. Similarly, multiply operator is a melt up and then plus is made into an add up. The constant 1.8 is a floating point constant I constant you know 32 corresponds to the number 32. So, in other words we now have a stream of these tokens. The first part of the token ID assign ID melt up, F constant add up icons these are typically integers there numbers. Whereas, the second part whenever it is present is actually gives you hints about what type of you know the token it is for example, if it is ID then that 1 and 2 may point to a table with indices 1 and 2 containing the string corresponding to the identifier. The icons F constant you know the second part will tell you the value of that particular number and so on and so forth. This is the input to syntax and lizer. So, now let us look at the reasons why lexical analysis is required very briefly. So, so the lexical lizers can be generated automatically from regular expression specifications. So, for example, lex and flex are two tools available in unix and if we feed a regular expression specification we are going to study these specifications later in the course outcomes a program which works as a lexical lizer. The lexical lizers are actually is a deterministic finite state automaton each one of them is a finite state machine and we will learn what these are in the coming lectures. But now, let us answer the question why is lexical analysis separate from parsing. It is not a theoretical limitation in other words the next phase of a compiler called parser can actually incorporate the lexical analysis also there is not much difficulty as far as theory is concerned. But practically if you look at the design a compiler is an extremely large piece of software millions of lines of code and simplifying the design making it modular is the only way its complexity can be controlled. So, simplification of the design by making lexical lizer a separate module is a reason because of software engineering purposes. The second reason input output issues are very limited you know are very serious and it is not a good idea to distribute such input output you know issues all over a compiler they are best handled in one module and in this case in a compiler lexical lizer handles all the input output issues. So, for example, it reads programs you know the from the source file and then any errors etcetera are all actually listed by the lexical lizer after collecting them from various parts then and so on. So, lexical lizers based on finite automata are more efficient to implement than push down automata which are used for parsing. This is a very deep reason. So, as I already mentioned lexical lizer is nothing but a deterministic finite state automata and a parser as we will see later corresponds to a push down automata. A push down automata uses a stack for its operation. So, if we actually try doing lexical lizers with a push down automata then we will end up actually pushing a lot of symbols under the stack then popping them off the stack and so on which are very inefficient operations. And therefore, using incorporating lexical lizer into a parser makes it very inefficient compared to the making a finite automata based lexical lizer. So, these are the reasons why lexical lizers are separate and of course, if you look at the previous slide as I said each one of these tokens the first part of the token is an integer. So, storing these integers is much more efficient than storing the characters corresponding to the source program. So, it is actually a very you know succinct and compact way of giving the program to the syntax lizer. So, then once we understand lexical analysis we must see how it actually helps syntax analysis the output of the lexical lizer is fed to a syntax lizer. So, we have these tokens coming into a syntax lizer the syntax lizer looks at the tokens and finds out whether the syntax is according to a grammar specification. In other words the assignment statement must have a variable on the left side an expression on the right side and so on. So, does this have you know the assignment operator is it correct or is it there is a mistake and whether the plus star etcetera are all properly inserted into the expression. These are all the syntax checks that syntax lizer can perform based on grammar specification which is given to it. So, input of a syntax lizer is a tree this small tree is called as a syntax tree or abstract syntax tree. So, for example, here it shows the structure of the assignment statement above this was Fahrenheit equal to you know as as let us look at it. Fahrenheit equal to centigrade into 1.8 plus 32. So, here this id corresponds to Fahrenheit this id corresponds to the next identifier and then we have the assignment symbol plus star 1.8 and 32. So, everything is working out well. So, this structure is shown in the form of syntax tree which is the input to the next phase of compiler called the semantic analyzer. So, syntax analyzers can be generated automatically from context tree grammar. So, we will learn about these specifications a little later, but right now it suffices to say that the you know there are tools to do this. For example, the yawk and antler are two such tools. So, they handle what are known as you know LALR1 grammars that is yawk and bison and antler handles what are known as LL1 grammars. They generate C programs or C plus plus programs which correspond to these parsers you know and they can be used by the compiler. So, as I already said parsers are based on pushdown automata. So, they are actually what are known as deterministic pushdown automata and there is a reason why we need the next phase of analysis called semantic analysis. The reason is parsers cannot handle context sensitive features of programming languages. Let me give you a few examples. So, if you are looking at the syntax alone that is whether the assignment statement has an identifier on the variable or identifier on the left hand side a properly formed expression on the right hand side this forms a syntax, but if you say can I check whether an integer variable is being assigned a floating point expression that is type matching on both sides of assignment this cannot be handled by a parser. So, there are theoretical limitations here context grammar cannot express such features of programming languages. Another feature which is here is variables are declared before use. So, we all know that we declare variables in a you know float b etcetera etcetera and then at the time of using a and b that is suppose a is used in an assignment statement or an expression. The compiler makes sure that a was declared before and it also makes sure that the type corresponding to the usage of a is the same as the type corresponding to its declaration. So, this feature variables declared and then checked after use or even declared before use cannot be captured using context regrammers. They require higher form of grammars called as context sensitive grammars and this is the reason why we need another phase of analysis called semantic analysis. Another very important feature of programming languages which cannot be captured in the context regrammer and hence cannot be caught as mistakes of this kind cannot be caught by a parser. They is here you know parameter types and number match in declaration and use. So, we declare large number of parameters in program functions which we write and each one of these parameters has a type attached to it. So, when we actually call that function or procedure we have to make sure that the actual parameters that we supply are of the same type and the number of parameters we supply are exactly the same as the one in the declaration. So, parameter type and number match in declaration use this property cannot be caught by the parser if the misuse of this property cannot be mistakes if this type cannot be caught by a parser and therefore, semantic analysis is supposed to take care of it. So, the next phase is the semantic analysis phase the input to the semantic analysis phase is a syntax tree. So, we already know that syntax tree is produced by a syntax analyzer it goes into a semantic analyzer and the output is also a syntax tree, but it is actually modified syntax tree. In other words there are changes made to this particular syntax tree. So, that the types of operands are all taken care of for example, this expression id star 1.8 corresponds to a floating point type you know both the id 2 and 1.8 are floating point types, but then we are adding an integer called 32. So, if there is some violation the you cannot really add floating point numbers and integers directly because the representation of these numbers is different inside a compiler. So, what does the compiler do inside a machine? So, the representation is different inside a machine. So, what does the compiler do? It converts the number 32 into a floating point number and then proceeds to generate a machine code for this particular statement. So, and this is recorded faithfully in the syntax tree which is called as the annotated syntax tree. So, that the code generator need not worry too much it just goes ahead with code generation looking at what is available in the annotated syntax tree. So, semantic consistency that cannot be handled at the parsing stage is handled here. So, I already gave you examples of this. So, I am the same thing is repeated here type checking of various programming language constructs is one of the most important task. As semantic analyzer also stores information in the symbol table or the syntax tree itself. So, each node of the syntax tree could store information corresponding to that particular node. What is the type of information that is stored? What are the types of variables? Is it in is it flowed? Is it a struct? Is it an array? etcetera. What are the types of function parameters? What are the dimensions of an array etcetera? So, these are the information that are stored in a symbol table by the semantic analyzer. This information is used not only for caching errors semantic validation as we know it, but it is also used for subsequent phases of the compilation process itself. For example, the code optimizer will also require information about the types of operands in order to perform certain types of optimization. And then the machine code generator needs to know the types of variables in order to generate appropriate types of instructions. So, both these phases require access to the symbol table. So, this is the semantic analysis phase builds the symbol table and that is the database which is used by the you know the phases later in compilation. Static semantics of programming languages can be specified using what are known as attribute grammars. So, we are going to study attribute grammars also in our course a little later of course. And attribute grammars actually are an extension of context free grammars. They are useful for specifying the semantics, what are known as static semantics of programming languages. And it is possible to generate the semantic analyzers semi-automatically from such specifications of attribute grammars. The next phase of compilation is the intermediate code generation phase. So, the annotated syntax tree which is output from a semantic analyzer is the input to an intermediate code generator. And the output of the intermediate code generator is to a machine independent code optimizer. So, let us see what this intermediate code generator has done on our example. So, here is a small tree corresponding to an assignment statement. So, it is very obvious that we need to do this multiplication first then the into float and then the plus and finally, the assignment. So, and that is the order in which the intermediate code has been generated. So, I will tell you why intermediate code after a few minutes, but let us understand this code to see what the intermediate code generator has done. It has generated T 1 equal to 2 into 1.8 corresponding to this expression. It has generated T 2 equal to into float 32 corresponding to this expression. T 3 equal to T 2 corresponding to this small tree and finally, I d 1 equal to T 3 corresponding to the assignment operator. So, an intermediate code program has the same semantics as the original source level program, but it is at a much lower level compared to the source level program, but I must you know mention that it is not a machine language. So, let us see why we require such intermediate code and what exactly we do with it. So, when generating machine code from directly from source code is definitely possible. There is no theoretical or practical limitation. There are two problems associated with this approach. The problem is you need to write too many compilers. Suppose you want to write compilers for m languages and let us say you have n target machines for which you require compilers. So, if we directly write you know generate machine code without generating any other form of intermediate code, we need to write m into n number of compilers. Now, inside a compiler the code optimizer is perhaps one of the largest and the most difficult to write component and it so happens that if we write you know compilers which generate machine code directly, we will not be able to reuse any part of this optimizer. To give you the norm to some in cling of what is involved about 50 percent of the compiler source code is for you know the front end that is the lexical analyzer, the parser and semantic analyzer and let us assume that there is an intermediate code generator. So, all these four components together form about 50 percent of the source code of a compiler. The other 50 percent is for the code optimizer and the machine code generator. So, out of these about 30, 35 percent is meant for just this code optimizer and the other 20 percent 25 percent is for machine code generation and machine code optimization. So, a very large part of compiler 30 to 40 percent if it has to be written again and again you know for every language and every machine it is a waste of effort. What we try to do is to generate intermediate code from the source code and then this intermediate code will be the same for many languages and many types of target machines. So, we will see whether it is C or C plus plus or 4 turn or Java, the intermediate code will be very similar. So, we in fact for GCC the same type of intermediate code is used by the entire family of GCC GNU compilers really. GCC is one of them we have GNU compilers for 4 turn Java and C plus plus as well. So, all these compilers use the same form of intermediate code. Once we have the same intermediate code for many languages we can write a single machine independent code optimizer. So, in other words that 35 percent component is going to be used for different languages and it is a common module which will be used for different compilers as well. So, and of course, so once we do that we do not require m into n compilers, but we will really require m plus n compilers. So, for m different languages we require different the front ends that is lexicon analyzer, parser etcetera etcetera. And we also require n numbers of code generators which are specific to the various target machines, but the intermediate code optimizer is going to be common between these. So, strictly speaking you really require m plus n plus 1 number of components for the compilers. Intermediate code must be easy to produce it should not be as complicated as machine code. Otherwise the effort spent in writing a machine code generator and machine independent or intermediate code generator will be similar. So, we do not want that to happen we want the intermediate code to be very simple and very easy to produce. This is some type of a universal language which can be mapped to any you know machine code and it should not contain any machine specific parameters nor is no addresses etcetera. There are different types of intermediate code as well. So, the type of intermediate code that is deployed actually is based on the application. So, quadruples, triples, indirect triples, abstracts, indexes these are all classical forms of intermediate code they have been in existence for decades and they have been used in commercial compilers machine independent optimization, machine code generation in various types of compilers. That is something we are going to study later in our course. Then there is a form of intermediate code called the static single assignment form which is a recent one. When I say recent it is for the past seven eight years it has been deployed in the GCC compiler and using this type of optimize this type of intermediate code makes some of the optimizations more effective. For example, conditional constant propagation global value numbering these are two very important optimizations which are carried out by a good compiler not necessarily simple compilers, but good quality compilers. And these optimizations are more effective on an intermediate code such as SSA rather than the quadruples or triples. So, modern compilers nowadays invariably use SSA form as one of their intermediate forms. So, in other words we may end up using two or more types of intermediate code in our compiler to begin with it could be quadruples or abstracts, indexes it may be translated to static single assignment form for better optimization and again translated to another type of intermediate code for better machine instruction machine code generation. Finally, program dependence type of a graph is another type of intermediate code which is useful in automatic parallelization instruction scheduling software pipelining etcetera. This is the intermediate code which shows the dependence between various types of statements in the program. For example, if there are two assignment statements in the program one of them produces a variable A the other one uses a variable A then there is a dependence between these two statements. So, this is in an actual what a program dependence graph shows. So, with this type of dependence is useful for automatic parallelization and other operations which I have mentioned here. Now, the code optimizer is the next phase which takes as input the intermediate code and generates you know produces very efficient code optimizer, code intermediate code and inputs it into the machine code generator. So, I have already told you what a code optimizer is it improves code. So, let us see how it operates here. So, here the first statement T1 equal to 82 star 1.8 remains as it is there is not much we can do in that, but it is not necessary to retain the second statement which is T2 equal to into float 32. So, we might as well create a floating point constant 32.0 and generate a new quadruple ID1 equal to T1 plus 32.0 instead of the three quadruples which are stated here. So, we have actually reduce the number of quadruples from 4 to 2 you know it is a really good achievement because for the short program it implies a 50 percent improvement. The machine independent code optimization actually becomes necessary because intermediate code as I said is a very simple type of code and the intermediate code generation process introduces many inefficiencies. So, there are extra copies of variables then instead of constants we actually put them into variables and then use that variable and then some expressions are evaluated again and again. So, these are all inefficiencies which result from intermediate code generation. So, code optimization removes such inefficiencies and improves code. And the improvement may be either time or space or power consumption. So, depending on what you require. So, for example, for very efficient servers you require time and memory optimization whereas, for embedded systems it could be power consumption which needs to be minimized. Code optimizers also change the structure of programs and sometimes they change it beyond recognition. So, they may in line functions they may under all loops. So, what does in lining of functions mean when there is a function call instead of making a sub routine call for that particular function the code of that particular function is embedded into the program and that is called in lining. Unrolling loops of course, is easy and fairly well known. We do not execute a loop 100 times. Instead of that we may execute it only 10 times but the body of the loop is made 10 times bigger. 10 iterations are actually in line inside the loop and that is called unrolling of a loop. And eliminating some program or defined variables. So, if there is a counter called i and there is another variable j which is dependent on i. In such a case it may be possible to remove i itself eliminate i. So, this is called induction variable elimination. Code optimization is actually a bunch of few mistakes and the improvement may actually be just 0 you never know whether there would be improvement or not. But some programs yield improvement some other programs may not yield any improvement. So, there are different types of machine dependent optimizations. For example, commence spectrum elimination, copy propagation, loop invariant code motion, partial redundancy elimination, induction variable elimination and strength reduction, code optimization. To perform these optimizations we require information about the program. What type of information which expressions are being re-computed in a function which definitions reach a particular point. So, analysis of the program to determine such information and storing it in a particular way is called data flow analysis and we are going to study this part of a compiler towards the end of the course. Finally, the machine code generation. So, it takes intermediate code as input and outputs a particular type of machine code. In this case you can say in a load floating point and then multiply floating point, add floating point, store floating point corresponding to these two instructions are being generated here. So, it converts the machine intermediate code into machine code and each intermediate code instruction may actually result in many instructions. Otherwise, it is possible that many intermediate code instructions actually give rise to only one single machine instruction. Depends on the complexity of the machine. It must also handle all aspects of machine architecture, registers, pipelining, cache, multiple function units, multiple course, whatever. All these aspects must be handled by the machine code generator. Generating efficient code is a very difficult problem is usually NP complete and there only for very simple types of machines this can be done optimally and generally tree pattern matching based strategies are among the best that are available. So, of course, we require to re-intimitate code for this type of tree pattern matching based generation. Storage location distance are also made here. So, in a register location which registers are used which operand should go into which register etcetera etcetera are all solved in the machine code generation phase of the compiler. There are also after machine code generation even the code that results is not very efficient. It is possible to improve it little more. For example, there are water known as machine dependent optimizations. If you are listed here, there are water known as pipel optimizations. So, you analyze sequence of instructions say 10, 15 in what is known as a small window and this window is called as a pipel. And using preset patterns you replace them with more efficient instructions. So, for example, load a comma r 1 store r 1 comma a well you know we are loading and then storing immediately. So, this is not necessary. So, you could just say load a comma r 1 get rid of the store instruction. Sometimes there is no need to if you have a code some code where there is a jump instruction and the target is another jump then this jump to jump can be eliminated and replaced by a single jump. It is possible to use say increment in instead of load and add. So, these are called machine idioms and these form part of people optimizations. Instruction scheduling that is reordering of instructions to eliminate pipeline interlocks and increase parallelism. So, usually we should not make the pipeline get stuck. There should be a free flow into the pipeline and out of the pipeline. So, reordering instructions to make this happen is called instructions scheduling and that is one of the machine dependent optimizations. And if the basic you know as per programs are what are known as basic blocks which are single entry, single exit pieces of code. So, if they are very small there is no way you can increase the parallelism in the program. So, we must make them bigger and this technique called trace scheduling is used to increase the parallelism available in the program by increasing the size of basic blocks. And finally, the software pipelining which is too complex to explain overly is a very sophisticated optimization which is used to increase parallelism in loops. So, that brings us to the end of the overview and in the next lecture we are going to look at the details of lexical analysis parsing etcetera. Thank you very much.\"\n","output_type":"stream"}]},{"cell_type":"code","source":"times = []\nfor i, segment in enumerate(result['segments']):\n    start, end = segment['start'], segment['end']\n    print(i)\n    print(f\"00:00:{str(int(start)).replace('.', ',')} --> 00:00:{str(int(end)).replace('.', ',')}\")\n    times.append(int(start))\n    print(segment['text'].strip())\n    print()","metadata":{"execution":{"iopub.status.busy":"2023-11-02T10:44:51.364405Z","iopub.execute_input":"2023-11-02T10:44:51.365157Z","iopub.status.idle":"2023-11-02T10:44:51.388272Z","shell.execute_reply.started":"2023-11-02T10:44:51.365101Z","shell.execute_reply":"2023-11-02T10:44:51.387220Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"0\n00:00:14 --> 00:00:22\nWelcome to this new course on Principles of Compiler Design. So, in this lecture I will\n\n1\n00:00:22 --> 00:00:31\ngive you an overview of a compiler, but before that we will also see how exactly the course\n\n2\n00:00:31 --> 00:00:39\nis organized and then the motivation for studying compiler design and of course, then go on\n\n3\n00:00:39 --> 00:00:42\nto the details of a compiler with block diagrams.\n\n4\n00:00:44 --> 00:00:53\nSo, the course is actually a first level course. In other words, this takes a detail look at the\n\n5\n00:00:53 --> 00:00:62\ninternals of a compiler and I do not assume any background for this particular course, but it\n\n6\n00:00:62 --> 00:00:69\nis a very intensive course. So, the pace of the course is going to be you know not very slow,\n\n7\n00:00:70 --> 00:00:77\nbut at the same time it is not going to be Ray C either, but the students who are actually\n\n8\n00:00:77 --> 00:00:84\ngoing to take this course seriously are requested to do the programming assignments.\n\n9\n00:00:84 --> 00:00:89\nThey are also supposed to solve theoretical problems, which I am going to suggest. Otherwise,\n\n10\n00:00:90 --> 00:00:97\nthis course will not be understood you know properly. The reason is a compiler is an excellent\n\n11\n00:00:97 --> 00:00:104\nexample of the theory being translated into practice and this is a wonderful example of that.\n\n12\n00:00:104 --> 00:00:112\nSo, let us see the motivation for studying a compiler. So, compilers are really everywhere.\n\n13\n00:00:113 --> 00:00:121\nSo, if you look at the applications of modern compiler technology pick up the browser,\n\n14\n00:00:122 --> 00:00:129\nopen it and then immediately you know there would be HTML files which are displayed on the\n\n15\n00:00:130 --> 00:00:136\nhomepage and that you are going to visit and so on. So, the HTML parsers are based on compiler\n\n16\n00:00:136 --> 00:00:144\ntechnology and then behind the scene there is JavaScript, there is flash etcetera running inside\n\n17\n00:00:144 --> 00:00:152\nthe browser and the interpreters for this JavaScript script and flash etcetera are also based\n\n18\n00:00:152 --> 00:00:158\non the modern compiler technology. Then of course, for the compiler itself we require machine\n\n19\n00:00:158 --> 00:00:165\ncode generation and for high level languages whenever we need code generation we you know\n\n20\n00:00:165 --> 00:00:171\nwe need to use compiler technology anyway. But then apart from that it has uses in software\n\n21\n00:00:171 --> 00:00:177\nengineering as well. For example, software testing and then program optimization then in the\n\n22\n00:00:177 --> 00:00:185\nsecurity domain malicious code detection design of new computer architectures. So, why are\n\n23\n00:00:185 --> 00:00:192\nthese important? For example, if you look at the development of a new processor nobody builds\n\n24\n00:00:192 --> 00:00:198\na processor you know right away even if the design is 100 percent accurate and all that the\n\n25\n00:00:198 --> 00:00:204\nperformance etcetera will all be known only after the hardware is built. Therefore, there\n\n26\n00:00:204 --> 00:00:213\nis a simulator which is built for a new CPU and then people also build compiler for that\n\n27\n00:00:213 --> 00:00:217\nparticular CPU. So, once the compiler is built you can compile\n\n28\n00:00:217 --> 00:00:224\nwrite programs in C or C++ or any other language compile those programs and then run them\n\n29\n00:00:224 --> 00:00:229\non the simulator see what kind of performance it has is giving if necessary make changes\n\n30\n00:00:229 --> 00:00:234\nin the hardware. So, that is called the compiler in the loop hardware development and it is\n\n31\n00:00:234 --> 00:00:241\nvery useful perhaps very widely used by chip designers in various companies. Then again in\n\n32\n00:00:243 --> 00:00:251\nthe area of hardware synthesis nobody really writes you know the low level assembly type of\n\n33\n00:00:251 --> 00:00:258\ncode for generating VLSI designs and so on and so forth that is called RTL register\n\n34\n00:00:258 --> 00:00:265\ntransfer logic. People really write it in very high description you know high level description\n\n35\n00:00:265 --> 00:00:273\nlanguages called VHDL or VDL and so on and then the compilers really generate RTL from\n\n36\n00:00:273 --> 00:00:279\nVHDL again compiler technology is involved here and then the novel application of compiler\n\n37\n00:00:280 --> 00:00:286\ntechnology is compiled simulation. Suppose you write a program in VHDL how do you really\n\n38\n00:00:287 --> 00:00:292\nfind out the performance of the chip or whatever is designed using that VHDL.\n\n39\n00:00:293 --> 00:00:300\nSo, typically a compiler is used to generate a simulator and the simulator is actually\n\n40\n00:00:302 --> 00:00:307\na computer program which is generated for that particular program which is being simulated.\n\n41\n00:00:308 --> 00:00:314\nSo, this is called simulation of the design and it is an example of compiled simulation.\n\n42\n00:00:314 --> 00:00:320\nThere is no interpretation of the design here and hence such simulations are much faster\n\n43\n00:00:320 --> 00:00:328\nthan interpretations. So, about the complexity of compiler technology it is also necessary\n\n44\n00:00:328 --> 00:00:336\nto say few words about this aspect. If you look at the compiler it is possibly the most\n\n45\n00:00:337 --> 00:00:343\ncomplex system software and writing it is a substantial exercise in software engineering.\n\n46\n00:00:344 --> 00:00:351\nSo, in fact in our institutes whenever somebody teaches courses on compiler design the\n\n47\n00:00:352 --> 00:00:360\nassociated assignments are really small compilers themselves and writing this is a fairly\n\n48\n00:00:360 --> 00:00:367\nlarge software engineering exercise. The complexity of a compiler really arises from the\n\n49\n00:00:367 --> 00:00:373\nfact that it is required to map a programmers requirements which are written in high level\n\n50\n00:00:374 --> 00:00:379\nlanguages to architectural details. So, we are really talking about a C program and then\n\n51\n00:00:379 --> 00:00:385\nit is translated into machine level program. So, in between you know the compiler has to\n\n52\n00:00:386 --> 00:00:391\nactually travel a long distance it is not as if it is a very simple operation. So, there\n\n53\n00:00:391 --> 00:00:397\nis a huge amount of complexity here. So, we are going to discuss this particular complexity\n\n54\n00:00:397 --> 00:00:404\nand the complex operation in its details in our course. A compiler uses you know algorithms\n\n55\n00:00:404 --> 00:00:408\nand techniques from a very large number of areas in computer science. We are going to\n\n56\n00:00:408 --> 00:00:415\nsee some examples very soon. So, it is not in that compiler technology is a subject on\n\n57\n00:00:415 --> 00:00:421\nits own. It has to borrow a huge number of techniques and algorithms from other areas\n\n58\n00:00:421 --> 00:00:429\nin computer science. And compiler translates I already mentioned this intricate theory\n\n59\n00:00:429 --> 00:00:436\ninto practice. So, you take a for example, a context free grammar specification which is\n\n60\n00:00:437 --> 00:00:443\nvery formal, very precise and absolutely essential for writing a you know describing\n\n61\n00:00:443 --> 00:00:449\na language. It can be translated into a parser with minimal effort there are tools such\n\n62\n00:00:449 --> 00:00:456\nas Yoc which do this. So, this enable in this enables tool building. So, tools take very\n\n63\n00:00:456 --> 00:00:461\nabstract specifications and generate programs from these specifications.\n\n64\n00:00:464 --> 00:00:470\nSo, now let us look at the type of algorithms which are used inside a compiler and see\n\n65\n00:00:470 --> 00:00:477\nand let me show you how we require many types of algorithms here. So, we require results\n\n66\n00:00:477 --> 00:00:484\nfrom mathematical logic lattice theory linear algebra probability etcetera. So, where are\n\n67\n00:00:484 --> 00:00:491\nthese used? For example, mathematical logic is used to you know in developing type checking\n\n68\n00:00:491 --> 00:00:495\ntheory. Then lattice theory is used in developing static analysis.\n\n69\n00:00:497 --> 00:00:504\nDesign analysis is heavily based on linear algebra and group parallelization is based\n\n70\n00:00:504 --> 00:00:510\non loop dependance analysis. So, cache analysis uses both static analysis and probability\n\n71\n00:00:510 --> 00:00:518\ntheory. So, in other words a very deep mathematical background is required to develop new compiler\n\n72\n00:00:518 --> 00:00:524\nalgorithms. In our course, we are going to study the existing compiler algorithms, but\n\n73\n00:00:524 --> 00:00:530\nwe will also look at some of the you know the basis which actually make up this particular\n\n74\n00:00:530 --> 00:00:538\ntopic. Then there are practical applications of many algorithms. For example, greedy algorithms\n\n75\n00:00:539 --> 00:00:545\nare used in register location. So, heuristic search is used in list scheduling which is a\n\n76\n00:00:545 --> 00:00:553\npart of a code generator. Graph algorithms are used in that code elimination register\n\n77\n00:00:553 --> 00:00:558\nlocation etcetera etcetera. Dynamic programming is used in instruction selection that is\n\n78\n00:00:558 --> 00:00:564\nhow to generate machine code. Optimization techniques are used in instruction scheduling.\n\n79\n00:00:565 --> 00:00:570\nFinite automata play a part in lexical analysis, post-event automata are very helpful for\n\n80\n00:00:570 --> 00:00:577\nparsing, fixed point algorithms are used for data flow analysis, very complex data structures\n\n81\n00:00:577 --> 00:00:582\nsuch as symbol tables, parse trees, data dependence graphs are going to be built. So, we use\n\n82\n00:00:582 --> 00:00:589\ntrees, balance to trees, graphs etcetera for such applications. Computer architecture\n\n83\n00:00:589 --> 00:00:595\nitself uses machine co you know the is used in the knowledge of computer architecture is\n\n84\n00:00:595 --> 00:00:604\nused in machine code generation. And then what are the other uses of some parts of\n\n85\n00:00:605 --> 00:00:610\ncompiler technology some aspects of compiler technology. For example, scanning and parsing\n\n86\n00:00:610 --> 00:00:617\ntechniques are of course, used in compilers, but they are also useful for a similar implementation\n\n87\n00:00:618 --> 00:00:623\nthey are useful for online text searching. For example, graph and dog which are available\n\n88\n00:00:623 --> 00:00:631\nin UNIX are based on you know the scanning techniques word processing website filtering\n\n89\n00:00:631 --> 00:00:637\ncommand language interpreters that is for UNIX for example, shell you know. So, is a command\n\n90\n00:00:637 --> 00:00:644\nlanguage comes scripting language. So, interpreters for such languages are useful scripting language\n\n91\n00:00:645 --> 00:00:651\ninterpretation again pearl, python, annex shell, XML parsing, documentary construction, database\n\n92\n00:00:651 --> 00:00:655\ninterpreters the list is very big. So, I have mentioned only a few of them which are\n\n93\n00:00:655 --> 00:00:663\nvery important. What about program analysis? So, one part of a compiler is scanning and\n\n94\n00:00:664 --> 00:00:671\nyou know performs scanning and parsing and another part of a compiler performs program analysis.\n\n95\n00:00:672 --> 00:00:677\nSo, program analysis techniques are useful in converting sequential programs to parallel\n\n96\n00:00:677 --> 00:00:685\nprograms. And very important it can be used to determine if programs are data raise,\n\n97\n00:00:685 --> 00:00:691\nfree in other words are there two parts of the program two threads actually accessing\n\n98\n00:00:691 --> 00:00:696\nthe same locations etcetera etcetera can all be decided using program analysis.\n\n99\n00:00:697 --> 00:00:702\nProfiling programs to determine busy regions of the code well if this is done then we can\n\n100\n00:00:702 --> 00:00:706\npossibly make that particular region of the code much more efficient.\n\n101\n00:00:707 --> 00:00:712\nProgram slicing techniques are used in debugging. So, a slice of a program is one small part\n\n102\n00:00:712 --> 00:00:718\nof a program. So, data flow analysis approach to software testing is again based on program\n\n103\n00:00:718 --> 00:00:724\nanalysis. For example, uncovering errors along all parts dereferencing well pointers, buffer\n\n104\n00:00:724 --> 00:00:729\noverflows, memory leaks these are all common errors which actually occur in programs.\n\n105\n00:00:730 --> 00:00:737\nAnd to a some extent taking detecting such problems using software testing requires\n\n106\n00:00:737 --> 00:00:744\nthe data flow analysis approach. Then worst case execution time estimation and energy\n\n107\n00:00:744 --> 00:00:750\nanalysis. If you look at a program it is very difficult to say what is the worst case\n\n108\n00:00:750 --> 00:00:756\ntime that it requires because time of execution for a particular program is based on its\n\n109\n00:00:756 --> 00:00:762\ninput it depends on the input. So, finding out the worst case input is a very hard problem\n\n110\n00:00:762 --> 00:00:769\nand worst case execution time estimation is also equally hard and uses it uses program\n\n111\n00:00:769 --> 00:00:775\nanalysis techniques. Energy analysis implies the detection you know rather computation of\n\n112\n00:00:775 --> 00:00:781\nthe amount of energy that a program takes. This is as difficult or more difficult than\n\n113\n00:00:781 --> 00:00:786\ntime time analysis. So, program analysis techniques are used in energy analysis as well.\n\n114\n00:00:789 --> 00:00:794\nSo, that is about you know the motivation to study this subject called compiler design.\n\n115\n00:00:795 --> 00:00:801\nSo, let us begin with this block diagram which talks about a general language processing\n\n116\n00:00:801 --> 00:00:811\nsystem. So, to begin with we have for example, here a pre processor which takes a source\n\n117\n00:00:811 --> 00:00:819\nprogram as input and then outputs modified source program. So, even in the C compiler we\n\n118\n00:00:820 --> 00:00:828\nhave such pre processors. So, for example, you write define hash defined macros or hash\n\n119\n00:00:828 --> 00:00:835\ninclude you know direct use inside a program. Then such macros are expanded by the pre processor\n\n120\n00:00:835 --> 00:00:843\nand the pre processor expands and provides the source program as input to the compiler.\n\n121\n00:00:844 --> 00:00:851\nA compiler itself takes a clean you know expanded source program in a high level language\n\n122\n00:00:851 --> 00:00:857\nsuch as C or C plus plus or any other language and outputs this assembly program for the\n\n123\n00:00:857 --> 00:00:864\nparticular machine. So, we will see the details of a compiler in short while. The target assembly\n\n124\n00:00:864 --> 00:00:869\nprogram is input to the assembler which takes the mnemonics in the assembly language and\n\n125\n00:00:869 --> 00:00:876\ntranslate them to actual binary machine code. Finally, the assembler output is called as\n\n126\n00:00:876 --> 00:00:882\nthe relocatable machine code which is combined with library files and relocatable you know\n\n127\n00:00:882 --> 00:00:889\nobject files from other sources by the linker and loader to provide the target machine code\n\n128\n00:00:889 --> 00:00:896\nwhich can run on a particular machine. So, now we 0 in on the compiler itself. So,\n\n129\n00:00:901 --> 00:00:906\ncompiler consists of many blocks they are all listed here.\n\n130\n00:00:907 --> 00:00:914\nLexical analyzer is the first one as output of that goes to a syntax analyzer the output\n\n131\n00:00:914 --> 00:00:920\nof which is again fed to a semantic analyzer following that is the intermediate code generator\n\n132\n00:00:921 --> 00:00:927\nand then comes the machine independent code optimizer the machine code generator and\n\n133\n00:00:927 --> 00:00:936\nfinally, the machine dependent code optimizer. And all these parts of a compiler use a data\n\n134\n00:00:936 --> 00:00:941\nstructure called as a symbol table which is actually somewhere in the middle. So, we\n\n135\n00:00:942 --> 00:00:949\nnow have for example, let us look at a Lexical analyzer and see what it does. A Lexical analyzer\n\n136\n00:00:950 --> 00:00:956\ntakes as input a character stream. So, we are now going to take each of these blocks\n\n137\n00:00:956 --> 00:00:962\nand study them in detail. So, let us begin with this Lexical analyzer. But before we begin\n\n138\n00:00:963 --> 00:00:968\nwith Lexical analyzer I must hasten to add that there is a difference between what are\n\n139\n00:00:968 --> 00:00:975\nknown as compilers and interpreters. So, if we look at the previous slide the compiler\n\n140\n00:00:977 --> 00:00:984\nconsists of this entire you know seven blocks along with the symbol table. Whereas, an\n\n141\n00:00:984 --> 00:00:990\ninterpreter stops after the intermediate code generation stage and the output of the\n\n142\n00:00:990 --> 00:00:997\nintermediate code generator is fed to an interpreter. So, let us see the difference between these\n\n143\n00:00:997 --> 00:00:1003\ntwo. Compilers generate machine code whereas, interpreters generate you know interpret intermediate\n\n144\n00:00:1003 --> 00:00:1009\ncode. Of course, interpreters are only 50 percent of a compiler. So, they are easier to\n\n145\n00:00:1009 --> 00:00:1015\nwrite and can provide better error messages because we still have access to the symbol table\n\n146\n00:00:1015 --> 00:00:1023\nand so on. But the catch is interpreters are 5 times lower or more actually more than\n\n147\n00:00:1023 --> 00:00:1027\n5 times lower than machine code generated by compilers. So, running machine code is\n\n148\n00:00:1027 --> 00:00:1034\nmuch faster, but interpreters are easier to build. So, people tend to write you know\n\n149\n00:00:1034 --> 00:00:1040\ninterpreters for certain types of languages whereas, they try to write compilers for languages\n\n150\n00:00:1040 --> 00:00:1045\nwhich are used to write professional programs. Interpreters also require much more memory.\n\n151\n00:00:1047 --> 00:00:1053\nAnd then you know even the compilation, lexical analysis parsing etcetera is all the time required\n\n152\n00:00:1053 --> 00:00:1060\nby the interpreter itself is added to the time required by the interpreter. So, they require\n\n153\n00:00:1060 --> 00:00:1064\nmuch more memory much more time than machine code generated by compilers and there are very\n\n154\n00:00:1064 --> 00:00:1072\nfamous examples per Python, Unixel, Java, Basic, List etcetera are all you know interpreter\n\n155\n00:00:1072 --> 00:00:1080\nbased languages. Now, let us get back to the block diagram and let us look at the lexical\n\n156\n00:00:1080 --> 00:00:1088\nanalyzer in some detail. A lexical analyzer takes source program. For example, here there\n\n157\n00:00:1088 --> 00:00:1095\nis a line far and high equal to centigrade star 1.8 plus 32. This is an assignment statement\n\n158\n00:00:1095 --> 00:00:1100\nin any particular language you know there is no need to talk about a particular C or C\n\n159\n00:00:1100 --> 00:00:1107\nplus plus such assignments are available in every language. So, now a the lexical analyzer\n\n160\n00:00:1107 --> 00:00:1115\ntakes as input such sentences from a source program and then it generates what is known\n\n161\n00:00:1115 --> 00:00:1123\nas a token stream. So, in this particular case the two names far and high and centigrade\n\n162\n00:00:1124 --> 00:00:1130\nare all are both called identifiers. So, far and high is coded as identifier 1 and\n\n163\n00:00:1130 --> 00:00:1137\ncentigrade is coded as identifier 2. The equal to sign which corresponds to assignment\n\n164\n00:00:1137 --> 00:00:1145\nis actually made an assign co is made into a token of kind of sign. Similarly, multiply\n\n165\n00:00:1145 --> 00:00:1153\noperator is a melt up and then plus is made into an add up. The constant 1.8 is a floating\n\n166\n00:00:1153 --> 00:00:1161\npoint constant I constant you know 32 corresponds to the number 32. So, in other words we now\n\n167\n00:00:1161 --> 00:00:1170\nhave a stream of these tokens. The first part of the token ID assign ID melt up, F\n\n168\n00:00:1170 --> 00:00:1176\nconstant add up icons these are typically integers there numbers. Whereas, the second part\n\n169\n00:00:1176 --> 00:00:1183\nwhenever it is present is actually gives you hints about what type of you know the token\n\n170\n00:00:1183 --> 00:00:1191\nit is for example, if it is ID then that 1 and 2 may point to a table with indices 1 and\n\n171\n00:00:1191 --> 00:00:1198\n2 containing the string corresponding to the identifier. The icons F constant you know\n\n172\n00:00:1198 --> 00:00:1203\nthe second part will tell you the value of that particular number and so on and so forth.\n\n173\n00:00:1204 --> 00:00:1209\nThis is the input to syntax and lizer. So, now let us look at the reasons why lexical\n\n174\n00:00:1209 --> 00:00:1217\nanalysis is required very briefly. So, so the lexical lizers can be generated automatically\n\n175\n00:00:1219 --> 00:00:1227\nfrom regular expression specifications. So, for example, lex and flex are two tools\n\n176\n00:00:1228 --> 00:00:1235\navailable in unix and if we feed a regular expression specification we are going to study\n\n177\n00:00:1235 --> 00:00:1242\nthese specifications later in the course outcomes a program which works as a lexical lizer.\n\n178\n00:00:1243 --> 00:00:1248\nThe lexical lizers are actually is a deterministic finite state automaton each one of them is\n\n179\n00:00:1248 --> 00:00:1254\na finite state machine and we will learn what these are in the coming lectures. But now,\n\n180\n00:00:1254 --> 00:00:1262\nlet us answer the question why is lexical analysis separate from parsing. It is not a theoretical\n\n181\n00:00:1265 --> 00:00:1271\nlimitation in other words the next phase of a compiler called parser can actually incorporate\n\n182\n00:00:1274 --> 00:00:1279\nthe lexical analysis also there is not much difficulty as far as theory is concerned.\n\n183\n00:00:1280 --> 00:00:1287\nBut practically if you look at the design a compiler is an extremely large piece of\n\n184\n00:00:1287 --> 00:00:1294\nsoftware millions of lines of code and simplifying the design making it modular is the only way\n\n185\n00:00:1295 --> 00:00:1301\nits complexity can be controlled. So, simplification of the design by making lexical lizer a separate\n\n186\n00:00:1301 --> 00:00:1306\nmodule is a reason because of software engineering purposes.\n\n187\n00:00:1308 --> 00:00:1315\nThe second reason input output issues are very limited you know are very serious and\n\n188\n00:00:1316 --> 00:00:1323\nit is not a good idea to distribute such input output you know issues all over a compiler\n\n189\n00:00:1323 --> 00:00:1329\nthey are best handled in one module and in this case in a compiler lexical lizer handles\n\n190\n00:00:1329 --> 00:00:1337\nall the input output issues. So, for example, it reads programs you know the from the\n\n191\n00:00:1338 --> 00:00:1344\nsource file and then any errors etcetera are all actually listed by the lexical lizer after\n\n192\n00:00:1344 --> 00:00:1352\ncollecting them from various parts then and so on. So, lexical lizers based on finite\n\n193\n00:00:1352 --> 00:00:1357\nautomata are more efficient to implement than push down automata which are used for parsing.\n\n194\n00:00:1359 --> 00:00:1366\nThis is a very deep reason. So, as I already mentioned lexical lizer is nothing but a deterministic\n\n195\n00:00:1366 --> 00:00:1372\nfinite state automata and a parser as we will see later corresponds to a push down automata.\n\n196\n00:00:1373 --> 00:00:1380\nA push down automata uses a stack for its operation. So, if we actually try doing lexical\n\n197\n00:00:1380 --> 00:00:1385\nlizers with a push down automata then we will end up actually pushing a lot of symbols\n\n198\n00:00:1386 --> 00:00:1390\nunder the stack then popping them off the stack and so on which are very inefficient\n\n199\n00:00:1391 --> 00:00:1398\noperations. And therefore, using incorporating lexical lizer into a parser makes it very\n\n200\n00:00:1400 --> 00:00:1406\ninefficient compared to the making a finite automata based lexical lizer. So, these are the\n\n201\n00:00:1406 --> 00:00:1412\nreasons why lexical lizers are separate and of course, if you look at the previous\n\n202\n00:00:1413 --> 00:00:1419\nslide as I said each one of these tokens the first part of the token is an integer.\n\n203\n00:00:1419 --> 00:00:1425\nSo, storing these integers is much more efficient than storing the characters corresponding\n\n204\n00:00:1425 --> 00:00:1433\nto the source program. So, it is actually a very you know succinct and compact way of\n\n205\n00:00:1435 --> 00:00:1442\ngiving the program to the syntax lizer. So, then once we understand lexical analysis\n\n206\n00:00:1442 --> 00:00:1449\nwe must see how it actually helps syntax analysis the output of the lexical lizer is fed\n\n207\n00:00:1450 --> 00:00:1456\nto a syntax lizer. So, we have these tokens coming into a syntax\n\n208\n00:00:1456 --> 00:00:1463\nlizer the syntax lizer looks at the tokens and finds out whether the syntax is according\n\n209\n00:00:1463 --> 00:00:1469\nto a grammar specification. In other words the assignment statement must have a variable\n\n210\n00:00:1470 --> 00:00:1476\non the left side an expression on the right side and so on. So, does this have you know\n\n211\n00:00:1476 --> 00:00:1481\nthe assignment operator is it correct or is it there is a mistake and whether the plus\n\n212\n00:00:1481 --> 00:00:1487\nstar etcetera are all properly inserted into the expression. These are all the syntax\n\n213\n00:00:1487 --> 00:00:1492\nchecks that syntax lizer can perform based on grammar specification which is given to\n\n214\n00:00:1493 --> 00:00:1494\nit.\n\n215\n00:00:1494 --> 00:00:1502\nSo, input of a syntax lizer is a tree this small tree is called as a syntax tree or abstract\n\n216\n00:00:1502 --> 00:00:1508\nsyntax tree. So, for example, here it shows the structure of the assignment statement\n\n217\n00:00:1508 --> 00:00:1515\nabove this was Fahrenheit equal to you know as as let us look at it.\n\n218\n00:00:1515 --> 00:00:1523\nFahrenheit equal to centigrade into 1.8 plus 32. So, here this id corresponds to Fahrenheit\n\n219\n00:00:1523 --> 00:00:1530\nthis id corresponds to the next identifier and then we have the assignment symbol plus\n\n220\n00:00:1531 --> 00:00:1537\nstar 1.8 and 32. So, everything is working out well. So, this structure is shown in the\n\n221\n00:00:1537 --> 00:00:1543\nform of syntax tree which is the input to the next phase of compiler called the semantic\n\n222\n00:00:1543 --> 00:00:1550\nanalyzer. So, syntax analyzers can be generated automatically from context tree grammar.\n\n223\n00:00:1552 --> 00:00:1556\nSo, we will learn about these specifications a little later, but right now it suffices\n\n224\n00:00:1556 --> 00:00:1564\nto say that the you know there are tools to do this. For example, the yawk and antler are\n\n225\n00:00:1564 --> 00:00:1572\ntwo such tools. So, they handle what are known as you know LALR1 grammars that is yawk\n\n226\n00:00:1572 --> 00:00:1579\nand bison and antler handles what are known as LL1 grammars. They generate C programs\n\n227\n00:00:1579 --> 00:00:1586\nor C plus plus programs which correspond to these parsers you know and they can be used\n\n228\n00:00:1586 --> 00:00:1592\nby the compiler. So, as I already said parsers are based on pushdown automata. So, they\n\n229\n00:00:1592 --> 00:00:1598\nare actually what are known as deterministic pushdown automata and there is a reason why\n\n230\n00:00:1599 --> 00:00:1606\nwe need the next phase of analysis called semantic analysis. The reason is parsers cannot\n\n231\n00:00:1606 --> 00:00:1613\nhandle context sensitive features of programming languages. Let me give you a few examples.\n\n232\n00:00:1614 --> 00:00:1620\nSo, if you are looking at the syntax alone that is whether the assignment statement has\n\n233\n00:00:1621 --> 00:00:1626\nan identifier on the variable or identifier on the left hand side a properly formed expression\n\n234\n00:00:1626 --> 00:00:1634\non the right hand side this forms a syntax, but if you say can I check whether an integer\n\n235\n00:00:1637 --> 00:00:1641\nvariable is being assigned a floating point expression that is type matching on both sides\n\n236\n00:00:1643 --> 00:00:1650\nof assignment this cannot be handled by a parser. So, there are theoretical limitations\n\n237\n00:00:1650 --> 00:00:1658\nhere context grammar cannot express such features of programming languages. Another feature\n\n238\n00:00:1659 --> 00:00:1665\nwhich is here is variables are declared before use. So, we all know that we declare variables\n\n239\n00:00:1668 --> 00:00:1675\nin a you know float b etcetera etcetera and then at the time of using a and b that is suppose\n\n240\n00:00:1678 --> 00:00:1684\na is used in an assignment statement or an expression. The compiler makes sure that a was\n\n241\n00:00:1685 --> 00:00:1692\ndeclared before and it also makes sure that the type corresponding to the usage of a is\n\n242\n00:00:1692 --> 00:00:1698\nthe same as the type corresponding to its declaration. So, this feature variables declared\n\n243\n00:00:1698 --> 00:00:1705\nand then checked after use or even declared before use cannot be captured using context\n\n244\n00:00:1705 --> 00:00:1712\nregrammers. They require higher form of grammars called as context sensitive grammars and this\n\n245\n00:00:1713 --> 00:00:1720\nis the reason why we need another phase of analysis called semantic analysis. Another very\n\n246\n00:00:1720 --> 00:00:1726\nimportant feature of programming languages which cannot be captured in the context regrammer\n\n247\n00:00:1727 --> 00:00:1734\nand hence cannot be caught as mistakes of this kind cannot be caught by a parser. They\n\n248\n00:00:1734 --> 00:00:1741\nis here you know parameter types and number match in declaration and use. So, we declare\n\n249\n00:00:1741 --> 00:00:1748\nlarge number of parameters in program functions which we write and each one of these parameters\n\n250\n00:00:1749 --> 00:00:1757\nhas a type attached to it. So, when we actually call that function or procedure we have to make\n\n251\n00:00:1758 --> 00:00:1765\nsure that the actual parameters that we supply are of the same type and the number of parameters\n\n252\n00:00:1765 --> 00:00:1772\nwe supply are exactly the same as the one in the declaration. So, parameter type and number\n\n253\n00:00:1772 --> 00:00:1779\nmatch in declaration use this property cannot be caught by the parser if the misuse of this\n\n254\n00:00:1779 --> 00:00:1785\nproperty cannot be mistakes if this type cannot be caught by a parser and therefore, semantic\n\n255\n00:00:1785 --> 00:00:1793\nanalysis is supposed to take care of it. So, the next phase is the semantic analysis phase\n\n256\n00:00:1793 --> 00:00:1801\nthe input to the semantic analysis phase is a syntax tree. So, we already know that syntax\n\n257\n00:00:1804 --> 00:00:1811\ntree is produced by a syntax analyzer it goes into a semantic analyzer and the output is\n\n258\n00:00:1811 --> 00:00:1819\nalso a syntax tree, but it is actually modified syntax tree. In other words there are changes\n\n259\n00:00:1819 --> 00:00:1826\nmade to this particular syntax tree. So, that the types of operands are all taken care\n\n260\n00:00:1827 --> 00:00:1835\nof for example, this expression id star 1.8 corresponds to a floating point type you know\n\n261\n00:00:1837 --> 00:00:1843\nboth the id 2 and 1.8 are floating point types, but then we are adding an integer called\n\n262\n00:00:1844 --> 00:00:1850\n32. So, if there is some violation the you cannot really add floating point numbers\n\n263\n00:00:1850 --> 00:00:1856\nand integers directly because the representation of these numbers is different inside a compiler.\n\n264\n00:00:1857 --> 00:00:1863\nSo, what does the compiler do inside a machine? So, the representation is different inside\n\n265\n00:00:1863 --> 00:00:1869\na machine. So, what does the compiler do? It converts the number 32 into a floating point\n\n266\n00:00:1869 --> 00:00:1876\nnumber and then proceeds to generate a machine code for this particular statement. So, and\n\n267\n00:00:1876 --> 00:00:1882\nthis is recorded faithfully in the syntax tree which is called as the annotated syntax\n\n268\n00:00:1882 --> 00:00:1887\ntree. So, that the code generator need not worry too much it just goes ahead with code\n\n269\n00:00:1887 --> 00:00:1892\ngeneration looking at what is available in the annotated syntax tree.\n\n270\n00:00:1895 --> 00:00:1900\nSo, semantic consistency that cannot be handled at the parsing stage is handled here.\n\n271\n00:00:1901 --> 00:00:1907\nSo, I already gave you examples of this. So, I am the same thing is repeated here type\n\n272\n00:00:1907 --> 00:00:1913\nchecking of various programming language constructs is one of the most important task. As semantic\n\n273\n00:00:1913 --> 00:00:1921\nanalyzer also stores information in the symbol table or the syntax tree itself. So, each\n\n274\n00:00:1921 --> 00:00:1925\nnode of the syntax tree could store information corresponding to that particular node.\n\n275\n00:00:1926 --> 00:00:1932\nWhat is the type of information that is stored? What are the types of variables? Is it in\n\n276\n00:00:1932 --> 00:00:1939\nis it flowed? Is it a struct? Is it an array? etcetera. What are the types of function parameters?\n\n277\n00:00:1940 --> 00:00:1947\nWhat are the dimensions of an array etcetera? So, these are the information that are stored\n\n278\n00:00:1948 --> 00:00:1954\nin a symbol table by the semantic analyzer. This information is used not only for caching\n\n279\n00:00:1954 --> 00:00:1960\nerrors semantic validation as we know it, but it is also used for subsequent phases of\n\n280\n00:00:1960 --> 00:00:1968\nthe compilation process itself. For example, the code optimizer will also require information\n\n281\n00:00:1968 --> 00:00:1976\nabout the types of operands in order to perform certain types of optimization. And then the\n\n282\n00:00:1976 --> 00:00:1981\nmachine code generator needs to know the types of variables in order to generate appropriate\n\n283\n00:00:1981 --> 00:00:1987\ntypes of instructions. So, both these phases require access to the symbol table. So, this\n\n284\n00:00:1987 --> 00:00:1992\nis the semantic analysis phase builds the symbol table and that is the database which is\n\n285\n00:00:1992 --> 00:00:1997\nused by the you know the phases later in compilation.\n\n286\n00:00:1999 --> 00:00:2003\nStatic semantics of programming languages can be specified using what are known as attribute\n\n287\n00:00:2003 --> 00:00:2010\ngrammars. So, we are going to study attribute grammars also in our course a little later of course.\n\n288\n00:00:2012 --> 00:00:2017\nAnd attribute grammars actually are an extension of context free grammars. They are useful for\n\n289\n00:00:2018 --> 00:00:2023\nspecifying the semantics, what are known as static semantics of programming languages.\n\n290\n00:00:2024 --> 00:00:2030\nAnd it is possible to generate the semantic analyzers semi-automatically from such\n\n291\n00:00:2031 --> 00:00:2038\nspecifications of attribute grammars. The next phase of compilation is the intermediate\n\n292\n00:00:2041 --> 00:00:2049\ncode generation phase. So, the annotated syntax tree which is output from a semantic analyzer\n\n293\n00:00:2050 --> 00:00:2056\nis the input to an intermediate code generator. And the output of the intermediate code generator\n\n294\n00:00:2056 --> 00:00:2063\nis to a machine independent code optimizer. So, let us see what this intermediate code\n\n295\n00:00:2063 --> 00:00:2069\ngenerator has done on our example. So, here is a small tree corresponding to an assignment\n\n296\n00:00:2069 --> 00:00:2076\nstatement. So, it is very obvious that we need to do this multiplication first then the\n\n297\n00:00:2076 --> 00:00:2083\ninto float and then the plus and finally, the assignment. So, and that is the order in\n\n298\n00:00:2083 --> 00:00:2088\nwhich the intermediate code has been generated. So, I will tell you why intermediate code after\n\n299\n00:00:2088 --> 00:00:2093\na few minutes, but let us understand this code to see what the intermediate code generator\n\n300\n00:00:2093 --> 00:00:2100\nhas done. It has generated T 1 equal to 2 into 1.8 corresponding to this expression.\n\n301\n00:00:2101 --> 00:00:2107\nIt has generated T 2 equal to into float 32 corresponding to this expression. T 3 equal\n\n302\n00:00:2108 --> 00:00:2114\nto T 2 corresponding to this small tree and finally, I d 1 equal to T 3 corresponding\n\n303\n00:00:2114 --> 00:00:2122\nto the assignment operator. So, an intermediate code program has the same semantics as the\n\n304\n00:00:2125 --> 00:00:2133\noriginal source level program, but it is at a much lower level compared to the source\n\n305\n00:00:2133 --> 00:00:2139\nlevel program, but I must you know mention that it is not a machine language. So, let us\n\n306\n00:00:2139 --> 00:00:2147\nsee why we require such intermediate code and what exactly we do with it. So, when generating\n\n307\n00:00:2148 --> 00:00:2154\nmachine code from directly from source code is definitely possible. There is no theoretical\n\n308\n00:00:2155 --> 00:00:2161\nor practical limitation. There are two problems associated with this approach. The problem\n\n309\n00:00:2162 --> 00:00:2167\nis you need to write too many compilers. Suppose you want to write compilers for m languages\n\n310\n00:00:2168 --> 00:00:2175\nand let us say you have n target machines for which you require compilers. So, if we directly\n\n311\n00:00:2175 --> 00:00:2182\nwrite you know generate machine code without generating any other form of intermediate code,\n\n312\n00:00:2182 --> 00:00:2185\nwe need to write m into n number of compilers.\n\n313\n00:00:2187 --> 00:00:2195\nNow, inside a compiler the code optimizer is perhaps one of the largest and the most\n\n314\n00:00:2195 --> 00:00:2203\ndifficult to write component and it so happens that if we write you know compilers which\n\n315\n00:00:2204 --> 00:00:2211\ngenerate machine code directly, we will not be able to reuse any part of this optimizer.\n\n316\n00:00:2211 --> 00:00:2219\nTo give you the norm to some in cling of what is involved about 50 percent of the compiler\n\n317\n00:00:2223 --> 00:00:2231\nsource code is for you know the front end that is the lexical analyzer, the parser and\n\n318\n00:00:2234 --> 00:00:2239\nsemantic analyzer and let us assume that there is an intermediate code generator. So, all\n\n319\n00:00:2239 --> 00:00:2245\nthese four components together form about 50 percent of the source code of a compiler.\n\n320\n00:00:2246 --> 00:00:2253\nThe other 50 percent is for the code optimizer and the machine code generator. So, out of\n\n321\n00:00:2254 --> 00:00:2261\nthese about 30, 35 percent is meant for just this code optimizer and the other 20 percent\n\n322\n00:00:2261 --> 00:00:2267\n25 percent is for machine code generation and machine code optimization.\n\n323\n00:00:2269 --> 00:00:2275\nSo, a very large part of compiler 30 to 40 percent if it has to be written again and\n\n324\n00:00:2275 --> 00:00:2282\nagain you know for every language and every machine it is a waste of effort. What we\n\n325\n00:00:2282 --> 00:00:2289\ntry to do is to generate intermediate code from the source code and then this intermediate\n\n326\n00:00:2289 --> 00:00:2296\ncode will be the same for many languages and many types of target machines. So, we will\n\n327\n00:00:2299 --> 00:00:2306\nsee whether it is C or C plus plus or 4 turn or Java, the intermediate code will be very\n\n328\n00:00:2306 --> 00:00:2313\nsimilar. So, we in fact for GCC the same type of intermediate code is used by the entire\n\n329\n00:00:2313 --> 00:00:2320\nfamily of GCC GNU compilers really. GCC is one of them we have GNU compilers for 4 turn\n\n330\n00:00:2321 --> 00:00:2327\nJava and C plus plus as well. So, all these compilers use the same form of intermediate\n\n331\n00:00:2327 --> 00:00:2334\ncode. Once we have the same intermediate code for many languages we can write a single\n\n332\n00:00:2334 --> 00:00:2342\nmachine independent code optimizer. So, in other words that 35 percent component is going\n\n333\n00:00:2342 --> 00:00:2348\nto be used for different languages and it is a common module which will be used for different\n\n334\n00:00:2348 --> 00:00:2356\ncompilers as well. So, and of course, so once we do that we do not require m into n\n\n335\n00:00:2356 --> 00:00:2363\ncompilers, but we will really require m plus n compilers. So, for m different languages\n\n336\n00:00:2363 --> 00:00:2369\nwe require different the front ends that is lexicon analyzer, parser etcetera etcetera.\n\n337\n00:00:2370 --> 00:00:2376\nAnd we also require n numbers of code generators which are specific to the various target machines,\n\n338\n00:00:2377 --> 00:00:2382\nbut the intermediate code optimizer is going to be common between these. So, strictly speaking\n\n339\n00:00:2383 --> 00:00:2388\nyou really require m plus n plus 1 number of components for the compilers.\n\n340\n00:00:2389 --> 00:00:2394\nIntermediate code must be easy to produce it should not be as complicated as machine code.\n\n341\n00:00:2394 --> 00:00:2402\nOtherwise the effort spent in writing a machine code generator and machine independent or\n\n342\n00:00:2404 --> 00:00:2410\nintermediate code generator will be similar. So, we do not want that to happen we want\n\n343\n00:00:2410 --> 00:00:2415\nthe intermediate code to be very simple and very easy to produce. This is some type of\n\n344\n00:00:2415 --> 00:00:2422\na universal language which can be mapped to any you know machine code and it should not\n\n345\n00:00:2422 --> 00:00:2430\ncontain any machine specific parameters nor is no addresses etcetera. There are different\n\n346\n00:00:2432 --> 00:00:2438\ntypes of intermediate code as well. So, the type of intermediate code that is deployed\n\n347\n00:00:2439 --> 00:00:2446\nactually is based on the application. So, quadruples, triples, indirect triples, abstracts,\n\n348\n00:00:2446 --> 00:00:2452\nindexes these are all classical forms of intermediate code they have been in existence\n\n349\n00:00:2452 --> 00:00:2458\nfor decades and they have been used in commercial compilers machine independent optimization,\n\n350\n00:00:2459 --> 00:00:2465\nmachine code generation in various types of compilers. That is something we are going\n\n351\n00:00:2465 --> 00:00:2473\nto study later in our course. Then there is a form of intermediate code called the\n\n352\n00:00:2473 --> 00:00:2480\nstatic single assignment form which is a recent one. When I say recent it is for the past\n\n353\n00:00:2480 --> 00:00:2488\nseven eight years it has been deployed in the GCC compiler and using this type of optimize\n\n354\n00:00:2488 --> 00:00:2495\nthis type of intermediate code makes some of the optimizations more effective. For example,\n\n355\n00:00:2496 --> 00:00:2504\nconditional constant propagation global value numbering these are two very important optimizations\n\n356\n00:00:2504 --> 00:00:2509\nwhich are carried out by a good compiler not necessarily simple compilers, but good quality\n\n357\n00:00:2509 --> 00:00:2517\ncompilers. And these optimizations are more effective on an intermediate code such as\n\n358\n00:00:2517 --> 00:00:2523\nSSA rather than the quadruples or triples. So, modern compilers nowadays invariably\n\n359\n00:00:2523 --> 00:00:2530\nuse SSA form as one of their intermediate forms. So, in other words we may end up using\n\n360\n00:00:2530 --> 00:00:2536\ntwo or more types of intermediate code in our compiler to begin with it could be quadruples\n\n361\n00:00:2536 --> 00:00:2542\nor abstracts, indexes it may be translated to static single assignment form for better\n\n362\n00:00:2542 --> 00:00:2547\noptimization and again translated to another type of intermediate code for better machine\n\n363\n00:00:2547 --> 00:00:2555\ninstruction machine code generation. Finally, program dependence type of a graph is another\n\n364\n00:00:2555 --> 00:00:2562\ntype of intermediate code which is useful in automatic parallelization instruction scheduling\n\n365\n00:00:2562 --> 00:00:2570\nsoftware pipelining etcetera. This is the intermediate code which shows the dependence\n\n366\n00:00:2570 --> 00:00:2577\nbetween various types of statements in the program. For example, if there are two assignment\n\n367\n00:00:2578 --> 00:00:2583\nstatements in the program one of them produces a variable A the other one uses a variable\n\n368\n00:00:2584 --> 00:00:2590\nA then there is a dependence between these two statements. So, this is in an actual what\n\n369\n00:00:2590 --> 00:00:2597\na program dependence graph shows. So, with this type of dependence is useful for automatic\n\n370\n00:00:2597 --> 00:00:2600\nparallelization and other operations which I have mentioned here.\n\n371\n00:00:2602 --> 00:00:2609\nNow, the code optimizer is the next phase which takes as input the intermediate code and\n\n372\n00:00:2612 --> 00:00:2618\ngenerates you know produces very efficient code optimizer, code intermediate code and\n\n373\n00:00:2618 --> 00:00:2625\ninputs it into the machine code generator. So, I have already told you what a code optimizer\n\n374\n00:00:2625 --> 00:00:2631\nis it improves code. So, let us see how it operates here. So, here the first statement T1\n\n375\n00:00:2631 --> 00:00:2637\nequal to 82 star 1.8 remains as it is there is not much we can do in that, but it is not\n\n376\n00:00:2637 --> 00:00:2644\nnecessary to retain the second statement which is T2 equal to into float 32. So, we might\n\n377\n00:00:2644 --> 00:00:2651\nas well create a floating point constant 32.0 and generate a new quadruple ID1 equal to\n\n378\n00:00:2651 --> 00:00:2658\nT1 plus 32.0 instead of the three quadruples which are stated here. So, we have actually\n\n379\n00:00:2662 --> 00:00:2668\nreduce the number of quadruples from 4 to 2 you know it is a really good achievement\n\n380\n00:00:2668 --> 00:00:2672\nbecause for the short program it implies a 50 percent improvement.\n\n381\n00:00:2676 --> 00:00:2683\nThe machine independent code optimization actually becomes necessary because intermediate code\n\n382\n00:00:2683 --> 00:00:2690\nas I said is a very simple type of code and the intermediate code generation process introduces\n\n383\n00:00:2690 --> 00:00:2698\nmany inefficiencies. So, there are extra copies of variables then instead of constants we\n\n384\n00:00:2698 --> 00:00:2704\nactually put them into variables and then use that variable and then some expressions are\n\n385\n00:00:2704 --> 00:00:2709\nevaluated again and again. So, these are all inefficiencies which result from intermediate\n\n386\n00:00:2709 --> 00:00:2717\ncode generation. So, code optimization removes such inefficiencies and improves code. And\n\n387\n00:00:2717 --> 00:00:2722\nthe improvement may be either time or space or power consumption. So, depending on what\n\n388\n00:00:2722 --> 00:00:2731\nyou require. So, for example, for very efficient servers you require time and memory optimization\n\n389\n00:00:2731 --> 00:00:2737\nwhereas, for embedded systems it could be power consumption which needs to be minimized.\n\n390\n00:00:2739 --> 00:00:2745\nCode optimizers also change the structure of programs and sometimes they change it beyond\n\n391\n00:00:2745 --> 00:00:2752\nrecognition. So, they may in line functions they may under all loops. So, what does in\n\n392\n00:00:2752 --> 00:00:2757\nlining of functions mean when there is a function call instead of making a sub routine call\n\n393\n00:00:2757 --> 00:00:2763\nfor that particular function the code of that particular function is embedded into the\n\n394\n00:00:2763 --> 00:00:2765\nprogram and that is called in lining.\n\n395\n00:00:2766 --> 00:00:2772\nUnrolling loops of course, is easy and fairly well known. We do not execute a loop 100 times.\n\n396\n00:00:2772 --> 00:00:2777\nInstead of that we may execute it only 10 times but the body of the loop is made 10 times\n\n397\n00:00:2777 --> 00:00:2782\nbigger. 10 iterations are actually in line inside the loop and that is called unrolling\n\n398\n00:00:2782 --> 00:00:2789\nof a loop. And eliminating some program or defined variables. So, if there is a counter\n\n399\n00:00:2789 --> 00:00:2796\ncalled i and there is another variable j which is dependent on i. In such a case it\n\n400\n00:00:2796 --> 00:00:2801\nmay be possible to remove i itself eliminate i. So, this is called induction variable elimination.\n\n401\n00:00:2801 --> 00:00:2807\nCode optimization is actually a bunch of few mistakes and the improvement may actually\n\n402\n00:00:2808 --> 00:00:2812\nbe just 0 you never know whether there would be improvement or not. But some programs\n\n403\n00:00:2812 --> 00:00:2815\nyield improvement some other programs may not yield any improvement.\n\n404\n00:00:2818 --> 00:00:2823\nSo, there are different types of machine dependent optimizations. For example, commence\n\n405\n00:00:2823 --> 00:00:2829\nspectrum elimination, copy propagation, loop invariant code motion, partial redundancy\n\n406\n00:00:2829 --> 00:00:2834\nelimination, induction variable elimination and strength reduction, code optimization.\n\n407\n00:00:2835 --> 00:00:2841\nTo perform these optimizations we require information about the program. What type of information\n\n408\n00:00:2841 --> 00:00:2846\nwhich expressions are being re-computed in a function which definitions reach a particular\n\n409\n00:00:2846 --> 00:00:2852\npoint. So, analysis of the program to determine such information and storing it in a particular\n\n410\n00:00:2853 --> 00:00:2859\nway is called data flow analysis and we are going to study this part of a compiler towards\n\n411\n00:00:2860 --> 00:00:2866\nthe end of the course. Finally, the machine code generation. So, it takes intermediate\n\n412\n00:00:2866 --> 00:00:2871\ncode as input and outputs a particular type of machine code. In this case you can say\n\n413\n00:00:2872 --> 00:00:2878\nin a load floating point and then multiply floating point, add floating point, store floating\n\n414\n00:00:2878 --> 00:00:2885\npoint corresponding to these two instructions are being generated here. So, it converts\n\n415\n00:00:2885 --> 00:00:2891\nthe machine intermediate code into machine code and each intermediate code instruction\n\n416\n00:00:2891 --> 00:00:2895\nmay actually result in many instructions. Otherwise, it is possible that many intermediate\n\n417\n00:00:2896 --> 00:00:2900\ncode instructions actually give rise to only one single machine instruction. Depends on\n\n418\n00:00:2900 --> 00:00:2905\nthe complexity of the machine. It must also handle all aspects of machine architecture,\n\n419\n00:00:2906 --> 00:00:2913\nregisters, pipelining, cache, multiple function units, multiple course, whatever. All these\n\n420\n00:00:2913 --> 00:00:2916\naspects must be handled by the machine code generator.\n\n421\n00:00:2916 --> 00:00:2922\nGenerating efficient code is a very difficult problem is usually NP complete and there only\n\n422\n00:00:2922 --> 00:00:2927\nfor very simple types of machines this can be done optimally and generally tree pattern\n\n423\n00:00:2927 --> 00:00:2934\nmatching based strategies are among the best that are available. So, of course, we require\n\n424\n00:00:2934 --> 00:00:2940\nto re-intimitate code for this type of tree pattern matching based generation. Storage\n\n425\n00:00:2940 --> 00:00:2946\nlocation distance are also made here. So, in a register location which registers are used\n\n426\n00:00:2946 --> 00:00:2953\nwhich operand should go into which register etcetera etcetera are all solved in the machine\n\n427\n00:00:2953 --> 00:00:2961\ncode generation phase of the compiler. There are also after machine code generation even\n\n428\n00:00:2961 --> 00:00:2967\nthe code that results is not very efficient. It is possible to improve it little more.\n\n429\n00:00:2968 --> 00:00:2974\nFor example, there are water known as machine dependent optimizations. If you are listed\n\n430\n00:00:2974 --> 00:00:2981\nhere, there are water known as pipel optimizations. So, you analyze sequence of instructions say\n\n431\n00:00:2981 --> 00:00:2989\n10, 15 in what is known as a small window and this window is called as a pipel. And using\n\n432\n00:00:2990 --> 00:00:2993\npreset patterns you replace them with more efficient instructions.\n\n433\n00:00:2994 --> 00:00:3000\nSo, for example, load a comma r 1 store r 1 comma a well you know we are loading and\n\n434\n00:00:3000 --> 00:00:3005\nthen storing immediately. So, this is not necessary. So, you could just say load a comma r 1\n\n435\n00:00:3005 --> 00:00:3011\nget rid of the store instruction. Sometimes there is no need to if you have a code some code\n\n436\n00:00:3011 --> 00:00:3016\nwhere there is a jump instruction and the target is another jump then this jump to jump\n\n437\n00:00:3016 --> 00:00:3022\ncan be eliminated and replaced by a single jump. It is possible to use say increment in\n\n438\n00:00:3022 --> 00:00:3028\ninstead of load and add. So, these are called machine idioms and these form part of people\n\n439\n00:00:3028 --> 00:00:3036\noptimizations. Instruction scheduling that is reordering of instructions to eliminate pipeline\n\n440\n00:00:3036 --> 00:00:3043\ninterlocks and increase parallelism. So, usually we should not make the pipeline get stuck.\n\n441\n00:00:3043 --> 00:00:3050\nThere should be a free flow into the pipeline and out of the pipeline. So, reordering instructions\n\n442\n00:00:3051 --> 00:00:3055\nto make this happen is called instructions scheduling and that is one of the machine dependent\n\n443\n00:00:3055 --> 00:00:3061\noptimizations. And if the basic you know as per programs are what are known as basic\n\n444\n00:00:3061 --> 00:00:3069\nblocks which are single entry, single exit pieces of code. So, if they are very small there\n\n445\n00:00:3069 --> 00:00:3075\nis no way you can increase the parallelism in the program. So, we must make them bigger\n\n446\n00:00:3076 --> 00:00:3080\nand this technique called trace scheduling is used to increase the parallelism available\n\n447\n00:00:3080 --> 00:00:3085\nin the program by increasing the size of basic blocks. And finally, the software pipelining\n\n448\n00:00:3086 --> 00:00:3092\nwhich is too complex to explain overly is a very sophisticated optimization which is\n\n449\n00:00:3092 --> 00:00:3100\nused to increase parallelism in loops. So, that brings us to the end of the overview\n\n450\n00:00:3102 --> 00:00:3107\nand in the next lecture we are going to look at the details of lexical analysis parsing\n\n451\n00:00:3110 --> 00:00:3112\netcetera. Thank you very much.\n\n","output_type":"stream"}]},{"cell_type":"code","source":"len(times)","metadata":{"execution":{"iopub.status.busy":"2023-11-02T10:44:51.389779Z","iopub.execute_input":"2023-11-02T10:44:51.390325Z","iopub.status.idle":"2023-11-02T10:44:51.399891Z","shell.execute_reply.started":"2023-11-02T10:44:51.390291Z","shell.execute_reply":"2023-11-02T10:44:51.399141Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"452"},"metadata":{}}]},{"cell_type":"code","source":"import cv2\nimport os\nfrom datetime import datetime\n\n#path to save images\npath = r'/kaggle/working/'\nos.chdir(path)\n\ni = 0\n\nvideo = cv2.VideoCapture('/kaggle/input/videonptel/videoplayback.mp4')\n\nfps = video.get(cv2.CAP_PROP_FPS)\nprint('frames per second =',fps)","metadata":{"execution":{"iopub.status.busy":"2023-11-02T10:44:51.400906Z","iopub.execute_input":"2023-11-02T10:44:51.401296Z","iopub.status.idle":"2023-11-02T10:44:51.504220Z","shell.execute_reply.started":"2023-11-02T10:44:51.401272Z","shell.execute_reply":"2023-11-02T10:44:51.503149Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"frames per second = 25.0\n","output_type":"stream"}]},{"cell_type":"code","source":"for i in times:\n        \n    frame_id = int(fps*( i))\n    video.set(cv2.CAP_PROP_POS_FRAMES, frame_id)\n    ret, frame = video.read()\n    \n    cv2.imwrite(str(i)+ '.png', frame)","metadata":{"execution":{"iopub.status.busy":"2023-11-02T10:50:17.873378Z","iopub.execute_input":"2023-11-02T10:50:17.873790Z","iopub.status.idle":"2023-11-02T10:50:29.015614Z","shell.execute_reply.started":"2023-11-02T10:50:17.873760Z","shell.execute_reply":"2023-11-02T10:50:29.014673Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stderr","text":"[h264 @ 0x55e98e8b7440] mmco: unref short failure\n","output_type":"stream"}]},{"cell_type":"code","source":"# # reducing frames\n\n# threshold = 20.0\n\n# frame =  cv2.imread(\"/kaggle/working/14.png\")\n# prev = frame\n\n# for i in times:\n    \n#     frame = \"/kaggle/working/\" + str(i) +\".png\"\n    \n#     if ((np.sum(np.absolute(frame - prev))//np.size(frame)) > threshold) :\n        \n#         cv2.imwrite('new' + str(i)+ '.png', frame)\n#         prev= frame\n    \n#     else:\n#         prev = frame\n        \n        \n#  # cv2.read(str(i)+ '.png')\n        ","metadata":{"execution":{"iopub.status.busy":"2023-11-02T10:51:43.529670Z","iopub.execute_input":"2023-11-02T10:51:43.530076Z","iopub.status.idle":"2023-11-02T10:51:43.534903Z","shell.execute_reply.started":"2023-11-02T10:51:43.530046Z","shell.execute_reply":"2023-11-02T10:51:43.534254Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"# select unique images# generate  text from image OCR\n# ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# text recognition\nimport cv2\nimport pytesseract\n\nfor i in times:\n    # read image\n    img = cv2.imread('/kaggle/working/'+str(i)+'.png')\n\n    # configurations\n    config = ('-l eng --oem 1 --psm 3')\n\n    # pytessercat\n    text = pytesseract.image_to_string(img, config=config)\n\n    # print text\n    text = text.split('\\n')\n    print(i)\n    print(text)\n    ","metadata":{"execution":{"iopub.status.busy":"2023-11-02T10:51:46.678917Z","iopub.execute_input":"2023-11-02T10:51:46.679302Z","iopub.status.idle":"2023-11-02T10:59:42.245667Z","shell.execute_reply.started":"2023-11-02T10:51:46.679272Z","shell.execute_reply":"2023-11-02T10:59:42.244478Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"14\n['Principles of Compiler Design', '', 'Lecture - 01', '‘An Overview of a compiler', '', 'Y.N. SRIKANT', 'Computer Science and Automation', 'Indian Institute of Science', 'Bangalore', '\\x0c']\n22\n[' ', '\\x0c']\n31\n['© About the course', '‘© Why should we study compiler design?', '', '‘© Compiler overview with block diagrams', '', ' ', '\\x0c']\n39\n['© About the course', '‘© Why should we study compiler design?', '', '‘© Compiler overview with block diagrams', '', ' ', '\\x0c']\n44\n['© A detailed look at the internals of a compiler', '@ Does not assume any background but is intensive', '© Doing programming assignments and solving theoretical', '', 'problems are both essential', '', '© A compiler is an excellent example of theory translated into', 'practice in a remarkable way', '', ' ', '\\x0c']\n53\n['© A detailed look at the internals of a compiler', '‘@ Does not assume any background but is intensive', '© Doing programming assignments and solving theoretical', '', 'problems are both essential', '', '© A compiler is an excellent example of theory translated into', 'practice in a remarkable way', '', ' ', '\\x0c']\n62\n['© A detailed look at the internals of a compiler', '@ Does not assume any background but is intensive', '© Doing programming assignments and solving theoretical', '', 'problems are both essential', '', '© A compiler is an excellent example of theory translated into', 'practice in a remarkable way', '', ' ', '\\x0c']\n70\n['© A detailed look at the internals of a compiler', '‘@ Does not assume any background but is intensive', '© Doing programming assignments and solving theoretical', '', 'problems are both essential', '', '© A compiler is an excellent example of theory translated into', 'practice in a remarkable way', '', ' ', '\\x0c']\n77\n['© A detailed look at the internals of a compiler', '@ Does not assume any background but is intensive', '© Doing programming assignments and solving theoretical', '', 'problems are both essential', '', '© A compiler is an excellent example of theory translated into', 'practice in a remarkable way', '', ' ', '\\x0c']\n84\n['© A detailed look at the internals of a compiler', '‘@ Does not assume any background but is intensive', '© Doing programming assignments and solving theoretical', '', 'problems are both essential', '', '© A compiler is an excellent example of theory translated into', 'practice in a remarkable way', '', ' ', '\\x0c']\n90\n['© A detailed look at the internals of a compiler', '@ Does not assume any background but is intensive', '© Doing programming assignments and solving theoretical', '', 'problems are both essential', '', '© A compiler is an excellent example of theory translated into', 'practice in a remarkable way', '', ' ', '\\x0c']\n97\n[' ', '\\x0c']\n104\n[' ', '\\x0c']\n113\n[' ', '', '© Compilers are everywhere!', '‘@ Many applications for compiler technology', '« Parsers for HTML in web browser', 'Interpreters for javascriptlash', 'Machine code generation for high level languages', 'Software testing', '', 'Program optimization', 'Malicious code detection', 'Design of new computer architectures', '', '«© Compilrinthe-loop hardware development', '', '« Hardware synthesis: VHDL to RTL translation', 'Compiled simulation', '«© Used to simulate designs writen in VHOL', '«No inlerpretaton of design, hence faster', '\\x0c']\n122\n['© Compilers are everywhere!', '‘@ Many applications for compiler technology', '« Parsers for HTML in web browser', '«@ Interpreters for javascripttiash', '‘¢ Machine code generation for high level languages', '«@ Software testing', '', '«© Program optimization', '«Malicious code detection', '«Design of new computer architectures', '', '«© Compierin-the-4oop hardware development', '', '« Hardware synthesis: VHDL to RTL translation', '© Compiled simulation', '«© Used to simulate designs writen in VHOL', '«No inlerpretaton of design, hence faster', '', ' ', '\\x0c']\n130\n[' ', '', '© Compilers are everywhere!', '‘@ Many applications for compiler technology', '« Parsers for HTML in web browser', '«@ Interpreters for javascripttiash', '‘¢ Machine code generation for high level languages', '«@ Software testing', '', '‘© Program optimization', '«@ Malicious code detection', '« Design of new computer architectures', '«© Compile.in-the-loop hardware development', '‘¢ Hardware synthesis: VHDL to RTL translation', '© Compiled simulation', '«Used to simulate designs writen in VHDL', '«No interpretation of design, hence faster', '\\x0c']\n136\n[' ', '', '© Compilers are everywhere!', '@ Many applications for compiler technology', '« Parsers for HTML in web browser', '«Interpreters for javascriptfash', '‘¢ Machine code generation for high level languages', '«@ Software testing', '', '«# Program optimization', '«@ Malicious code detection', '« Design of new computer architectures', '«© Compile.n-the-loop hardware development', '«¢ Hardware synthesis: VHDL to RTL translation', '‘© Compiled simulation', '«Used to simulate designs writen in VHDL', '«No interpretation of design, hence faster', '\\x0c']\n144\n['© Compilers are everywhere!', '‘@ Many applications for compiler technology', '« Parsers for HTML in web browser', '«@ Interpreters for javascripttlash', '‘¢ Machine code generation for high level languages', '«@ Software testing', '', '« Program optimization', '«Malicious code detection', '« Design of new computer architectures', '«© Compile.in-the-loop hardware development', '«¢ Hardware synthesis: VHDL to RTL translation', '‘© Compiled simulation', '«Used to simulate designs writen in VHDL', '«No inlerpretaton of design, hence fastr', '', ' ', '\\x0c']\n152\n[' ', '', '© Compilers are everywhere!', '‘@ Many applications for compiler technology', '« Parsers for HTML in web browser', '«@ Interpreters for javascripttiash', '‘¢ Machine code generation for high level languages', '«@ Software testing', '', '« Program optimization', '«@ Malicious code detection', '« Design of new computer architectures', '«© Compile.in-te-loop hardware development', '‘¢ Hardware synthesis: VHDL to RTL translation', '‘© Compiled simulation', '«Used to simulate designs writen in VHDL', '«No inlerprtaton of design, hence faster', '\\x0c']\n158\n[' ', '', '© Compilers are everywhere!', '‘© Many applications for compiler technology', '« Parsers for HTML in web browser', '«Interpreters for javascriptfash', '‘¢ Machine code generation for high level languages', '«@ Software testing', '', '« Program optimization', '«@ Malicious code detection', '«¢ Design of new computer architectures', '«© Compile.in-the-loop hardware development', '«¢ Hardware synthesis: VHDL to RTL translation', '‘© Compiled simulation', '«Used to simulate designs writen in VHDL', '«No inlerprtaton of design, hence faster', '\\x0c']\n165\n[' ', '', '© Compilers are everywhere!', '@ Many applications for compiler technology', '« Parsers for HTML in web browser', '«@ Interpreters for javascripttiash', '‘¢ Machine code generation for high level languages', '«@ Software testing', '', '«© Program optimization', '«@ Malicious code detection', '« Design of new computer architectures', '«© Compile.in-the-loop hardware development', '«¢ Hardware synthesis: VHDL to RTL translation', '© Compiled simulation', '«Used to simulate designs writen in VHDL', '«No inlerpretaton of design, hence faster', '\\x0c']\n171\n[' ', '', '© Compilers are everywhere!', '‘@ Many applications for compiler technology', '« Parsers for HTML in web browser', '«@ Interpreters for javascripttlash', '‘¢ Machine code generation for high level languages', '«@ Software testing', '', '« Program optimization', '«@ Malicious code detection', '« Design of new computer architectures', '«© Compile.in.the-loop hardware development', '«¢ Hardware synthesis: VHDL to RTL translation', '‘© Compiled simulation', '«Used to simulate designs writen in VHDL', '«No inlerpretaton of design, hence faster', '\\x0c']\n177\n[' ', '', '© Compilers are everywhere!', '‘@ Many applications for compiler technology', '« Parsers for HTML in web browser', '«Interpreters for javascriptfash', '‘¢ Machine code generation for high level languages', '«@ Software testing', '', '«© Program optimization', '«Malicious code detection', '« Design of new computer architectures', '«© Compile.n-the-loop hardware development', '«¢ Hardware synthesis: VHDL to RTL translation', '‘© Compiled simulation', '«Used to simulate designs writen in VHDL', '«No interpretation of design, hence faster', '\\x0c']\n185\n[' ', '', '© Compilers are everywhere!', '@ Many applications for compiler technology', '« Parsers for HTML in web browser', '«@ Interpreters for javascripttiash', '‘¢ Machine code generation for high level languages', '«@ Software testing', '', '‘© Program optimization', '«@ Malicious code detection', '« Design of new computer architectures', '«© Compile.in-the-loop hardware development', '«¢ Hardware synthesis: VHDL to RTL translation', '‘© Compiled simulation', '«Used to simulate designs writen in VHDL', '«No inlerpretaton of design, hence faster', '\\x0c']\n192\n[' ', '', '‘© Compilers are everywhere!', '‘@ Many applications for compiler technology', '« Parsers for HTML in web browser', '«Interpreters for javascriptfash', '‘¢ Machine code generation for high level languages', '«@ Software testing', '', '‘© Program optimization', '«Malicious code detection', '« Design of new computer architectures', '«© Compile.in.te-loop hardware development', '‘¢ Hardware synthesis: VHDL to RTL translation', '‘© Compiled simulation', '«Used to simulate designs writen in VHDL', '«No inlerpretaton of design, hence faster', '\\x0c']\n198\n[' ', '', '© Compilers are everywhere!', '‘@ Many applications for compiler technology', '« Parsers for HTML in web browser', '« Interpreters for javascriptfash', '‘¢ Machine code generation for high level languages', '«@ Software testing', '', '«© Program optimization', '«Malicious code detection', '« Design of new computer architectures', '«© Compile.in.the-loop hardware development', '‘¢ Hardware synthesis: VHDL to RTL translation', '‘© Compiled simulation', '«Used to simulate designs writen in VHDL', '«No inlerprtaton of design, hence faster', '\\x0c']\n204\n[' ', '', '© Compilers are everywhere!', '@ Many applications for compiler technology', '« Parsers for HTML in web browser', '«Interpreters for javascriptfash', '‘¢ Machine code generation for high level languages', '«@ Software testing', '', '«© Program optimization', '«@ Malicious code detection', '« Design of new computer architectures', '«© Compile.in.te-loop hardware development', '«¢ Hardware synthesis: VHDL to RTL translation', '‘© Compiled simulation', '«Used to simulate designs writen in VHDL', '«No inlerpretaton of design, hence faster', '\\x0c']\n213\n[' ', '', 'We Study Compiler Design’', '', '© Compilers are everywhere!', '‘@ Many applications for compiler technology', '« Parsers for HTML in web browser', '«@ Interpreters for javascripttlash', '‘¢ Machine code generation for high level languages', '«@ Software testing', '«© Program optimization', '«Malicious code detection', '«Design of new computer architectures', '«© Compierin-the-4oop hardware development', '‘¢ Hardware synthesis: VHDL to ATL translation', 'Compiled simulation', '© Used to simulate designs writen in VHOL', '«No inlerprtaton of design, hence faster', '\\x0c']\n217\n['© Compilers are everywhere!', '‘@ Many applications for compiler technology', '« Parsers for HTML in web browser', '«@ Interpreters for javascripttiash', '‘¢ Machine code generation for high level languages', '«@ Software testing', '', '‘© Program optimization', '«Malicious code detection', '« Design of new computer architectures', '«© Compile.in-the loop hardware development', '«¢ Hardware synthesis: VHDL to RTL translation', '© Compiled simulation', '«Used to simulate designs writen in VHDL', '«No inlerprtaton of design, hence faster', '', ' ', '\\x0c']\n224\n[' ', '', '© Compilers are everywhere!', '‘@ Many applications for compiler technology', '« Parsers for HTML in web browser', '«@ Interpreters for javascripttlash', '‘¢ Machine code generation for high level languages', '«@ Software testing', '', '« Program optimization', '«Malicious code detection', '«# Design of new computer architectures', '«© Compiler.in-the loop hardware development', '«¢ Hardware synthesis: VHDL to RTL translation', '‘© Compiled simulation', '«Used to simulate designs writen in VHDL', '«No inlerprtaton of design, hence faster', '\\x0c']\n229\n['© Compilers are everywhere!', '‘@ Many applications for compiler technology', '« Parsers for HTML in web browser', '« Interpreters for javascriptfash', '‘¢ Machine code generation for high level languages', '«@ Software testing', '', '‘© Program optimization', '«Malicious code detection', '« Design of new computer architectures', '«© Compile.in-the-loop hardware development', '‘¢ Hardware synthesis: VHDL to RTL translation', '‘© Compiled simulation', '«Used to simulate designs writen in VHDL', '«No interpretation of design, hence faster', '', ' ', '\\x0c']\n234\n[' ', '', '© Compilers are everywhere!', '‘@ Many applications for compiler technology', '« Parsers for HTML in web browser', '«@ Interpreters for javascripttiash', '‘¢ Machine code generation for high level languages', '«@ Software testing', '', '«© Program optimization', '«@ Malicious code detection', '« Design of new computer architectures', '«© Compiler.n-the-loop hardware development', '«¢ Hardware synthesis: VHDL to RTL translation', '‘© Compiled simulation', '«Used to simulate designs writen in VHDL', '«No inlerprtaton of design, hence faster', '\\x0c']\n243\n['© Compilers are everywhere!', '‘ Many applications for compiler technology', '« Parsers for HTML in web browser', '«@ Interpreters for javascripttiash', '‘¢ Machine code generation for high level languages', '«@ Software testing', '', '‘© Program optimization', '«@ Malicious code detection', '« Design of new computer architectures', '«© Compile.in-te-loop hardware development', '«¢ Hardware synthesis: VHDL to RTL translation', '‘© Compiled simulation', '«Used to simulate designs writen in VHDL', '«No inlerpretaton of design, hence fastr', '', ' ', '\\x0c']\n251\n['© Compilers are everywhere!', '‘@ Many applications for compiler technology', '« Parsers for HTML in web browser', '«@ Interpreters for javascripttiash', '‘¢ Machine code generation for high level languages', '«@ Software testing', '', '© Program optimization', '«@ Malicious code detection', '«¢ Design of new computer architectures', '«© Compile.in-the-loop hardware development', '«¢ Hardware synthesis: VHDL to RTL translation', '‘© Compiled simulation', '«Used to simulate designs writen in VHDL', '«No inlerprtaton of design, hence faster', '', ' ', '\\x0c']\n258\n['© Compilers are everywhere!', '‘ Many applications for compiler technology', '« Parsers for HTML in web browser', '«@ Interpreters for javascripttiash', '‘¢ Machine code generation for high level languages', '«@ Software testing', '', '«@ Program optimization', '«@ Malicious code detection', '« Design of new computer architectures', '«© Compile.in-the loop hardware development', '«¢ Hardware synthesis: VHDL to RTL translation', '‘© Compiled simulation', '«Used to simulate designs writen in VHDL', '«No inlerprtaton of design, hence fast', '', ' ', '\\x0c']\n265\n[' ', '', '© Compilers are everywhere!', '‘@ Many applications for compiler technology', '« Parsers for HTML in web browser', '«@ Interpreters for javascripttiash', '‘¢ Machine code generation for high level languages', '«@ Software testing', '', '« Program optimization', '«@ Malicious code detection', '« Design of new computer architectures', '«© Compiler.in-the-loop hardware development', '«¢ Hardware synthesis: VHDL to RTL translation', '‘© Compiled simulation', '«Used to simulate designs witen in VHDL', '«No inlerprtaton of design, hence faster', '\\x0c']\n273\n[' ', '', '© Compilers are everywhere!', '@ Many applications for compiler technology', '« Parsers for HTML in web browser', '«Interpreters for javascriptfash', '‘¢ Machine code generation for high level languages', '«@ Software testing', '', '«© Program optimization', '«@ Malicious code detection', '« Design of new computer architectures', '«© Compile.in.the loop hardware development', '«¢ Hardware synthesis: VHDL to RTL translation', '‘© Compiled simulation', '«Used to simulate designs writen in VHDL', '«No interpretation of design, hence faster', '\\x0c']\n280\n[' ', '', '‘© Compilers are everywhere!', '@ Many applications for compiler technology', '« Parsers for HTML in web browser', '«Interpreters for javascriptfash', '‘¢ Machine code generation for high level languages', '«@ Software testing', '', '« Program optimization', '«Malicious code detection', '« Design of new computer architectures', '«© Compile.in.the loop hardware development', '«¢ Hardware synthesis: VHDL to RTL translation', '© Compiled simulation', '«Used to simulate designs writen in VHDL', '«No inlerprtaton of design, hence faster', '\\x0c']\n287\n['© Compilers are everywhere!', '@ Many applications for compiler technology', '« Parsers for HTML in web browser', '«Interpreters for javascriptfash', '‘¢ Machine code generation for high level languages', '«@ Software testing', '', '«¢ Program optimization', '«@ Malicious code detection', '« Design of new computer architectures', '«© Compile.in-te-loop hardware development', '«¢ Hardware synthesis: VHDL to RTL translation', '‘© Compiled simulation', '«Used to simulate designs writen in VHDL', '«No inlerprtaton of design, hence faster', '', ' ', '\\x0c']\n293\n['© Compilers are everywhere!', '@ Many applications for compiler technology', '« Parsers for HTML in web browser', '«@ Interpreters for javascripttlash', '‘¢ Machine code generation for high level languages', '«@ Software testing', '', '«© Program optimization', '«Malicious code detection', '« Design of new computer architectures', '«© Compile.n-te-loop hardware development', '«¢ Hardware synthesis: VHDL to RTL translation', '‘© Compiled simulation', '«Used to simulate designs writen in VHDL', '«No inlerprtaton of design, hence faster', '', ' ', '\\x0c']\n302\n[' ', '', 'We Study Compiler Design’', '', '© Compilers are everywhere!', '@ Many applications for compiler technology', '« Parsers for HTML in web browser', '« Interpreters for javascriptfash', '‘¢ Machine code generation for high level languages', '«@ Software testing', '« Program optimization', '«@ Malicious code detection', '«Design of new computer architectures', '«© Compierin-the-loop hardware development', '« Hardware synthesis: VHDL to TL translation', 'Compiled simulation', '«© Used to simulate designs writen in VHOL', '«No interpretation of design, hence faster', '\\x0c']\n308\n['‘© Compilers are everywhere!', '‘ Many applications for compiler technology', '« Parsers for HTML in web browser', '«@ Interpreters for javascripttiash', '‘¢ Machine code generation for high level languages', '«Software testing', '', '‘© Program optimization', '«@ Malicious code detection', '«# Design of new computer architectures', '«© Compiler.in.the-loop hardware development', '«¢ Hardware synthesis: VHDL to RTL translation', '© Compiled simulation', '«Used to simulate designs writen in VHDL', '«No interpretation of design, hence faster', '', ' ', '\\x0c']\n314\n[' ', '', '© Compilers are everywhere!', '@ Many applications for compiler technology', '« Parsers for HTML in web browser', '«Interpreters for javascriptfash', '‘¢ Machine code generation for high level languages', '«@ Software testing', '', '« Program optimization', '« Malicious code detection', '« Design of new computer architectures', '«© Compile.n-the loop hardware development', '«¢ Hardware synthesis: VHDL to RTL translation', '‘© Compiled simulation', '«Used to simulate designs writen in VHDL', '«No inlerprtaton of design, hence faster', '\\x0c']\n320\n['© Compilers are everywhere!', '@ Many applications for compiler technology', '« Parsers for HTML in web browser', '«@ Interpreters for javascripttiash', '‘¢ Machine code generation for high level languages', '«@ Software testing', '', '‘© Program optimization', '«@ Malicious code detection', '« Design of new computer architectures', '«© Compile.in-the-loop hardware development', '«¢ Hardware synthesis: VHDL to RTL translation', '© Compiled simulation', '«Used to simulate designs writen in VHDL', '«No interpretation of design, hence faster', '', ' ', '\\x0c']\n328\n['About the Complexity of Compiler Technology', '', '© A compile is possibly the most complex system software', 'and writing it is a substantial exercise in software', 'engineering', '', '© The complexity arises from the fact that its required to', \"map a programmer's requirements (in a HLL program) to\", 'architectural details', '', '© Ituses algorithms and techniques from a very large', 'number of areas in computer science', '', '© Translates intricate theory into practice - enables tool', 'building', '', ' ', '\\x0c']\n337\n[' A.compiler is possibly the most complex system software', 'and writing it is a substantial exercise in software', 'engineering', '', '@ The complexity arises from the fact that its required to', 'map a programmers requirements (in a HLL program) to', '', 'architectural details', '', '@ Ituses algorithms and techniques from a very large', 'number of areas in computer science', '', '© Translates intricate theory into practice - enables tool', 'building', '', ' ', '\\x0c']\n344\n['‘ Acompiler is possibly the most complex system software', 'and writing it is a substantial exercise in software', 'engineering', '', '‘@ The complexity arises from the fact that itis required to', \"map a programmer's requirements (in a HLL program) to\", '', 'architectural details', '', '@ Ituses algorithms and techniques from a very large', 'number of areas in computer science', '', '© Translates intricate theory into practice - enables tool', 'building', '', ' ', '\\x0c']\n352\n['© A compile is possibly the most complex system software', 'and writing it is a substantial exercise in software', 'engineering', '', '@ The complexity arises from the fact that its required to', \"map a programmer's requirements (in a HLL program) to\", '', 'architectural details', '', '@ Ituses algorithms and techniques from a very large', 'number of areas in computer science', '', '© Translates intricate theory into practice - enables tool', 'building', '', ' ', '\\x0c']\n360\n[' A.compiler is possibly the most complex system software', 'and writing it is a substantial exercise in software', 'engineering', '', '@ The complexity arises from the fact that its required to', \"map a programmer's requirements (in a HLL program) to\", '', 'architectural details', '', '@ Ituses algorithms and techniques from a very large', 'number of areas in computer science', '', '© Translates intricate theory into practice - enables tool', 'building', '', ' ', '\\x0c']\n367\n['A compiler is possibly the most complex system software', 'and writing itis a substantial exercise in software', 'engineering', '', '‘@ The complexity arises from the fact that itis required to', \"map a programmer's requirements (in a HLL program) to\", '', 'architectural details', '', '@ Ituses algorithms and techniques from a very large', 'number of areas in computer science', '', '© Translates intricate theory into practice - enables tool', 'building', '', ' ', '\\x0c']\n374\n['@ A-compiler is possibly the most complex system software', 'and writing itis a substantial exercise in software', 'engineering', '', '‘@ The complexity arises from the fact that itis required to', \"map a programmer's requirements (in a HLL program) to\", '', 'architectural details', '', '@ Ituses algorithms and techniques from a very large', 'number of areas in computer science', '', '© Translates intricate theory into practice - enables tool', 'building', '', ' ', '\\x0c']\n379\n['@ A.compiler is possibly the most complex system software', 'and writing itis a substantial exercise in software', 'engineering', '', '‘@ The complexity arises from the fact that itis required to', \"map a programmer's requirements (in a HLL program) to\", '', 'architectural details', '', '@ It uses algorithms and techniques from a very large', 'number of areas in computer science', '', '© Translates intricate theory into practice - enables tool', 'building', '', ' ', '\\x0c']\n386\n['© A compile is possibly the most complex system software', 'and writing it is a substantial exercise in software', 'engineering', '', '@ The complexity arises from the fact that its required to', \"map a programmer's requirements (in a HLL program) to\", '', 'architectural details', '', '© Ituses algorithms and techniques from a very large', 'number of areas in computer science', '', '© Translates intricate theory into practice - enables tool', 'building', '', ' ', '\\x0c']\n391\n['‘@ A.compiler is possibly the most complex system software', 'and writing it is a substantial exercise in software', 'engineering', '', '‘@ The complexity arises from the fact that itis required to', \"map a programmer's requirements (in a HLL program) to\", '', 'architectural details', '', '@ Ituses algorithms and techniques from a very large', 'number of areas in computer science', '', '© Translates intricate theory into practice - enables tool', 'building', '', ' ', '\\x0c']\n397\n['@ A compiler is possibly the most complex system software', 'and writing it is a substantial exercise in software', 'engineering', '', '@ The complexity arises from the fact that its required to', \"map a programmer's requirements (in a HLL program) to\", '', 'architectural details', '', '@ Ituses algorithms and techniques from a very large', 'number of areas in computer science', '', '© Translates intricate theory into practice - enables tool', 'building', '', ' ', '\\x0c']\n404\n['@ A.compiler is possibly the most complex system software', 'and writing it is a substantial exercise in software', 'engineering', '', '‘@ The complexity arises from the fact that itis required to', \"map a programmer's requirements (in a HLL program) to\", '', 'architectural details', '', '@ Ituses algorithms and techniques from a very large', 'number of areas in computer science', '', '© Translates intricate theory into practice - enables tool', 'building', '', ' ', '\\x0c']\n408\n['@ A compiler is possibly the most complex system software', 'and writing it is a substantial exercise in software', 'engineering', '', '‘@ The complexity arises from the fact that itis required to', \"map a programmer's requirements (in a HLL program) to\", '', 'architectural details', '', '@ Ituses algorithms and techniques from a very large', 'number of areas in computer science', '', '© Translates intricate theory into practice - enables tool', 'building', '', ' ', '\\x0c']\n415\n['@ A-compiler is possibly the most complex system software', 'and writing itis a substantial exercise in software', 'engineering', '', '‘@ The complexity arises from the fact that itis required to', \"map a programmer's requirements (in a HLL program) to\", '', 'architectural details', '', '@ Ituses algorithms and techniques from a very large', 'number of areas in computer science', '', '© Translates intricate theory into practice - enables tool', 'building', '', ' ', '\\x0c']\n421\n['A compiler is possibly the most complex system software', 'and writing itis a substantial exercise in software', 'engineering', '', '‘@ The complexity arises from the fact that itis required to', \"map a programmer's requirements (in a HLL program) to\", '', 'architectural details', '', '@ Ituses algorithms and techniques from a very large', 'number of areas in computer science', '', '© Translates intricate theory into practice - enables tool', 'building', '', ' ', '\\x0c']\n429\n['@ A.compiler is possibly the most complex system software', 'and writing it is a substantial exercise in software', 'engineering', '', '@ The complexity arises from the fact that its required to', 'map a programmers requirements (in a HLL program) to', '', 'architectural details', '', '@ Ituses algorithms and techniques from a very large', 'number of areas in computer science', '', '© Translates intricate theory into practice - enables tool', 'building', '', ' ', '\\x0c']\n437\n['@ A.compiler is possibly the most complex system software', 'and writing it is a substantial exercise in software', 'engineering', '', '‘@ The complexity arises from the fact that itis required to', \"map a programmer's requirements (in a HLL program) to\", '', 'architectural details', '', '@ Ituses algorithms and techniques from a very large', 'number of areas in computer science', '', '© Translates intricate theory into practice - enables tool', 'building', '', ' ', '\\x0c']\n443\n['@ A-compiler is possibly the most complex system software', 'and writing it is a substantial exercise in software', 'engineering', '', '@ The complexity arises from the fact that its required to', \"map a programmer's requirements (in a HLL program) to\", '', 'architectural details', '', '@ Ituses algorithms and techniques from a very large', 'number of areas in computer science', '', '© Translates intricate theory into practice - enables tool', 'building', '', ' ', '\\x0c']\n449\n['@ A compiler is possibly the most complex system software', 'and writing itis a substantial exercise in software', 'engineering', '', '‘@ The complexity arises from the fact that itis required to', \"map a programmer's requirements (in a HLL program) to\", '', 'architectural details', '', '@ It uses algorithms and techniques from a very large', 'number of areas in computer science', '', '© Translates intricate theory into practice - enables tool', 'building', '', ' ', '\\x0c']\n456\n['@ A-compiler is possibly the most complex system software', 'and writing it is a substantial exercise in software', 'engineering', '', '‘@ The complexity arises from the fact that itis required to', \"map a programmer's requirements (in a HLL program) to\", '', 'architectural details', '', '@ It uses algorithms and techniques from a very large', 'number of areas in computer science', '', '© Translates intricate theory into practice - enables tool', 'building', '', ' ', '\\x0c']\n464\n['@ Draws results from mathematical logic, lattice theory, linear', 'algebra, probability, etc.', '« type checking, static analysis, dependence analysis and', 'loop parallelization, cache analysis, etc.', '', '‘© Makes practical application of', '«# Greedy algorithms - register allocation', '«© Heuristic search - ist scheduling', '', '«© Graph algorithms - dead code elimination, register', 'allocation', '', '«¢ Dynamic programming - instruction selection', '', '«¢ Optimization techniques - instruction scheduling', '', '¢ Finite automata - lexical analysis', '', '« Pushdown automata - parsing', '', '« Fixed point algorithms - data-low aralysis', '', '«© Complex data structures - symbol tables, par', 'dependence graphs', '', '‘© Computer architecture - machine code gen', '', ' ', '\\x0c']\n470\n['@ Draws results from mathematical logic, lattice theory, linear', 'algebra, probability etc.', '« type checking, static analysis, dependence analysis and', 'loop parallelization, cache analysis, etc.', '© Makes practical application of', '«© Greedy algorithms - register allocation', '« Heuristic search ist scheduling', '', '« Graph algorithms - dead code elimination, register', 'allocation', '', '‘© Dynamic programming - instruction selection', '', '‘© Optimization techniques - instruction scheduling', '', '« Finite automata - lexical analysis', '', '« Pushdown automata - parsing', '', '« Fixed point algorithms - data-low analysis', '', '‘© Complex data structures - symbol tables, par', 'dependence graphs', '', '‘© Computer architecture - machine code gene', '', ' ', '\\x0c']\n477\n['© Draws results from mathematical logic, lattice theory, linear', 'algebra, probability, etc.', '« type checking, static analysis, dependence analysis and', 'loop parallelization, cache analysis, etc.', '© Makes practical application of', '« Greedy algorithms - register allocation', '«¢ Heuristic search - lst scheduling', '', '«© Graph algorithms - dead code elimination, register', 'allocation', '', '‘¢ Dynamic programming - instruction selection', '', '‘© Optimization techniques - instruction scheduling', '', '« Finite automata - lexical analysis', '', '« Pushdown automata - parsing', '', '« Fixed point algorithms - data-low analysis', '', '© Complex data structures - symbol tables, par', 'dependence graphs', '', '«© Computer architecture - machine code gen', '', ' ', '\\x0c']\n484\n['@ Draws results from mathematical logic, lattice theory, linear', 'algebra, probability, etc.', '« type checking, static analysis, dependence analysis and', 'loop parallelization, cache analysis, etc.', '© Makes practical application of', '«© Greedy algorithms - register allocation', '«© Heuristic search - ist scheduling', '', '«© Graph algorithms - dead code elimination, register', 'allocation', '', '‘¢ Dynamic programming - instruction selection', '', '‘© Optimization techniques - instruction scheduling', '', '¢ Finite automata - lexical analysis', '', '« Pushdown automata - parsing', '', '« Fixed point algorithms - data-low analysis', '', '«© Complex data structures - symbol tables, par', 'dependence graphs', '', '«© Computer architecture - machine code gen', '', ' ', '\\x0c']\n491\n['ie Nature of Compiler Algorithms', '', '© Draws results trom mathematical logic, lattice theory, linear', 'algebra, probability, etc.', '« type checking, static analysis, dependence analysis and', 'loop parallelization, cache analysis, etc.', '© Makes practical application of', '« Greedy algorithms - register allocation', '« Heuristic search - ist scheduling', '«© Graph algorithms - dead code elimination, register', 'allocation', '«¢ Dynamic programming - instruction selection', '‘© Optimization techniques - instruction scheduling', '« Finite automata - lexical analysis', '« Pushdown automata - parsing', '« Fixed point algorithms - data-low analysis', '«© Complex data structures - symbol tables, pa', 'dependence graphs', '‘© Computer architecture - machine code gene', '', ' ', '\\x0c']\n497\n['© Draws results from mathematical logic, lattice theory, linear', 'algebra, probability, etc.', '« type checking, static analysis, dependence analysis and', 'loop parallelization, cache analysis, etc.', '© Makes practical application of', '«# Greedy algorithms - register allocation', '« Heuristic search - ist scheduling', '', '«© Graph algorithms - dead code elimination, register', 'allocation', '', '‘© Dynamic programming - instruction selection', '', '‘© Optimization techniques - instruction scheduling', '', '« Finite automata - lexical analysis', '', '« Pushdown automata - parsing', '', '« Fixed point algorithms - data-low analysis', '', '‘© Complex data structures - symbol tables, par', 'dependence graphs', '', '‘© Computer architecture - machine code gene\"', '', ' ', '\\x0c']\n504\n['ie Nature of Compiler Algorithms', '', '@ Draws results from mathematical logic, lattice theory, linear', 'algebra, probability, etc.', '« type checking, static analysis, dependence analysis and', 'loop parallelization, cache analysis, etc.', '© Makes practical application of', '«© Greedy algorithms - register allocation', '«© Heuristic search - ist scheduling', '«© Graph algorithms - dead code elimination, register', 'allocation', '«¢ Dynamic programming - instruction selection', '«¢ Optimization techniques - instruction scheduling', '« Finite automata - lexical analysis', '« Pushdown automata - parsing', '« Fixed point algorithms - data-low analysis', '© Complex data structures - symbol tables, par', 'dependence graphs', '‘© Computer architecture - machine code gener-', '', ' ', '\\x0c']\n510\n['About the Nature of Compiler Algorithms:', '', '@ Draws results from mathematical logic, lattice theory, linear', 'algebra, probability, etc.', '« type checking, static analysis, dependence analysis and', 'loop parallelization, cache analysis, etc.', '', '© Makes practical application of', '« Greedy algorithms - register allocation', '«¢ Heuristic search - lst scheduling', '', '«© Graph algorithms - dead code elimination, register', 'allocation', '', '‘¢ Dynamic programming - instruction selection', '', '‘© Optimization techniques - instruction scheduling', '', '« Finite automata - lexical analysis', '', '« Pushdown automata - parsing', '', '« Fixed point algorithms - data-low analysis', '', '© Complex data structures - symbol tables, par', 'dependence graphs', '', '‘© Computer architecture - machine code gener-', '', ' ', '\\x0c']\n518\n['ie Nature of Compiler Algori', '', '© Draws results trom mathematical logic, lattice theory, linear', 'algebra, probability, etc.', '« type checking, static analysis, dependence analysis and', 'loop parallelization, cache analysis, etc.', '© Makes practical application of', '«© Greedy algorithms - register allocation', '«© Heuristic search - ist scheduling', '«© Graph algorithms - dead code elimination, register', 'allocation', '«¢ Dynamic programming - instruction selection', '«© Optimization techniques - instruction scheduling', '¢ Finite automata - lexical analysis', '« Pushdown automata - parsing', '« Fixed point algorithms - data-low analysis', '«© Complex data structures - symbol tables, pa', 'dependence graphs', '‘© Computer architecture - machine code gene', '', ' ', '\\x0c']\n524\n['ie Nature of Compiler Algorithms', '', '@ Draws results from mathematical logic, lattice theory, linear', 'algebra, probability, etc.', '« type checking, static analysis, dependence analysis and', 'loop parallelization, cache analysis, etc.', '© Makes practical application of', '«© Greedy algorithms - register allocation', '« Heuristic search ist scheduling', '«© Graph algorithms - dead code elimination, register', 'allocation', '«¢ Dynamic programming - instruction selection', '« Optimization techniques - instruction scheduling', '« Finite automata - lexical analysis', '« Pushdown automata - parsing', '« Fixed point algorithms - data-low analysis', '«© Complex data structures - symbol tables, pa', 'dependence graphs', \"«© Computer architecture - machine code gene '\", '', ' ', '\\x0c']\n530\n['@ Draws results from mathematical logic, lattice theory, linear', 'algebra, probability, etc.', '« type checking, static analysis, dependence analysis and', 'loop parallelization, cache analysis, etc.', '© Makes practical application of', '«# Greedy algorithms - register allocation', '« Heuristic search - ist scheduling', '', '«© Graph algorithms - dead code elimination, register', 'allocation', '', '‘¢ Dynamic programming - instruction selection', '', '‘© Optimization techniques - instruction scheduling', '', '« Finite automata - lexical analysis', '', '« Pushdown automata - parsing', '', '« Fixed point algorithms - data-low analysis', '', '‘© Complex data structures - symbol tables, pat', 'dependence graphs', '', '«© Computer architecture - machine code gene', '', ' ', '\\x0c']\n539\n['ie Nature of Compiler Algor', '', '© Draws results from mathematical logic, lattice theory, linear', 'algebra, probability, etc.', '« type checking, static analysis, dependence analysis and', 'loop parallelization, cache analysis, etc.', '© Makes practical application of', '© Greedy algorithms - register allocation', '«¢ Heuristic search - list scheduling', '«© Graph algorithms - dead code elimination, register', 'allocation', '‘¢ Dynamic programming - instruction selection', '‘© Optimization techniques - instruction scheduling', '¢ Finite automata - lexical analysis', '« Pushdown automata - parsing', '« Fixed point algorithms - data-low analysis', '‘© Complex data structures - symbol tables, par', 'dependence graphs', '«© Computer architecture - machine code gen', '', ' ', '\\x0c']\n545\n['@ Draws results from mathematical logic, lattice theory, linear', 'algebra, probability, etc.', '« type checking, static analysis, dependence analysis and', 'loop parallelization, cache analysis, etc.', '© Makes practical application of', '© Greedy algorithms - register allocation', '« Heuristic search - ist scheduling', '', '«© Graph algorithms - dead code elimination, register', 'allocation', '', '‘¢ Dynamic programming - instruction selection', '', '‘© Optimization techniques - instruction scheduling', '', '« Finite automata - lexical analysis', '', '« Pushdown automata - parsing', '', '« Fixed point algorithms - data-low analysis', '', '‘© Complex data structures - symbol tables, pa', 'dependence graphs', '', '‘© Computer architecture - machine code gene\"', '', ' ', '\\x0c']\n553\n['@ Draws results from mathematical logic, lattice theory, linear', 'algebra, probability, etc.', '« type checking, static analysis, dependence analysis and', 'loop parallelization, cache analysis, etc.', '‘© Makes practical application of', '«© Greedy algorithms - register allocation', '« Heuristic search - ist scheduling', '', '« Graph algorithms - dead code elimination, register', 'allocation', '', '‘¢ Dynamic programming - instruction selection', '', '‘© Optimization techniques - instruction scheduling', '', '«Finite automata - lexical analysis', '', '« Pushdown automata - parsing', '', '« Fixed point algorithms - data-low analysis', '', '‘© Complex data structures - symbol tables, par', 'dependence graphs', '', '«© Computer architecture - machine code gener=', '', ' ', '\\x0c']\n558\n['@ Draws results from mathematical logic, lattice theory, linear', 'algebra, probability, etc.', '« type checking, static analysis, dependence analysis and', 'loop parallelization, cache analysis, etc.', '© Makes practical application of', '«# Greedy algorithms - register allocation', '« Heuristic search - ist scheduling', '', '«© Graph algorithms - dead code elimination, register', 'allocation', '', '‘¢ Dynamic programming - instruction selection', '', '‘© Optimization techniques - instruction scheduling', '', '« Finite automata - lexical analysis', '', '« Pushdown automata - parsing', '', '« Fixed point algorithms - data-low analysis', '', '‘© Complex data structures - symbol tables, paf', 'dependence graphs', '', '‘© Computer architecture - machine code gene', '', ' ', '\\x0c']\n565\n['@ Draws results from mathematical logic, lattice theory, linear', 'algebra, probability, etc.', '« type checking, static analysis, dependence analysis and', 'loop parallelization, cache analysis, etc.', '© Makes practical application of', '«© Greedy algorithms - register allocation', '«© Heuristic search - ist scheduling', '', '«© Graph algorithms - dead code elimination, register', 'allocation', '', '‘¢ Dynamic programming - instruction selection', '', '‘© Optimization techniques - instruction scheduling', '', '« Finite automata - lexical analysis', '', '« Pushdown automata - parsing', '', '« Fixed point algorithms - data-low analysis', '', '‘© Complex data structures - symbol tables, pat', 'dependence graphs', '', '‘© Computer architecture - machine code gene', '', ' ', '\\x0c']\n570\n['ie Nature of Compiler Algorithms', '', '© Draws results from mathematical logic, lattice theory, linear', 'algebra, probability, etc.', '« type checking, static analysis, dependence analysis and', 'loop parallelization, cache analysis, etc.', '© Makes practical application of', '«# Greedy algorithms - register allocation', '«© Heuristic search - ist scheduling', '«© Graph algorithms - dead code elimination, register', 'allocation', '«¢ Dynamic programming - instruction selection', '‘© Optimization techniques - instruction scheduling', '« Finite automata - lexical analysis', '« Pushdown automata - parsing', '« Fixed point algorithms - data-low analysis', '«© Complex data structures - symbol tables, pa', 'dependence graphs', '‘© Computer architecture - machine code gene’ |', '', ' ', '\\x0c']\n577\n['@ Draws results from mathematical logic, lattice theory, linear', 'algebra, probability, etc.', '« type checking, static analysis, dependence analysis and', 'loop parallelization, cache analysis, etc.', '', '© Makes practical application of', '«© Greedy algorithms - register allocation', '«¢ Heuristic search - lst scheduling', '«© Graph algorithms - dead code elimination, register', '', 'allocation', '', '«¢ Dynamic programming - instruction selection', '', '«© Optimization techniques - instruction scheduling', '', '« Finite automata - lexical analysis', '', '« Pushdown automata - parsing', '', '« Fixed point algorithms - data-low analysis', '', '«© Complex data structures - symbol tables, parse trees, data', 'dependence graphs', '', '‘© Computer architecture - machine code generation', '', ' ', '\\x0c']\n582\n['@ Draws results from mathematical logic, lattice theory, linear', 'algebra, probability, etc.', '« type checking, static analysis, dependence analysis and', 'loop parallelization, cache analysis, etc.', '', '‘© Makes practical application of', '‘© Greedy algorithms - register allocation', '«© Heuristic search - ist scheduling', '', '«© Graph algorithms - dead code elimination, register', 'allocation', '', '‘¢ Dynamic programming - instruction selection', '', '‘© Optimization techniques - instruction scheduling', '', '« Finite automata - lexical analysis', '', '« Pushdown automata - parsing', '', '« Fixed point algorithms - data-low analysis', '', '‘© Complex data structures - symbol tables, parse trees, data,', 'dependence graphs', '', '‘© Computer architecture - machine code generation', '', ' ', '\\x0c']\n589\n['@ Draws results from mathematical logic, lattice theory, linear', 'algebra, probability, etc.', '« type checking, static analysis, dependence analysis and', 'loop parallelization, cache analysis, etc.', '© Makes practical application of', '«© Greedy algorithms - register allocation', '« Heuristic search - ist scheduling', '', '‘© Graph algorithms - dead code elimination, register', 'allocation', '', '«¢ Dynamic programming - instruction selection', '', '‘© Optimization techniques - instruction scheduling', '', '« Finite automata - lexical analysis', '', '« Pushdown automata - parsing', '', '« Fixed point algorithms - data-low analysis', '', '«© Complex data structures - symbol tables, parse trees, data', 'dependence graphs', '', '‘© Computer architecture - machine code generation', '', ' ', '\\x0c']\n595\n['@ Draws results from mathematical logic, lattice theory, linear', 'algebra, probability, etc.', '« type checking, static analysis, dependence analysis and', 'loop parallelization, cache analysis, etc.', '', '‘© Makes practical application of', '«© Greedy algorithms - register allocation', '«© Heuristic search - ist scheduling', '', '«© Graph algorithms - dead code elimination, register', 'allocation', '', '‘¢ Dynamic programming - instruction selection', '', '‘© Optimization techniques - instruction scheduling', '', '« Finite automata - lexical analysis', '', '« Pushdown automata - parsing', '', '« Fixed point algorithms - data-flow analysis', '', '‘© Complex data structures - symbol tables, parse trees, data,', 'dependence graphs', '', '‘© Computer architecture - machine code generation', '', ' ', '\\x0c']\n605\n['Parsing Techniques', '', '@ Assembler implementation', '', '© Online text searching (GREP. AWK) and word processing', '© Website filtering', '', '‘© Command language interpreters', '', '© Scripting language interpretation (Unix shell, Perl, Python)', 'XML parsing and document tree construction', '', '@ Database query interpreters', '', ' ', '\\x0c']\n610\n['Parsing Techniques', '', '@ Assembler implementation', '', '© Online text searching (GREP. AWK) and word processing', '© Website filtering', '', '‘© Command language interpreters', '', '© Scripting language interpretation (Unix shell, Perl, Python)', 'XML parsing and document tree construction', '', '‘@ Database query interpreters', '', ' ', '\\x0c']\n618\n['Parsing Techniques', '', '@ Assembler implementation', '', '© Online text searching (GREP. AWK) and word processing', '© Website filtering', '', '© Command language interpreters', '', '© Scripting language interpretation (Unix shell, Perl, Python)', 'XML parsing and document tree construction', '', '‘@ Database query interpreters', '', ' ', '\\x0c']\n623\n['@ Assembler implementation', '', '© Online text searching (GREP, AWK) and word processing', '© Website filtering', '', '© Command language interpreters', '', '© Scripting language interpretation (Unix shell, Perl, Python)', '@ XML parsing and document tree construction', '@ Database query interpreters', '', ' ', '\\x0c']\n631\n['@ Assembler implementation', '', '© Online text searching (GREP. AWK) and word processing', '© Website filtering', '', '‘© Command language interpreters', '', '© Scripting language interpretation (Unix shell, Perl, Python)', 'XML parsing and document tree construction', '@ Database query interpreters', '', ' ', '\\x0c']\n637\n['Parsing Techniques', '', '@ Assembler implementation', '', '© Online text searching (GREP. AWK) and word processing', '© Website filtering', '', '‘© Command language interpreters', '', '© Scripting language interpretation (Unix shell, Perl, Python)', 'XML parsing and document tree construction', '', '‘@ Database query interpreters', '', ' ', '\\x0c']\n645\n['Parsing Techniques', '', '@ Assembler implementation', '', '© Online text searching (GREP. AWK) and word processing', '© Website filtering', '', '© Command language interpreters', '', '© Scripting language interpretation (Unix shell, Perl, Python)', 'XML parsing and document tree construction', '', '‘@ Database query interpreters', '', ' ', '\\x0c']\n651\n['Parsing Techniques', '', '@ Assembler implementation', '', '© Online text searching (GREP. AWK) and word processing', '© Website filtering', '', '‘© Command language interpreters', '', '© Scripting language interpretation (Unix shell, Perl, Python)', 'XML parsing and document tree construction', '', '‘@ Database query interpreters', '', ' ', '\\x0c']\n655\n['Parsing Techniques', '', '@ Assembler implementation', '', '© Online text searching (GREP. AWK) and word processing', '© Website filtering', '', '© Command language interpreters', '', '© Scripting language interpretation (Unix shell, Perl, Python)', '@ XML parsing and document tree construction', '', '‘@ Database query interpreters', '', ' ', '\\x0c']\n664\n['Program Analysis Techniques', '', '© Converting a sequential loop to a parallel loop', '© Program analysis to determine it programs are data-race', 'free', '© Profiling programs to determine busy regions', '@ Program slicing', '© Data-flow analysis approach to software testing', '«© Uncovering errors along all paths', '', '@ Dereferencing null pointers', ' Butfer overflows and memory leaks', '', '© Worst Case Execution Time (WCET) estimati', 'energy analysis', '', ' ', '\\x0c']\n672\n['Program Analysis Techniques', '', '© Converting a sequential loop to a parallel loop', '@ Program analysis to determine if programs are data-race', 'free', '@ Profiling programs to determine busy regions', '@ Program slicing', '© Data-flow analysis approach to software testing', '«¢ Uncovering errors along all paths', '', '@ Dereferencing null pointers', ' Butfer overflows and memory leaks', '', '@ Worst Case Execution Time (WCET) estimatio', 'energy analysis', '', ' ', '\\x0c']\n677\n['ogram Analysis Techniques', '', '© Converting a sequential loop to a parallel loop', '', '@ Program analysis to determine it programs are data-race', 'free', '', '@ Profiling programs to determine busy regions', '© Program slicing', '', '© Data-flow analysis approach to software testing', '«© Uncovering errors along all paths', '«@ Dereterencing nul pointers', '«Butter overfiows and memory leaks', '', '@ Worst Case Execution Time (WCET) estimatio', 'energy analysis', '', ' ', '\\x0c']\n685\n['Program Analysis Techniques', '', '© Converting a sequential loop to a parallel loop', '@ Program analysis to determine if programs are data-race', 'free', '@ Profiling programs to determine busy regions', '@ Program slicing', '© Data-flow analysis approach to software testing', '«¢ Uncovering errors along all paths', '', '@ Dereferencing null pointers', ' Butfer overflows and memory leaks', '', '@ Worst Case Execution Time (WCET) estimati', 'energy analysis', '', ' ', '\\x0c']\n691\n['Program Analysis Techniques', '', '© Converting a sequential loop to a parallel loop', '@ Program analysis to determine if programs are data-race', 'free', '@ Profiling programs to determine busy regions', '© Program slicing', '© Data-flow analysis approach to software testing', '«¢ Uncovering errors along all paths', '', '@ Dereferencing null pointers', ' Butfer overflows and memory leaks', '', '@ Worst Case Execution Time (WCET) estimatio', 'energy analysis', '', ' ', '\\x0c']\n697\n['Program Analysis Techniques', '', '@ Converting a sequential loop to a parallel loop', '@ Program analysis to determine if programs are data-race', 'free', '@ Profiling programs to determine busy regions', '© Program slicing', '© Data-flow analysis approach to software testing', '«¢ Uncovering errors along all paths', '', '@ Dereferencing null pointers', ' Butfer overflows and memory leaks', '', '@ Worst Case Execution Time (WCET) estimatio', 'energy analysis', '', ' ', '\\x0c']\n702\n['Program Analysis Techniques', '', '© Converting a sequential loop to a parallel loop', '@ Program analysis to determine if programs are data-race', 'free', '@ Profiling programs to determine busy regions', '© Program slicing', '© Data-flow analysis approach to software testing', '«¢ Uncovering errors along all paths', '', '@ Dereferencing null pointers', 'Butter overflows and memory leaks', '', '@ Worst Case Execution Time (WCET) estimati', 'energy analysis', '', ' ', '\\x0c']\n707\n['Program Analysis Techniques', '', '© Converting a sequential loop to a parallel loop', '@ Program analysis to determine if programs are data-race', 'free', '@ Profiling programs to determine busy regions', '© Program slicing', '© Data-flow analysis approach to software testing', '«¢ Uncovering errors along all paths', '', '@ Dereferencing null pointers', ' Butfer overflows and memory leaks', '', '@ Worst Case Execution Time (WCET) estimatio', 'energy analysis', '', ' ', '\\x0c']\n712\n['Program Analysis Techniques', '', '© Converting a sequential loop to a parallel loop', '@ Program analysis to determine if programs are data-race', 'free', '@ Profiling programs to determine busy regions', '© Program slicing', '© Data-flow analysis approach to software testing', '«¢ Uncovering errors along all paths', '', '@ Dereferencing null pointers', 'Butler overflows and memory leaks', '', '© Worst Case Execution Time (WCET) estimati', 'energy analysis', '', ' ', '\\x0c']\n718\n['Program Analysis Techniques', '', '@ Converting a sequential loop to a parallel loop', '@ Program analysis to determine if programs are data-race', 'free', '@ Profiling programs to determine busy regions', '© Program slicing', '© Data-flow analysis approach to software testing', '«¢ Uncovering errors along all paths', '', '@ Dereferencing null pointers', ' Butfer overflows and memory leaks', '', '@ Worst Case Execution Time (WCET) estimati', 'energy analysis', '', ' ', '\\x0c']\n724\n['Program Analysis Techniques', '', '© Converting a sequential loop to a parallel loop', '@ Program analysis to determine if programs are data-race', 'free', '@ Profiling programs to determine busy regions', '© Program slicing', '© Data-flow analysis approach to software testing', '«¢ Uncovering errors along all paths', '', '@ Dereferencing null pointers', '© Butfer overflows and memory leaks', '', '@ Worst Case Execution Time (WCET) estimati', 'energy analysis', '', ' ', '\\x0c']\n730\n['Program Analysis Techniques', '', '© Converting a sequential loop to a parallel loop', '@ Program analysis to determine if programs are data-race', 'free', '@ Profiling programs to determine busy regions', '© Program slicing', '© Data-flow analysis approach to software testing', '«© Uncovering errors along all paths', '', '@ Dereferencing null pointers', 'Butter overflows and memory leaks', '', '@ Worst Case Execution Time (WCET) estimati', 'energy analysis', '', ' ', '\\x0c']\n737\n['Program Analysis Techniques', '', '© Converting a sequential loop to a parallel loop', '@ Program analysis to determine if programs are data-race', 'tree', '@ Profiling programs to determine busy regions', '@ Program slicing', '© Data-flow analysis approach to software testing', '«¢ Uncovering errors along all paths', '', '@ Dereferencing null pointers', 'Butler overflows and memory leaks', '', '@ Worst Case Execution Time (WCET) estimati', 'energy analysis', '', ' ', '\\x0c']\n744\n['Program Analysis Techniques', '', '© Converting a sequential loop to a parallel loop', '@ Program analysis to determine if programs are data-race', 'tree', '@ Profiling programs to determine busy regions', '© Program slicing', '© Data-flow analysis approach to software testing', '«© Uncovering errors along all paths', '', '@ Dereferencing null pointers', ' Butfer overflows and memory leaks', '', '@ Worst Case Execution Time (WCET) estimatio', 'energy analysis', '', ' ', '\\x0c']\n750\n['Program Analysis Techniques', '', '© Converting a sequential loop to a parallel loop', '@ Program analysis to determine if programs are data-race', 'free', '@ Profiling programs to determine busy regions', '© Program slicing', '© Data-flow analysis approach to software testing', '«¢ Uncovering errors along all paths', '', '# Dereterencing null pointers', '« Butfer overtiows and memory leaks', '', '@ Worst Case Execution Time (WCET) estimat', 'energy analysis', '', ' ', '\\x0c']\n756\n['Program Analysis Techniques', '', '© Converting a sequential loop to a parallel loop', '@ Program analysis to determine if programs are data-race', 'free', '@ Profiling programs to determine busy regions', '© Program slicing', '© Data-flow analysis approach to software testing', '«¢ Uncovering errors along all paths', '', '@ Dereferencing null pointers', ' Butfer overflows and memory leaks', '', '@ Worst Case Execution Time (WCET) estimatio', 'energy analysis', '', ' ', '\\x0c']\n762\n['Program Analysis Techniques', '', '© Converting a sequential loop to a parallel loop', '@ Program analysis to determine if programs are data-race', 'free', '@ Profiling programs to determine busy regions', '© Program slicing', '© Data-flow analysis approach to software testing', '«¢ Uncovering errors along all paths', '', '@ Dereferencing null pointers', ' Butfer overflows and memory leaks', '', '© Worst Case Execution Time (WCET) estimatio', 'energy analysis', '', ' ', '\\x0c']\n769\n['Program Analysis Techniques', '', '@ Converting a sequential loop to a parallel loop', '@ Program analysis to determine if programs are data-race', 'free', '@ Profiling programs to determine busy regions', '© Program slicing', '© Data-flow analysis approach to software testing', '«¢ Uncovering errors along all paths', '', '@ Dereferencing null pointers', ' Butfer overflows and memory leaks', '', '@ Worst Case Execution Time (WCET) estimati', 'energy analysis', '', ' ', '\\x0c']\n775\n['Program Analysis Techniques', '', '© Converting a sequential loop to a parallel loop', '@ Program analysis to determine if programs are data-race', 'free', '@ Profiling programs to determine busy regions', '© Program slicing', '© Data-flow analysis approach to software testing', '«© Uncovering errors along all paths', '', '@ Dereterencing null pointers', '« Butfer overtiows and memory leaks', '', '@ Worst Case Execution Time (WCET) estimatio', 'energy analysis', '', ' ', '\\x0c']\n781\n['ogram Analysis Techniques', '', '© Converting a sequential loop to a parallel loop', '', '@ Program analysis to determine it programs are data-race', 'free', '', '© Profiling programs to determine busy regions', '@ Program slicing', '', '© Data-flow analysis approach to software testing', '«© Uncovering errors along all paths', '@ Dereferencing null pointers', '«Butter overiows and memory leaks', '', '© Worst Case Execution Time (WCET) estimati', 'energy analysis', '', ' ', '\\x0c']\n789\n['anguage Processing System', 'source program', '', 'ands maces', '', '‘modified source program', '', '‘Compiler | A LANGUAGE', '', ': PROCESSING', 'target assembly program Sera', '', 'Assembler', '', 'relocatable machine code', '', 'wo library files', 'inker/Loader-—— relocatable object fil', '', 'target machine code', '', ' ', '\\x0c']\n795\n['anguage Processing System', '', 'source program', '', '[Preprocessor Srarisraxoe', '', '‘modified source program', '', 'Compiler ALANGUAGE', '', ': PROCESSING', 'target assembly program eri', '', '| Assembler', '', 'relocatable machine code', '', '= library files', 'LinkerLoadet— oie object', '', 'target machine code', '', ' ', '\\x0c']\n801\n['anguage Processing System', '', 'source program', '', '[Preprocessor Scardsmacrs', '', 'modified source program', '', '|_Compiter ALANGUAGE', '', 'PROCESSING', '', 'target assembly program pas', '', '| Assembler', '', 'relocatable machine code', '', 'mee vray les', '', 'relocatable object files', '', 'target machine code', '', ' ', '\\x0c']\n811\n['anguage Processing System', '', 'source program', '', 'Frepecesra) enero', '', 'modified source program', '', 'Compiler ALANGUAGE', '', 'ui PROCESSING', 'target assembly program rm', '', '| Assembler', '', 'relocatable machine code', '', 'library files', '', 'LinkerLoader-——~ relocatable object files', '', 'target machine code', '', ' ', '\\x0c']\n820\n['anguage Processing System', '', 'source program', '', 'Preprocessor Soiree maces', '', '‘modified source program', '', '|_Sompiter A LANGUAGE', '', 'PROCESSING', '', 'target assembly program en', '', 'Assembler', '', 'relocatable machine code', '', 'library files', '', '—', 'LinkerLoader-——~ relocatable object files', '', 'target machine code', '', ' ', '\\x0c']\n828\n['anguage Processing System', '', 'source program', '', 'Preprocessor \"isandsracoe', '', '‘modified source program', '', '| Compiler ALANGUAGE', '', 'PROCESSING', '', 'target assembly program vere', '', '| Aavoniat', '', 'relocatable machine code', '', 'library files', '', 'LinkerLoader-——~ relocatable object files', '', 'target machine code', '', ' ', '\\x0c']\n835\n['source program', '', '[Preprocessor ®:anse macros', '', '‘modified source program', '', '| oe', '', 'ALANGUAGE', 'PROCESSING', '', 'target assembly program Sven', '', '| Assembler', 'relocatable machine code', '', 'library files', 'Link Loader relocatable object files', '', 'target machine code', '', ' ', '\\x0c']\n844\n['anguage Processing System', '', 'source program', '', '[Preprocessor Ssarssraxoe', 'modified source program', '', '| Compiter A LANGUAGE', '', 'PROCESSING', '', 'target assembly program evErEl', '', '| Assembler', '', 'relocatable machine code', '', 'library files', '', 'LinkerlLoader-—— ;eiocatable object files', '', 'target machine code', '', ' ', '\\x0c']\n851\n['source program', '', '[Preprocessor)  Sanésmaxcs', 'modified source program', '', '‘Compiler A LANGUAGE', '', 'PROCESSING', '', 'target assembly program Cer', '', '| avenbier', '', 'relocatable machine code', '', 'library files', '', 'LinkerfLoader-— relocatable object files', '', 'target machine code', '', ' ', '\\x0c']\n857\n['anguage Processing System', '', 'source program', '', '[Preprocessor \"ands macros', '', '‘modified source program', '', '|_Sompiter ALANGUAGE', '', 'PROCESSING', '', 'target assembly program creel', '', '| Assembler', '', 'relocatable machine code', '', 'library files', '', 'LinkerLoader-——~ relocatable object files', '', '© target machine code', '', ' ', '\\x0c']\n864\n['source program', '', '[Preprocessor Ssarssraxoe', '', '‘modified source program', '', '| Sompiter ALANGUAGE', '', 'PROCESSING', '', 'target assembly program ave', '', '| Havonbiar', '', 'relocatable machine code', '', 'a library files', 'LinkertLoader-— elocaabe object es', '', 'target machine code', '', ' ', '\\x0c']\n869\n['source program', '', '[Preprocessor Sears raxce', '', '‘modified source program', '', '‘Compiler A LANGUAGE', '', 'PROCESSING', 'target assembly program Pen', '', '| ime', '', 'relocatable machine code', '', 'Ss library files', 'LinkerfLoader-— relocatable object files', '', 'target machine code', '', ' ', '\\x0c']\n876\n['source program', '', 'Preprocessor, Soins macos', '', '‘modified source program', '', '‘Compiler ‘A LANGUAGE', '', 'PROCESSING', '', 'target assembly program ayer', '', '| Assembler', '', 'relocatable machine code', '', 'library files', '', 'LinkerlLoader-——~ ;eiocatable object files', '', '© target machine code', '', ' ', '\\x0c']\n882\n[' ', '', 'anguage Processing System', '', 'source program', '', 'Preprocessor, Soir maces', '', 'modified source program', '| ts A LANGUAGE', '', ': PROCESSING', 'target assembly program Patan', '', 'Assembler', '', 'relocatable machine code', '', 'library files', 'relocatable object files', '', 'Linker/Loader-—', '', 'target machine code', '\\x0c']\n889\n['source program', '', '[Preprocessor) Sanésmaxcs', '', '‘modified source program', '', '‘Compiler ALANGUAGE', '', 'PROCESSING', 'target assembly program vere', '', '| i', '', 'relocatable machine code', '', 'remoadey __ Wbrary files', 'LinkerLoader—— re rcatable object les', '', 'target machine code', '', ' ', '\\x0c']\n901\n['ompller Overview', '', 'character stream', 'i optimized', 'Lexical Analyze target-machine code', 'token stream', '', '‘syntax Analyzer}', '‘Symbol', '', 'syntax tree Table', '', '‘Semantic Analyzer', '', 'target-machine code', '', 'Code: Generator', '', 'optimized', \"annotated'syntax tree intermediate representation\", '', '. Machine-tndependent', 'Intermediate Code Generator Code Optimizer', '', '© intermediate representation', '', ' ', '\\x0c']\n907\n['ompller Overview', '', 'character stream', 'i optimized', 'Lexical Analyze target-machine code', '', 'token stream Machine-Dependent', 'b Code Opt', '', '‘syntax Analyze]', '', 'target-machine code', 'T ‘Symbol :', 'syntax tree Table', '', '‘Semantic Analyzer', '', 'Code: Generator', '', 'optimized', \"annotated'syntax tree intermediate representation\", '', '‘ Machine-Independent', 'Intermediate Code Generator Code Optimizer', '', '© intermediate representation', '', ' ', '\\x0c']\n914\n['ompller Overview', '', 'character stream', '', 'i optimized', 'Lexical Analyze target-machine code', '', 'token stream Machine-Dependent', ': Code Op', '', '‘syntax Analyzer|', '‘Symbol', '', 'syntax tree | Table', '', '‘Semantic Analyzer', '', 'target-machine code', '', 'Code: Generator', '', 'optimized', \"annotated'syntax tree intermediate representation\", '', 'i Machine-Independent', 'Intermediate Code Generator Code Optimizer', '', 'intermediate representation', '', ' ', '\\x0c']\n921\n['ompller Overview', '', 'character stream', 'i optimized', 'Lexical Analyzer target-machine code', 'token stream', '', '‘syntax Analyzer!', '‘Symbot', '', 'syntax tree Table', '', '‘Semantic Analyzer', '', 'target-machine code', '', 'Code: Generator', '', 'optimized', \"annotated'syntax tree intermediate representation\", '', 'i Machine-Independent', 'Intermediate Code Generator Code Optimizer', '', '© intermediate representation', '', ' ', '\\x0c']\n927\n['ompller Overview', '', 'character stream', '', 'i optimized', 'Lexical Analyze target-machine code', '', 'token stream Machine-Dependent', 'b Code Opt', '', '‘syntax Analyzer}', '‘Symbol', '', 'syntax tree | Table', '', '‘Semantic Analyzer', '', 'target-machine code', '', 'Code: Generator', '', 'optimized', \"annotated'syntax tree intermediate representation\", '', 'z Machine-ndependent', 'Intermediate Code Generator Code Optimizer', '', '© intermediate representation', '', ' ', '\\x0c']\n936\n['ompller Overview', '', 'character stream', 'i optimized', 'Lexical Analyze target-machine code', '', 'token stream', '', 'pmeeaoteeons| ae) target-machine code', '', 'syntax tree', '', '‘Semantic Analyzer', '', '‘Code Generator', '', 'optimized', \"annotated'syntax tree intermediate representation\", '', 'i Machine-Independent', 'Intermediate Code Generator Code Optimizer', '', '© intermediate representation', '', ' ', '\\x0c']\n942\n['ompller Overview', '', 'character stream', '', '‘ optimized', 'Lexical Analyze target-machine code', '', 'token stream Machine-Dependent', '1 Code Op', '', '‘syntax Analyzer|', '‘Symbol', '', 'syntax tree Table', '', '‘Semantic Analyzer', '', 'target-machine code', '', 'Code: Generator', '', 'optimized', \"annotated'syntax tree intermediate representation\", '', 'i Machine-Independent', 'Intermediate Code Generator Code Optimizer', '', '© intermediate representation', '', ' ', '\\x0c']\n950\n['ompller Overview', '', 'character stream', 'i optimized', 'Lexical Analyze target-machine code', '', 'token stream Machine-Dependent', '', 'Code Opt', '‘syntax Analyzer|', '‘Symbol', '', 'syntax tree Table', '', '‘Semantic Analyzer', '', 'target-machine code', '', 'Code: Generator', '', 'optimized', \"annotated'syntax tree intermediate representation\", '', '4 Machine-Independent', 'Intermediate Code Generator Code Optimizer', '', '© intermediate representation', '', ' ', '\\x0c']\n956\n['ompller Overview', '', 'character stream', '', 'i optimized', 'Lexical Analyze target-machine code', '', 'token stream Machine-Dependent', 'L Code Op', '', '‘syntax Analyzer}', '‘Symbol', '', 'syntax tree Table', '', '‘Semantic Analyzer', '', 'target-machine code', '', 'Code: Generator', '', 'optimized', \"annotated'syntax tree intermediate representation\", '', 'i Machine-independent', 'Intermediate Code Generator Code Optimizer', '', '© intermediate representation', '', ' ', '\\x0c']\n963\n['Compilers generate machine code, whereas interpreters', 'interpret intermediate code', '', '@ Interpreters are easier to write and can provide better error', 'messages (symbol table is still available)', '', '@ Interpreters are at least 5 times slower than machine code', 'generated by compilers', '', '@ Interpreters also require much more memory than machine', 'code generated by compilers', '', '‘© Examples: Perl, Python, Unix Shell, Java, BASIC, LISP', '', ' ', '\\x0c']\n968\n['© Compilers generate machine code, whereas interpreters', 'interpret intermediate code', '', '@ Interpreters are easier to write and can provide better error', 'messages (symbol table is still available)', '', '@ Interpreters are at least 5 times slower than machine code', 'generated by compilers', '', '@ Interpreters also require much more memory than machine', 'code generated by compilers', '', '© Examples: Perl, Python, Unix Shell, Java, BASIC, LISP', '', ' ', '\\x0c']\n977\n['ompller Overview', '', 'character stream', '', '‘ optimized', 'Lexical Analyze target-machine code', '', 'token stream', '', '‘syntax Analyzer|', '‘Symbot', '', 'syntax tree | Table', '', '‘Semantic Analyzer', '', 'target-machine code', '', 'Code: Generator', '', 'optimized', \"annotated'syntax tree intermediate representation\", '', ': Machine-ndependent', 'Intermediate Code Generator Code Optimizer', '', 'JD) inertia representation', '', ' ', '\\x0c']\n984\n['ompller Overview', '', 'character stream', '', '‘ optimized', 'Lexical Analyze target-machine code', '', 'token stream Machine-Dependent', '1 Code Op', '', '‘syntax Analyzer|', '‘Symbol', '', 'syntax tee | Table', '', '‘Semantic Analyzer', '', 'target-machine code', '', 'Code: Generator', '', 'optimized', \"annotated'syntax tree intermediate representation\", '', '‘ Machine-Independent', 'Intermediate Code Generator Code Optimizer', '', '© intermediate representation', '', ' ', '\\x0c']\n990\n['ompller Overview', '', 'character stream', 'i optimized', 'Lexical Analyze target-machine code', '', 'token stream Machine-Dependent', '1 Code Op', '', '‘syntax Analyze]', '', 'target-machine code', 'T ‘Symbo! :', 'syntax tree Table', '', '‘Semantic Analyzer', '', 'Code: Generator', '', 'optimized', \"annotated'syntax tree intermediate representation\", '', '‘ Machine-Independent', 'Intermediate Code Generator Code Optimizer', '', '© intermediate representation', '', ' ', '\\x0c']\n997\n['© Compilers generate machine code, whereas interpreters', 'interpret intermediate code', '', '@ Interpreters are easier to write and can provide better error', 'messages (symbol table is still available)', '', '@ Interpreters are at least 5 times slower than machine code', 'generated by compilers', '', '@ Interpreters also require much more memory than machine', 'code generated by compilers', '', '© Examples: Perl, Python, Unix Shell, Java, BASIC, LISP', '', ' ', '\\x0c']\n1003\n['Compilers generate machine code, whereas interpreters', 'interpret intermediate code', '', '@ Interpreters are easier to write and can provide better error', 'messages (symbol table is still available)', '', '@ Interpreters are at least 5 times slower than machine code', 'generated by compilers', '', '@ Interpreters also require much more memory than machine', 'code generated by compilers', '', '‘© Examples: Perl, Python, Unix Shell, Java, BASIC, LISP', '', ' ', '\\x0c']\n1009\n['@ Compilers generate machine code, whereas interpreters', 'interpret intermediate code', '', '@ Interpreters are easier to write and can provide better error', 'messages (symbol table is still available)', '', '@ Interpreters are at least 5 times slower than machine code', 'generated by compilers', '', '@ Interpreters also require much more memory than machine', 'code generated by compilers', '', '© Examples: Perl, Python, Unix Shell, Java, BASIC, LISP', '', ' ', '\\x0c']\n1015\n['© Compilers generate machine code, whereas interpreters', 'interpret intermediate code', '', '@ Interpreters are easier to write and can provide better error', 'messages (symbol table is still available)', '', '@ Interpreters are at least 5 times slower than machine code', 'generated by compilers', '', '@ Interpreters also require much more memory than machine', 'code generated by compilers', '', '‘© Examples: Perl, Python, Unix Shell, Java, BASIC, LISP', '', ' ', '\\x0c']\n1023\n['Compilers generate machine code, whereas interpreters', 'interpret intermediate code', '', '@ Interpreters are easier to write and can provide better error', 'messages (symbol table is still available)', '', '@ Interpreters are at least 5 times slower than machine code', 'generated by compilers', '', '@ Interpreters also require much more memory than machine', 'code generated by compilers', '', '© Examples: Perl, Python, Unix Shell, Java, BASIC, LISP', '', ' ', '\\x0c']\n1027\n['Compilers generate machine code, whereas interpreters', 'interpret intermediate code', '', '@ Interpreters are easier to write and can provide better error', 'messages (symbol table is still available)', '', '@ Interpreters are at least 5 times slower than machine code', 'generated by compilers', '', '@ Interpreters also require much more memory than machine', 'code generated by compilers', '', '‘© Examples: Perl, Python, Unix Shell, Java, BASIC, LISP', '', ' ', '\\x0c']\n1034\n['© Compilers generate machine code, whereas interpreters', 'interpret intermediate code', '', '@ Interpreters are easier to write and can provide better error', 'messages (symbol table is still available)', '', '@ Interpreters are at least 5 times slower than machine code', 'generated by compilers', '', '@ Interpreters also require much more memory than machine', 'code generated by compilers', '', '‘© Examples: Perl, Python, Unix Shell, Java, BASIC, LISP', '', ' ', '\\x0c']\n1040\n['© Compilers generate machine code, whereas interpreters', 'interpret intermediate code', '', '@ Interpreters are easier to write and can provide better error', 'messages (symbol table is still available)', '', '@ Interpreters are at least 5 times slower than machine code', 'generated by compilers', '', '@ Interpreters also require much more memory than machine', 'code generated by compilers', '', '‘© Examples: Perl, Python, Unix Shell, Java, BASIC, LISP', '', ' ', '\\x0c']\n1047\n['© Compilers generate machine code, whereas interpreters', 'interpret intermediate code', '', '@ Interpreters are easier to write and can provide better error', 'messages (symbol table is still available)', '', '@ Interpreters are at least 5 times slower than machine code', 'generated by compilers', '', '@ Interpreters also require much more memory than machine', 'code generated by compilers', '', '‘© Examples: Perl, Python, Unix Shell, Java, BASIC, LISP', '', ' ', '\\x0c']\n1053\n['ompllers and Interpreters', '', '‘ Compilers generate machine code, whereas interpreters', 'interpret intermediate code', '', '@ Interpreters are easier to write and can provide better error', 'messages (symbol table is still available)', '', '@ Interpreters are at least 5 times slower than machine code', 'generated by compilers', '', '@ Interpreters also require much more memory than machine', 'code generated by compilers', '', '© Examples: Perl, Python, Unix Shell, Java, BASLG.LISP', '', ' ', '\\x0c']\n1060\n['‘© Compilers generate machine code, whereas interpreters', 'interpret intermediate code', '', '@ Interpreters are easier to write and can provide better error', 'messages (symbol table is still available)', '', '@ Interpreters are at least 5 times slower than machine code', 'generated by compilers', '', '@ Interpreters also require much more memory than machine', 'code generated by compilers', '', '‘© Examples: Perl, Python, Unix Shell, Java, BASLG. LISP', '', ' ', '\\x0c']\n1064\n['© Compilers generate machine code, whereas interpreters', 'interpret intermediate code', '', '@ Interpreters are easier to write and can provide better error', 'messages (symbol table is still available)', '', '@ Interpreters are at least 5 times slower than machine code', 'generated by compilers', '', '@ Interpreters also require much more memory than machine', 'code generated by compilers', '', '© Examples: Perl, Python, Unix Shell, Java, BASJG.LISP', '', ' ', '\\x0c']\n1072\n['© Compilers generate machine code, whereas interpreters', 'interpret intermediate code', '', '@ Interpreters are easier to write and can provide better error', 'messages (symbol table is still available)', '', '@ Interpreters are at least 5 times slower than machine code', 'generated by compilers', '', '@ Interpreters also require much more memory than machine', 'code generated by compilers', '', '‘© Examples: Perl, Python, Unix Shell, Java, BASJG.LISP', '', ' ', '\\x0c']\n1080\n['fahrenheit = centigrade * 4.8 + 32', '', 'Lexical Analyzer', '', '<id,1> <assign> <id,2> <multop>', '<fconst, 1.8> <addop> <iconst,32>', '', '‘Syntax Analyzer', '', ' ', '\\x0c']\n1088\n['fahrenheit = centigrade * 4.8 + 32', '', 'Lexical Analyzer', '', '<id,1> <assign> <id,2> <multop>', '<fconst, 1.8> <addop> <iconst,32>', '', '‘Syntax Analyzer', '', ' ', '\\x0c']\n1095\n['fahrenheit = centigrade * 1.8 + 32', '', 'Lexical Analyzer', '', '<id,1> <assign> <id,2> <multop>', '<fconst, 1.8> <addop> <iconst,32>', '', '‘Syntax Analyzer', '', ' ', '\\x0c']\n1100\n['fahrenheit = centigrade * 1.8 + 32', '', 'Lexical Analyzer', '', '<id,1> <assign> <id,2> <multop>', '<fconst, 1.8> <addop> <iconst,32>', '', '‘Syntax Analyzer,', '', ' ', '\\x0c']\n1107\n['fahrenheit = centigrade * 4.8 + 32', '', 'Lexical Analyzer', '', '<id,1> <assign> <id,2> <multop>', '<fconst, 1.8> <addop> <iconst,32>', '', '‘Syntax Analyzer', '', ' ', '\\x0c']\n1115\n['fahrenheit = centigrade * 4.8 + 32', '', 'Lexical Analyzer', '', '<id,1> <agsign> <id,2> <multop>', '<fconst, 1.8> <addop> <iconst,32>', '', '‘Syntax Analyzer', '', ' ', '\\x0c']\n1124\n['fahrenheit = centigrede * 4.8 + 32', '', 'Lexical Analyzer', '', '<id,1> <assign> <id,2> <multop>', '<fconst, 1.8> <addop> <iconst,32>', '', '‘Syntax Analyzer', '', ' ', '\\x0c']\n1130\n['fahrenheit = centigrade * 1.8 + 32', '', 'Lexical Analyzer', '', '<id,1> <assign> <id,2> <multop>', '<fconst, 1.8> <addop> <iconst,32>', '', '‘Syntax Analyzer', '', ' ', '\\x0c']\n1137\n['fahrenheit’ centigrade * 1.8 + 32', '', 'Lexical Analyzer', '', '<id,1> <assign> <id,2> <multop>', '<fconst, 1.8> <addop> <iconst,32>', '', '‘Syntax Analyzer', '', ' ', '\\x0c']\n1145\n['fahrenheit = centigrade * 1.8 + 32', '', 'Lexical Analyzer', '', '<id,1> <assign> <id,2> <multop>', '<fconst, 1.8> <addop> <iconst,32>', '', '‘Syntax Analyzer', '', ' ', '\\x0c']\n1153\n['fahrenheit = centigrade * 4.8 + 32', '', 'Lexical Analyzer', '', '<id,1> <assign> <id,2> <multop>', '<fconst, 1.8> <addop> <iconst,32>', '', '‘Syntax Analyzer', '', ' ', '\\x0c']\n1161\n['fahrenheit = centigrade * 4.8 + 32', '', 'Lexical Analyzer', '', '<id,1> <assign> <id,2> <multop>', '<fconst, 1.8> <addop> <iconst,32>', '', '‘Syntax Analyzer', '', ' ', '\\x0c']\n1170\n['fahrenheit = centigrade * 4.8 + 32', '', 'Lexical Analyzer', '', '<id,1> <assign> <id,2> <multop>', '<fconst, 1.8> <addop> <iconst,32>', '', '‘Syntax Analyzer', '', ' ', '\\x0c']\n1176\n['fahrenheit = centigrade * 4.8 + 32', '', 'Lexical Analyzer', '', '<id,1> <assign> <id,2> <multop>', '<fconst, 1.8> <addop> <iconst,32>', '', '‘Syntax Analyzer', '', ' ', '\\x0c']\n1183\n['fahrenheit = centigrade * 1.8 + 32', '', 'Lexical Analyzer', '', '<id,1> <assign> <id,2> <multop>', '<fconst, 1.8> <addop> <iconst,32>', '', '‘Syntax Analyzer', '', ' ', '\\x0c']\n1191\n['fahrenheit = centigrade * 4.8 + 32', '', 'Lexical Analyzer', '', '<id,1> <assign> <id,2> <multop>', '<fconst, 1.8> <addop> <iconst,32>', '', '‘Syntax Analyzer', '', ' ', '\\x0c']\n1198\n['fahrenheit = centigrade * 4.8 + 32', '', 'Lexical Analyzer', '', '<id,1> <assign> <id,2> <multop>', '<fconst, 1.8> <addop> <iconst,32>', '', '‘Syntax Analyzer', '', ' ', '\\x0c']\n1204\n['fahrenheit = centigrade * 4.8 + 32', '', 'Lexical Analyzer', '', '<id,1> <assign> <id,2> <multop>', '<fconst, 1.8> <addop> <iconst,32>', '', '‘Syntax Analyzer', '', ' ', '\\x0c']\n1209\n['fahrenheit = centigrade * 4.8 + 32', '', 'Lexical Analyzer', '', '<id,1> <assign> <id,2> <multop>', '<fconst, 1.8> <addop> <iconst,32>', '', '‘Syntax Analyzer', '', ' ', '\\x0c']\n1219\n['@ LA can be generated automatically trom regular expression', 'specifications', '', 'LEX and Flex are two such tools', '@ LAis a deterministic finite state automaton', '', '@ Why is LA separate from parsing?', '«© Simpitication of design - software engineering reason', '© 1 issues are limited LA alone', '‘ LAbased on finite automata are more efficient to implement', 'than pushdown automata used for parsing (due to stack)', '', ' ', '\\x0c']\n1228\n['@ LA can be generated automatically trom regular expression', 'specifications', '', '@ LEX and Flex are two such tools', '@ LAis a deterministic finite state automaton', '', '‘© Why is LA separate from parsing?', '«@ Simplification of design - software engineering reason', '@ 1/0 issues are limited LA alone', '@ LAbased on finite automata are more efficient to implement', 'than pushdown automata used for parsing (due to stack)', '', ' ', '\\x0c']\n1235\n['@ LAcan be generated automatically trom regular expression', 'specifications', '', 'LEX and Flex are two such tools', '@ LAisa deterministic finite state automaton', '', '© Why is LA separate from parsing?', '«© Simpitication of design - software engineering reason', '@ 10 issues are limited LA alone', '« LAbased on finite automata are more efficient to implement,', 'than pushdown automata used for parsing (due to stack)', '', ' ', '\\x0c']\n1243\n['exical Analysis', '', '@ LA can be generated automatically trom regular expression', 'specifications', '', 'LEX and Flex are two such tools', '@ LAis a deterministic finite state automaton', '', '‘@ Why is LA separate from parsing?', '‘ Simpitication of design - software engineering reason', '# UO issues are limited LA alone', '«@ LA based on finite automata are more efficient to implement', 'than pushdown automata used for parsing (due to stack)', '', ' ', '\\x0c']\n1248\n['@ LAcan be generated automatically trom regular expression', 'specifications', '', 'LEX and Flex are two such tools', '@ LAis a deterministic finite state automaton', '', '‘© Why is LA separate from parsing?', '«@ Simplification of design - software engineering reason', '@ 110 issues are limited LA alone', '@ LAbased on finite automata are more efficient to implement', 'than pushdown automata used for parsing (due to stack)', '', ' ', '\\x0c']\n1254\n['@ LA can be generated automatically trom regular expression', 'specifications', '', 'LEX and Flex are two such tools', '@ LAis a deterministic finite state automaton', '', '@ Why is LA separate from parsing?', '« Simpitication of design - software engineering reason', '# UO issues are limited LA alone', '«@ LA based on finite automata are more efficient to implement', 'than pushdown automata used for parsing (due to stack)', '', ' ', '\\x0c']\n1265\n['@ LA can be generated automatically trom regular expression', 'specifications', '', '@ LEX and Flex are two such tools', '@ LAisa deterministic finite state automaton', '', '@ Why is LA separate from parsing?', '‘ Simpitication of design - software engineering reason', '# UO issues are limited LA alone', '«@ LA based on finite automata are more efficient to implement', 'than pushdown automata used for parsing (due to stack)', '', ' ', '\\x0c']\n1274\n['@ LAcan be generated automatically trom regular expression', 'specifications', '', 'LEX and Flex are two such tools', '@ [Aisa deterministic finite state automaton', '', '@ Why is LA separate from parsing?', '«© Simpitication of design - software engineering reason', '@ 10 issues are limited LA alone', '‘ LAbased on finite automata are more efficient to implement', 'than pushdown automata used for parsing (due to stack)', '', ' ', '\\x0c']\n1280\n['@ LA can be generated automatically trom regular expression', 'specifications', '', 'LEX and Flex are two such tools', '@ LAis a deterministic finite state automaton', '', '‘@ Why is LA separate from parsing?', '« Simpitication of design - software engineering reason', '#10 issues are limited LA alone', '«@ LA based on finite automata are more efficient to implement', 'than pushdown automata used for parsing (due to stack)', '', ' ', '\\x0c']\n1287\n['@ LAcan be generated automatically trom regular expression', 'specifications', '', '@ LEX and Flex are two such tools', '@ LAis a deterministic finite state automaton', '', '@ Why is LA separate from parsing?', '«© Simpitication of design - software engineering reason', '© 10 issues are limited LA alone', '‘ LAbased on frite automata are more efficient to implement', 'than pushdown automata used for parsing (due to stack)', '', ' ', '\\x0c']\n1295\n['@ LA can be generated automatically rom regular expression', 'specifications', '', 'LEX and Flex are two such tools', '@ LAisa deterministic finite state automaton', '', '@ Why is LA separate from parsing?', '« Simpitication of design - software engineering reason', '# UO issues are limited LA alone', '«@ LA based on finite automata are more efficient to implement', 'than pushdown automata used for parsing (due to stack)', '', ' ', '\\x0c']\n1301\n['@ LAcan be generated automatically trom regular expression', 'specifications', '', 'LEX and Flex are two such tools', '@ LAis a deterministic finite state automaton', '', 'Why is LA separate from parsing?', '«© Simpitication of design - software engineering reason', '@ 10 issues are limited LA alone', '‘ LAbased on finite automata are more efficient to implement,', 'than pushdown automata used for parsing (due to stack)', '', ' ', '\\x0c']\n1308\n['@ LAcan be generated automatically trom regular expression', 'specifications', '', '@ LEX and Flex are two such tools', '@ LAis a deterministic finite state automaton', '', '© Whyis LA separate from parsing?', '« Simpitication of design - software engineering reason', '# UO issues are limited LA alone', '«@ LA based on finite automata are more efficient to implement', 'than pushdown automata used for parsing (due to stack)', '', ' ', '\\x0c']\n1316\n['@ LAcan be generated automatically trom regular expression', 'specifications', '', 'LEX and Flex are two such tools', '@ LAis a deterministic finite state automaton', '', '‘© Why is LA separate from parsing?', '«@ Simplification of design - software engineering reason', '@ 110 issues are limited LA alone', '@ LAbased on finite automata are more efficient to implement', 'than pushdown automata used for parsing (due to stack)', '', ' ', '\\x0c']\n1323\n['@ LA can be generated automatically trom regular expression', 'specifications', '', 'LEX and Flex are two such tools', '@ LAis a deterministic finite state automaton', '', '@ Why is LA separate from parsing?', '«© Simpitication of design - software engineering reason', '© 10 issues are limited LA alone', '‘ LAbased on finite automata are more efficient to implement,', 'than pushdown automata used for parsing (due to stack)', '', ' ', '\\x0c']\n1329\n['@ LA can be generated automatically trom regular expression', 'specifications', '', '© LEX and Flex are two such tools', '@ LAis.a deterministic finite state automaton', '', '@ Why is LA separate from parsing?', '« Simpitication of design - software engineering reason', '@ UO issues are limited LA alone', '«@ LA based on finite automata are more efficient to implement', 'than pushdown automata used for parsing (due to stack)', '', ' ', '\\x0c']\n1338\n['@ LAcan be generated automatically trom regular expression', 'specifications', '', 'LEX and Flex are two such tools', '@ LAis a deterministic finite state automaton', '', '@ Why is LA separate from parsing?', '«© Simpitication of design - software engineering reason', '@ LO issues are limited LA alone', '« LAbased on finite automata are more efficient to implement,', 'than pushdown automata used for parsing (due to stack)', '', ' ', '\\x0c']\n1344\n['@ LAcan be generated automatically trom regular expression', 'specifications', '', '@ LEX and Flex are two such tools', '@ LAis a deterministic finite state automaton', '', '@ Why is LA separate from parsing?', '«© Simpiticaton of design - software engineering reason', '© 10 issues are limited LA alone', '« LAbased on finite automata are more efficient to implement,', 'than pushdown automata used for parsing (due to stack)', '', ' ', '\\x0c']\n1352\n['@ LAcan be generated automatically trom regular expression', 'specifications', '', 'LEX and Flex are two such tools', '@ LAis a deterministic finite state automaton', '', '@ Why is LA separate from parsing?', '« Simpitication of design - software engineering reason', '# UO issues are limited LA alone', '@ LA based on finite automata are more efficient to implement', 'than pushdown automata used for parsing (due to stack)', '', ' ', '\\x0c']\n1359\n['@ LAcan be generated automatically trom regular expression', 'specifications', '', '@ LEX and Flex are two such tools', '@ LAis a deterministic finite state automaton', '', '@ Why is LA separate from parsing?', '« Simpltication of design - software engineering reason', '# UO issues are limited LA alone', '«@ LA based on finite automata are more efficient to implement', 'than pushdown automata used for parsing (due to stack)', '', ' ', '\\x0c']\n1366\n['@ LAcan be generated automatically trom regular expression', 'specifications', '', '@ LEX and Flex are two such tools', '@ LAis a deterministic finite state automaton', '', '‘@ Why is LA separate from parsing?', '‘© Simpitication of design - software engineering reason', '@ UO issues are limited LA alone', '«@ LA based on finite automata are more efficient to implement', 'than pushdown automata used for parsing (due to stack)', '', ' ', '\\x0c']\n1373\n['@ LAcan be generated automatically trom regular expression', 'specifications', '', 'LEX and Flex are two such tools', '@ LAis a deterministic finite state automaton', '', '@ Why is LA separate from parsing?', '«© Simpiticaton of design - software engineering reason', '@ 10 issues are limited LA alone', '«@ LAbased on finite automata are more efficient to implement', 'than pushdown automata used for parsing (due to stack)', '', ' ', '\\x0c']\n1380\n['@ LAcan be generated automatically trom regular expression', 'specifications', '', 'LEX and Flex are two such tools', '@ LAis a deterministic finite state automaton', '', '‘© Why is LA separate from parsing?', '« Simplification of design - software engineering reason', '@ 110 issues are limited LA alone', '@ LAbased on finite automata are more efficient to implement', 'than pushdown automata used for parsing (due to stack)', '', ' ', '\\x0c']\n1386\n['exical Analysis', '', '@ LAcan be generated automatically trom regular expression', 'specifications', '', 'LEX and Flex are two such tools', '@ LAis a deterministic finite state automaton', '', '‘© Why is LA separate from parsing?', '@ Simplification of design - software engineering reason', '@ 110 issues are limited LA alone', '@ LA based on finite automata are more efficient to implement', 'than pushdown automata used for parsing (due to stack)', '', ' ', '\\x0c']\n1391\n['@ LA can be generated automatically trom regular expression', 'specifications', '', 'LEX and Flex are two such tools', '@ LAis a deterministic finite state automaton', '', '@ Why is LA separate from parsing?', '«© Simpitication of design - software engineering reason', '@ 1 issues are limited LA alone', '« LAbased on finite automata are more efficient to implement,', 'than pushdown automata used for parsing (due to stack)', '', ' ', '\\x0c']\n1400\n['exical Analysis', '', '@ LA can be generated automatically trom regular expression', 'specifications', '', 'LEX and Flex are two such tools', '@ LAis a deterministic finite state automaton', '', '@ Why is LA separate from parsing?', '«© Simpitication of design - software engineering reason', '# UO issues are limited LA alone', '«@ LA based on finite automata are more efficent to implement', 'than pushdown automata used for parsing (due to stack)', '', ' ', '\\x0c']\n1406\n['@ LAcan be generated automatically trom regular expression', 'specifications', '', '@ LEX and Flex are two such tools', '@ LAis a deterministic finite state automaton', '', '@ Why is LA separate from parsing?', '«© Simpitication of design - software engineering reason', '@ 10 issues are limited LA alone', '« LAbased on finite automata are more efficient to implement', 'than pushdown automata used for parsing (due to stack)', '', ' ', '\\x0c']\n1413\n['fahrenheit = centigrade * 4.8 + 32', '', 'Lexical Analyzer', '', '<id,1> <assign> <id,2> <multop>', '<fconst, 1.8> <addop> <iconst,32>', '', '‘Syntax Analyzer', '', ' ', '\\x0c']\n1419\n['fahrenheit = centigrade * 4.8 + 32', '', 'Lexical Analyzer', '', '<id,1> <assign> <id,2> <multop>', '<fconst, 1.8> <addop> <iconst,32>', '', '‘Syntax Analyzer', '', ' ', '\\x0c']\n1425\n['fahrenheit = céntigrade * 4.8 + 32', '', 'Lexical Analyzer', '', '<id,1> <assign> <id,2> <multop>', '<fconst, 1.8> <addop> <iconst,32>', '', '‘Syntax Analyzer', '', ' ', '\\x0c']\n1435\n['fahrenheit = centigrade * 1.8 + 32', '', 'Lexical Analyzer', '', '<id,1> <assign> <id,2> <multop>', '<fconst, 1.8> <addop> <iconst,32>', '', '‘Syntax Analyzer', '', ' ', '\\x0c']\n1442\n['<id,1> <assign> <id,2> <multop>', '<fconst, 1.8> <addop> <iconst,32>', '', '‘Syntax Analyzer', '', ' ', '\\x0c']\n1450\n['ranslation Overview - Syntax Analysis', '', '<id,1> <assign> <id,2> <multop>', '<fconst, 1.8> <addop> <iconst,32>', '', '‘Syntax Analyzer', '', ' ', '\\x0c']\n1456\n['ranslation Overview - Syntax Analysis', '', '<id,1> <assign> <id,2> <multop>', '<fconst, 1.8> <addop> <iconst,32>', '', '‘Syntax Analyzer', '', ' ', '\\x0c']\n1463\n['ranslation Overview - Syntax Analysis', '', '<id,1> <assign> <id,2> <multop>', '<fconst, 1.8> <addos> <iconst,32>', '', '‘Syntax Analyzer', '', ' ', '\\x0c']\n1470\n['<id,1> <assign> <id,2> <multop>', '<fconst, 1.8> <addop> <iconst,32>', '', '‘Syntax Analyzer', '', ' ', '\\x0c']\n1476\n['<id,1> <assign> <id,2> <multop>', '<fconst, 1.8> <addop> <iconst,32>', '', '‘Syntax Analyzer', '', ' ', '\\x0c']\n1481\n['ranslation Overview - Syntax Analysis', '', '<id,1> <assign> <id,2> <multop>', '<fconst, 1.8> <addop> <iconst,32>', '', '‘Syntax Analyzer', '', ' ', '\\x0c']\n1487\n['ranslation Overview - Syntax Analysis', '', '<id,1> <assign> <id,2> <multop>', '<fconst, 1.8> <addop> <iconst,32>', '', '‘Syntax Analyzer', '', ' ', '\\x0c']\n1493\n['ranslation Overview - Syntax Analysis', '', '<id,1> <assign> <id,2> <multop>', '<fconst, 1.8> <addop> <iconst,32>', '', '‘Syntax Analyzer', '', ' ', '\\x0c']\n1494\n['ranslation Overview - Syntax Analysis', '', '<id,1> <assign> <id,2> <multop>', '<fconst, 1.8> <addop> <iconst,32>', '', '‘Syntax Analyzer', '', ' ', '\\x0c']\n1502\n['<id,1> <assign> <id,2> <multop>', '<fconst, 1.8> <addop> <iconst,32>', '', '‘Syntax Analyzer', '', ' ', '\\x0c']\n1508\n[' ', '', 'ranslation Overview - Syntax Analysis', '', '<id,1> <assign> <id,2> <multop>', '<fconst, 1.8> <addop> <iconst,32>', '', '‘Syntax Analyzer', '\\x0c']\n1515\n['fahrenheit = centigrade * 4.8 + 32', '', 'Lexical Analyzer', '', '<id,1> <assign> <id,2> <multop>', '<fconst, 1.8> <addop> <iconst,32>', '', '‘Syntax Analyzer', '', ' ', '\\x0c']\n1523\n['ranslation Overview - Syntax Analysis', '', '<id,1> <assign> <id,2> <multop>', '<fconst, 1.8> <addop> <iconst,32>', '', '‘Syntax Analyzer', '', ' ', '\\x0c']\n1531\n['ranslation Overview - Syntax Analysis', '', '<id,1> <assign> <id,2> <multop>', '<fconst, 1.8> <addop> <iconst,32>', '', '‘Syntax Analyzer', '', ' ', '\\x0c']\n1537\n['<id,1> <assign> <id,2> <multop>', '<fconst, 1.8> <addop> <iconst,32>', '', '‘Syntax Analyzer', '', ' ', '\\x0c']\n1543\n['<id,1> <assign> <id,2> <multop>', '<fconst, 1.8> <addop> <iconst,32>', '', '‘Syntax Analyzer', '', ' ', '\\x0c']\n1552\n['Parsing or', '', '@ Syntax analyzers (parsers) can be generated automatically', 'from several variants of context-free grammar', 'specifications', '', '@ LL(1), and LALR(1) are the most popular ones', '«© ANTLR (for LL(1)), YACC and Bison (for LALR(1}) are such', 'tools', '', '© Parsers are deterministic push-down automata', '', '@ Parsers cannot handle context-sensitive features of', 'programming languages; ¢.g', '', '« Variables are deciared before use', '« Types match on both sides of assignments', '« Parameter types and number match in declar', '', ' ', '\\x0c']\n1556\n['Parsing or Syntax Analysis', '', '@ Syntax analyzers (parsers) can be generated automatically', 'from several variants of context-free grammar', 'specifications', '', ' LL(1), and LALR(1) are the most popular ones', '«© ANTLR (for LL(1)), YACC and Bison (for LALR(1) are such', 'tools', '', '@ Parsers are deterministic push-down automata', '', '@ Parsers cannot handle context-sensitive features of', 'programming languages; ¢.g', '', '« Variables are declared before use', '« Types match on both sides of assignments', '« Parameter types and number match in declar', '', ' ', '\\x0c']\n1564\n['Parsing or', '', '@ Syntax analyzers (parsers) can be generated automatically', 'from several variants of context-free grammar', 'specifications', '', ' LL(1), and LALR(1) are the most popular ones', '«© ANTLR (for LL(1)), YACC and Bison (for LALR(1) are such', 'tools', '', '@ Parsers are deterministic push-down automata', '', '@ Parsers cannot handle context-sensitive features of', 'programming languages; e.g', '', '« Variables are decared before use', '« Types match on both sides of assignments', '‘ Parameter types and number match in decta', '', ' ', '\\x0c']\n1572\n['Parsing or', '', '@ Syntax analyzers (parsers) can be generated automatically', 'from several variants of context-free grammar', 'specifications', '', '@ LL(1), and LALR(1) are the most popular ones', '«© ANTLR (for LL(1)), YACC and Bison (for LALR(1)) are such', 'tools', '', '@ Parsers are deterministic push-down automata', '', '@ Parsers cannot handle context-sensitive features of', 'programming languages; ¢.g', '', '« Variables are deciared before use', '« Types match on both sides of assignments', '« Parameter types and number match in decl', '', ' ', '\\x0c']\n1579\n['Parsing or', '', '@ Syntax analyzers (parsers) can be generated automatically', 'from several variants of context-free grammar', 'specifications', '', '@ LL(1), and LALR(1) are the most popular ones', '«© ANTLR (for LL(1)), YACC and Bison (for LALR(1) are such', 'tools', '', '@ Parsers are deterministic push-down automata', '', '@ Parsers cannot handle context-sensitive features of', 'programming languages; ¢.g', '', '« Variables are deciared before use', '« Types match on both sides of assignments', '« Parameter types and number match in decta', '', ' ', '\\x0c']\n1586\n['Parsing or', '', '@ Syntax analyzers (parsers) can be generated automatically', 'from several variants of context-free grammar', 'specifications', '', '@ LL(1), and LALR(1) are the most popular ones', '«© ANTLR (for LL(1)), YACC and Bison (for LALR(1) are such', 'tools', '', '@ Parsers are deterministic push-down automata', '', '@ Parsers cannot handle context-sensitive features of', 'programming languages; ¢.g', '', '« Variables are deciared before use', '« Types match on both sides of assignments', '«¢ Parameter types and number match in decla', '', ' ', '\\x0c']\n1592\n['Parsing or', '', '@ Syntax analyzers (parsers) can be generated automatically', 'from several variants of context-free grammar', 'specifications', '', ' LL(1), and LALR(1) are the most popular ones', '« ANTLR (for LL(1)), YACC and Bison (for LALR(1}) are such', 'tools', '', '@ Parsers are deterministic push-down automata', '', '@ Parsers cannot handle context-sensitive features of', 'programming languages; ¢.g', '', '« Variables are deciared before use', '« Types match on both sides of assignments', '« Parameter types and number match in decla', '', ' ', '\\x0c']\n1599\n['arsing or Syntax', '', '@ Syntax analyzers (parsers) can be generated automatically', 'from several variants of context-free grammar', 'specifications', '', '@ LL(1), and LALR(1) are the most popular ones', '@ ANTLR (for LL(1)), YACC and Bison (or LALR(1)) are such', 'tools', '', '@ Parsers are deterministic push-down automata', '', '@ Parsers cannot handle context-sensitive features of', 'programming languages; 9.', '', '« Variables are declared before use', '« Types match on both sides of assignments', '‘ Parameter types and number match in decta', '', ' ', '\\x0c']\n1606\n['Parsing or', '', '@ Syntax analyzers (parsers) can be generated automatically', 'from several variants of context-free grammar', 'specifications', '', '@ LL(1), and LALR(1) are the most popular ones', '«@ ANTLR (for LL(1)), YACC and Bison (for LALR(1}) are such', 'tools', '', '@ Parsers are deterministic push-down automata', '', '@ Parsers cannot handle context-sensitive features of', 'programming languages; e.g', '', '« Variables are deciared before use', '« Types match on both sides of assignments', '«© Parameter types and number match in declay', '', ' ', '\\x0c']\n1614\n['Parsing or Syntax Analysis', '', '@ Syntax analyzers (parsers) can be generated automatically', 'from several variants of context-free grammar', 'specifications', '', ' LL(1), and LALR(1) are the most popular ones', '«© ANTLR (for LL(1)), YACC and Bison (for LALR(1) are such', 'tools', '', '@ Parsers are deterministic push-down automata', '', '@ Parsers cannot handle context-sensitive features of', 'programming languages; ¢.g', '', '« Variables are deciared before use', '« Types match on both sides of assignments', '« Parameter types and number match in decla', '', ' ', '\\x0c']\n1621\n['Parsing or', '', '@ Syntax analyzers (parsers) can be generated automatically', 'from several variants of context-free grammar', 'specifications', '', '@ LL(1), and LALR(1) are the most popular ones', '«© ANTLR (for LL(1)), YACC and Bison (for LALR(1)) are such', 'tools', '', '@ Parsers are deterministic push-down automata', '', '@ Parsers cannot handle context-sensitive features of', 'programming languages; 9.', '', '« Variables are deciared before use', '« Types match on both sides of assignments', '« Parameter types and number match in decla', '', ' ', '\\x0c']\n1626\n['Parsing or', '', '@ Syntax analyzers (parsers) can be generated automatically', 'from several variants of context-free grammar', 'specifications', '', '@ LL(1), and LALR(1) are the most popular ones', '«© ANTLR (for LL(1)), YACC and Bison (for LALR(1) are such', 'tools', '', '@ Parsers are deterministic push-down automata', '', '@ Parsers cannot handle context-sensitive features of', 'programming languages; eg.', '', '« Variables are deciared before use', '« Types match on both sides of assignments', '‘ Parameter types and number match in decta', '', ' ', '\\x0c']\n1637\n['Parsing or', '', '@ Syntax analyzers (parsers) can be generated automatically', 'from several variants of context-free grammar', 'specifications', '', '@ LL(1), and LALR(1) are the most popular ones', '«© ANTLR (for LL(1)), YACC and Bison (for LALR(1)) are such', 'tools', '', '@ Parsers are deterministic push-down automata', '', '@ Parsers cannot handle context-sensitive features of', 'programming languages; ¢.g', '', '« Variables are deciared before use', '« Types match on both sides of assignments', '‘ Parameter types and number match in decta', '', ' ', '\\x0c']\n1643\n['Parsing or', '', '@ Syntax analyzers (parsers) can be generated automatically', 'from several variants of context-free grammar', 'specifications', '', '@ LL(1), and LALR(1) are the most popular ones', '«© ANTLR (for LL(1)), YACC and Bison (for LALR(1) are such', 'tools', '', '@ Parsers are deterministic push-down automata', '', '@ Parsers cannot handle context-sensitive features of', 'programming languages; ¢.g', '', '« Variables are declared before use', '« Types match on both sides of assignments', '« Parameter types and fiumber match in decla', '', ' ', '\\x0c']\n1650\n['Parsing or', '', '@ Syntax analyzers (parsers) can be generated automatically', 'from several variants of context-free grammar', 'specifications', '', '@ LL(1), and LALR(1) are the most popular ones', '«© ANTLR (for LL(1)), YACC and Bison (for LALR(1}) are such', 'tools', '', '@ Parsers are deterministic push-down automata', '', '@ Parsers cannot handle context-sensitive features of', 'programming languages; e.g', '', '« Variables are decared before use', '« Types match on both sides of assignments', '«© Parameter types and number match in declaration and use', '', ' ', '\\x0c']\n1659\n['Parsing or', '', '@ Syntax analyzers (parsers) can be generated automatically', 'from several variants of context-free grammar', 'specifications', '', '@ LL(1), and LALR(1) are the most popular ones', '«© ANTLR (for LL(1)), YACC and Bison (for LALR(1}) are such', 'tools', '', '@ Parsers are deterministic push-down automata', '', '@ Parsers cannot handle context-sensitive features of', 'programming languages; ¢.g', '', '« Variables are deciared before use', '« Types match on both sides of assignments', '« Parameter types and number match in declaration and use', '', ' ', '\\x0c']\n1668\n['Parsing or', '', '@ Syntax analyzers (parsers) can be generated automatically', 'from several variants of context-free grammar', 'specifications', '', '@ LL(1), and LALR(1) are the most popular ones', '«@ ANTLR (for LL(1)), YACC and Bison (for LALR(1) are such', 'tools', '', '@ Parsers are deterministic push-down automata', '', '@ Parsers cannot handle context-sensitive features of', 'programming languages; ¢.g', '', '« Variables are deciared before use', '« Types match on both sides of assignments', '« Parameter types and number match in declaration and use', '', ' ', '\\x0c']\n1678\n['Parsing or', '', '@ Syntax analyzers (parsers) can be generated automatically', 'from several variants of context-free grammar', 'specifications', '', '@ LL(1), and LALR(1) are the most popular ones', '«© ANTLR (for LL(1)), YACC and Bison (for LALR(1)) are such', 'tools', '', '@ Parsers are deterministic push-down automata', '', '@ Parsers cannot handle context-sensitive features of', 'programming languages; ¢.g', '', '« Variables are deciared before use', '«© Types match on both sides of assignments', '« Parameter types and number match in declaration and use', '', ' ', '\\x0c']\n1685\n['Parsing or', '', '@ Syntax analyzers (parsers) can be generated automatically', 'from several variants of context-free grammar', 'specifications', '', '@ LL(1), and LALR(1) are the most popular ones', '«© ANTLR (for LL(1)), YACC and Bison (for LALR(1)) are such', 'tools', '', '@ Parsers are deterministic push-down automata', '', '@ Parsers cannot handle context-sensitive features of', 'programming languages; ¢.g', '', '« Variables are decared before use', '«© Types match on both sides of assignments', '« Parameter types and number match in declaration and use', '', ' ', '\\x0c']\n1692\n['Parsing or', '', '@ Syntax analyzers (parsers) can be generated automatically', 'from several variants of context-free grammar', 'specifications', '', '@ LL(1), and LALR(1) are the most popular ones', '«© ANTLR (for LL(1)), YACC and Bison (for LALR(1)) are such', 'tools', '', '@ Parsers are deterministic push-down automata', '', '@ Parsers cannot handle context-sensitive features of', 'programming languages; ¢.g', '', '« Variables are deciared before use', '« Types match on both sides of assignments', '«© Parameter types and number match in declaration and use', '', ' ', '\\x0c']\n1698\n['Parsing or Syntax Analysis', '', '@ Syntax analyzers (parsers) can be generated automatically', 'from several variants of context-free grammar', 'specifications', '', '@ LL(1), and LALR(1) are the most popular ones', '«© ANTLR (for LL(1)), YACC and Bison (for LALR(1) are such', 'tools', '', '@ Parsers are deterministic push-down automata', '', '@ Parsers cannot handle context-sensitive features of', 'programming languages; ¢.g', '', '« Variables are deciared before use', '« Types match on both sides of assignments', '« Parameter types and number match in declaration and use', '', ' ', '\\x0c']\n1705\n['Parsing or', '', '@ Syntax analyzers (parsers) can be generated automatically', 'from several variants of context-free grammar', 'specifications', '', '@ LL(1), and LALR(1) are the most popular ones', '«© ANTLR (for LL(1)), YACC and Bison (for LALR(1)) are such', 'tools', '', '@ Parsers are deterministic push-down automata', '', '@ Parsers cannot handle context-sensitive features of', 'programming languages; ¢.g', '', '« Variables are declared before use', '« Types match on both sides of assignments', '« Parameter types and number match in declaration and use', '', ' ', '\\x0c']\n1713\n['Parsing or', '', '@ Syntax analyzers (parsers) can be generated automatically', 'from several variants of context-free grammar', 'specifications', '', '@ LL(1), and LALR(1) are the most popular ones', '«© ANTLR (for LL(1)), YACC and Bison (for LALR(1}) are such', 'tools', '', '@ Parsers are deterministic push-down automata', '', '@ Parsers cannot handle context-sensitive features of', 'programming languages; ¢.g', '', '« Variables are declared before use', '« Types match on both sides of assignments', '« Parameter types and number match in declaration and use', '', ' ', '\\x0c']\n1720\n['Parsing or', '', '@ Syntax analyzers (parsers) can be generated automatically', 'from several variants of context-free grammar', 'specifications', '', '@ LL(1), and LALR(1) are the most popular ones', '«© ANTLR (for LL(1)), YACC and Bison (for LALR(1) are such', 'tools', '', '@ Parsers are deterministic push-down automata', '', '@ Parsers cannot handle context-sensitive features of', 'programming languages; ¢.g', '', '« Variables are declared before use', '«8 Types match on both sides of assignments', '« Parameter types and number match in declaration and use', '', ' ', '\\x0c']\n1727\n['Parsing or', '', '@ Syntax analyzers (parsers) can be generated automatically', 'from several variants of context-free grammar', 'specifications', '', '@ LL(1), and LALR(1) are the most popular ones', '«© ANTLR (for LL(1)), YACC and Bison (for LALR(1) are such', 'tools', '', '@ Parsers are deterministic push-down automata', '', '@ Parsers cannot handle context-sensitive features of', 'programming languages; ¢.g', '', '« Variables are deciared before use', '« Types match on both sides of assignments', '« Parameter types and number gatch in declaration and use', '', ' ', '\\x0c']\n1734\n['Parsing or Syntax Analysis', '', '@ Syntax analyzers (parsers) can be generated automatically', 'from several variants of context-free grammar', 'specifications', '', '@ LL(1), and LALR(1) are the most popular ones', '«© ANTLR (for LL(1)), YACC and Bison (for LALR(1) are such', 'tools', '', '@ Parsers are deterministic push-down automata', '', '@ Parsers cannot handle context-sensitive features of', 'programming languages; ¢.g', '', '« Variables are declared before use', '« Types match on both sides of assignments', '« Parameter type and number match in declaration and use', '', ' ', '\\x0c']\n1741\n['Parsing or', '', '@ Syntax analyzers (parsers) can be generated automatically', 'from several variants of context-free grammar', 'specifications', '', '@ LL(1), and LALR(1) are the most popular ones', '«© ANTLR (for LL(1)), YACC and Bison (for LALR(1) are such', 'tools', '', '@ Parsers are deterministic push-down automata', '', '@ Parsers cannot handle context-sensitive features of', 'programming languages; ¢.g', '', '« Variables are deciared before use', '« Types match on both sides of assignments', '« Parameter types and number match in declaration and use', '', ' ', '\\x0c']\n1749\n['Parsing or', '', '@ Syntax analyzers (parsers) can be generated automatically', 'from several variants of context-free grammar', 'specifications', '', '@ LL(1), and LALR(1) are the most popular ones', '«© ANTLR (for LL(1)), YACC and Bison (for LALR(1) are such', 'tools', '', '@ Parsers are deterministic push-down automata', '', '@ Parsers cannot handle context-sensitive features of', 'programming languages; ¢.g', '', '« Vatiables are deciared before use', '« Types match on both sides of assignments', '« Parameter types and number match in declaration and use', '', ' ', '\\x0c']\n1758\n['Parsing or', '', '@ Syntax analyzers (parsers) can be generated automatically', 'from several variants of context-free grammar', 'specifications', '', '@ LL(1), and LALR(1) are the most popular ones', '«© ANTLR (for LL(1)), YACC and Bison (for LALR(1) are such', 'tools', '', '© Parsers are deterministic push-down automata', '', '@ Parsers cannot handle context-sensitive features of', 'programming languages; e.g', '', '« Variables are decared before use', '« Types match on both sides of assignments', '« Parameter types and number match in declaration and use', '', ' ', '\\x0c']\n1765\n['Parsing or', '', '@ Syntax analyzers (parsers) can be generated automatically', 'from several variants of context-free grammar', 'specifications', '', '@ LL(1), and LALR(1) are the most popular ones', '«© ANTLR (for LL(1)), YACC and Bison (for LALR(1)) are such', 'tools', '', '@ Parsers are deterministic push-down automata', '', '@ Parsers cannot handle context-sensitive features of', 'programming languages; ¢.g', '', '« Variables are declared before use', '« Types match on both sides of assignments', '« Parameter types and number match in declaration and use', '', ' ', '\\x0c']\n1772\n['Parsing or', '', '@ Syntax analyzers (parsers) can be generated automatically', 'from several variants of context-free grammar', 'specifications', '', '@ LU(1), and LALR(1) are the most popular ones', '«© ANTLR (for LL(1)), YACC and Bison (for LALR(1}) are such', 'tools', '', '@ Parsers are deterministic push-down automata', '', '@ Parsers cannot handle context-sensitive features of', 'programming languages; e.g', '', '« Variables are decared before use', '« Types match on both sides of assignments', '« Parameter types and number match in declaration and use', '', ' ', '\\x0c']\n1779\n['Parsing or Syntax Analysis', '', '@ Syntax analyzers (parsers) can be generated automatically', 'from several variants of context-free grammar', 'specifications', '', '@ LL(1), and LALR(1) are the most popular ones', '«© ANTLR (for LL(1)), YACC and Bison (for LALR(1)) are such', 'tools', '', '@ Parsers are deterministic push-down automata', '', '@ Parsers cannot handle context-sensitive features of', 'programming languages; ¢.g', '', '« Variables are decared before use', '« Types match on both sides of assignments', '« Parameter types and number match in declaration and use', '', ' ', '\\x0c']\n1785\n['Parsing or', '', '@ Syntax analyzers (parsers) can be generated automatically', 'from several variants of context-free grammar', 'specifications', '', '@ LL(1), and LALR(1) are the most popular ones', '«© ANTLR (for LL(1)), YACC and Bison (for LALR(1)) are such', 'tools', '', '© Parsers are deterministic push-down automata', '', '@ Parsers cannot handle context-sensitive features of', 'programming languages; ¢.g', '', '« Variables are deciared before use', '« Types match on both sides of assignments', '« Parameter types and number match in declaration and use', '', ' ', '\\x0c']\n1793\n['Int.code Generator', '', ' ', '\\x0c']\n1804\n['Int.code Generator', '', ' ', '\\x0c']\n1811\n['IntCode Generator', '', ' ', '\\x0c']\n1819\n['i', '', 'Int.code Generator', '', ' ', '\\x0c']\n1827\n['Int.code Generator', '', ' ', '\\x0c']\n1837\n['Int.code Generator', '', ' ', '\\x0c']\n1844\n['Int.code Generator', '', ' ', '\\x0c']\n1850\n['intotioat', '48 32', '', 'Int.code Generator', '', ' ', '\\x0c']\n1857\n['Int.code Generator', '', ' ', '\\x0c']\n1863\n['inalysis', '', 'Semantic Analyzer', '', 'intotioat', '48 32', '', 'Int.code Generator', '', ' ', '\\x0c']\n1869\n['Int.code Generator', '', ' ', '\\x0c']\n1876\n['intoftoat', '', 'i 48 32', '', 'Int.code Generator', '', ' ', '\\x0c']\n1882\n['Int.code Generator', '', ' ', '\\x0c']\n1887\n['i', '', 'Int.code Generator', '', ' ', '\\x0c']\n1895\n['© Semantic consistency that cannot be handled at the', 'parsing stage is handled here', '', '© Type checking of various programming language', 'constructs is one of the most important tasks', '', '© Stores type information in the symbol table or the syntax', '', 'tree', '© Types of variables, function parameters, array dimensions,', 'ete', '«Used not only for semantic validation but also for', 'subsequent phases of compilation', '© Static semantics of programming languages can be', 'specified using attribute grammars', '', ' ', '\\x0c']\n1901\n['© Semantic consistency that cannot be handled at the', 'parsing stage is handled here', '', '© Type checking of various programming language', 'constructs is one of the most important tasks', '', '© Stores type information in the symbol table or the syntax', '', 'tree', '© Types of variables, function parameters, array dimensions,', 'ete', '«Used not only for semantic validation but also for', 'subsequent phases of compilation', '@ Static semantics of programming languages can be', 'specified using attribute grammars', '', ' ', '\\x0c']\n1907\n['@ Semantic consistency that cannot be handled at the', 'parsing stage is handled here', '', '© Type checking of various programming anguage', 'constructs is one of the most important tasks', '', '© Stores type information in the symbol table or the syntax', '', 'tree', '© Types of variables, function parameters, array dimensions,', 'ete', '«¢ Used not only for semantic validation but also for', 'subsequent phases of compilation', '@ Static semantics of programming languages can be', 'specified using attribute grammars', '', ' ', '\\x0c']\n1913\n['@ Semantic consistency that cannot be handled at the', 'parsing stage is handled here', '', '© Type checking of various programming language', 'constructs is one of the most important tasks', '', '@ Stores type information in the symbol table or the syntax', '', 'tree', '© Types of variables, function parameters, array dimensions,', 'ete', '«¢ Used not only for semantic validation but also for', 'subsequent phases of compilation', '@ Static semantics of programming languages can be', 'specified using attribute grammars', '', ' ', '\\x0c']\n1921\n['emantic Analysis', '', '© Semantic consistency that cannot be handled at the', 'parsing stage is handled here', '© Type checking of various programming language', 'constructs is one of the most important tasks', '© Stores type information in the symbol table or the syntax', 'tree', '© Types of variables, function parameters, array dimensions,', 'ete', '«Used not only for semantic validation but also for', 'subsequent phases of compilation', '', '@ Static semantics of programming languages can be', 'specified using attribute grammars', '', ' ', '\\x0c']\n1926\n['© Semantic consistency that cannot be handled at the', 'parsing stage is handled here', '', '© Type checking of various programming language', 'constructs is one of the most important tasks', '', '© Stores type information in the symbol table or the syntax', '', 'tree', '© Types of variables, function parameters, array dimensions,', 'ete', '«Used not only for semantic validation but also for', 'subsequent phases of compilation', '@ Static semantics of programming languages can be', 'specified using attribute grammars', '', ' ', '\\x0c']\n1932\n['@ Semantic consistency that cannot be handled at the', 'parsing stage is handled here', '', '© Type checking of various programming language', 'constructs is one of the most important tasks', '', '© Stores type information in the symbol table or the syntax', '', 'tree', '« Types of variables, function parameters, array dimensions,', 'etc,', '‘¢ Used not only for semantic validation but also for', 'subsequent phases of compilation', '', '@ Static semantics of programming languages can be', 'specified using attribute grammars', '', ' ', '\\x0c']\n1940\n['© Semantic consistency that cannot be handled at the', 'parsing stage is handled here', '', '© Type checking of various programming language', 'constructs is one of the most important tasks', '', '@ Stores type information in the symbol table or the syntax', '', 'tree', '© Types of variables, function parameters, array dimensions,', 'ete', '«Used not only for semantic validation but also for', 'subsequent phases of compilation', '@ Static semantics of programming languages can be', 'specified using attribute grammars', '', ' ', '\\x0c']\n1948\n['Semantic consistency that cannot be handled at the', 'parsing stage is handled here', '', '@ Type checking of various programming language', 'Constructs is one of the most important tasks', '', '@ Stores type information in the symbol table or the syntax', '', 'tree', '© Types of variables, function parameters, array dimensions,', 'etc', '«Used not only for semantic validation but also for', 'subsequent phases of compilation', '© Static semantics of programming languages c', 'specified using attribute grammars', '', ' ', '\\x0c']\n1954\n['Semantic consistency that cannot be handled at the', 'parsing stage is handled here', '', '© Type checking of various programming language', 'constructs is one of the most important tasks', '', '© Stores type information in the symbol table or the syntax', '', 'tree', '© Types of variables, function parameters, array dimensions,', 'ete', '«# Used not only for semantiévaldation but also for', 'subsequent phases of compilation', '© Static semantics of programming languages c', 'specitied using attribute grammars', '', ' ', '\\x0c']\n1960\n['@ Semantic consistency that cannot be handled at the', 'parsing stage is handled here', '', '@ Type checking of various programming language', 'Constructs is one of the most important tasks', '', '@ Stores type information in the symbol table or the syntax', '', 'tree', '© Types of variables, function parameters, array dimensions,', 'etc', '«# Used not only for semantic validation but also for', 'subsequent phases of compilation', '© Static semantics of prdgramming languages c', 'specified using attribute grammars', '', ' ', '\\x0c']\n1968\n['@ Semantic consistency that cannot be handled at the', 'parsing stage is handled here', '', '© Type checking of various programming language', 'constructs is one of the most important tasks', '', '© Stores type information in the symbol table or the syntax', '', 'tree', '© Types of variables, function parameters, array dimensions,', 'ete', '«Used not only for semantic validation but also for', 'subsequent phases of compilation', '© Static semantics of programming languages c', 'specified using attribute grammars', '', ' ', '\\x0c']\n1976\n['© Semantic consistency that cannot be handled at the', 'parsing stage is handled here', '', '© Type checking of various programming language', 'constructs is one of the most important tasks', '', '© Stores type information in the symbol table or the syntax', '', 'tree', '© Types of variables, function parameters, array dimensions,', 'ete', '«# Used not only for semantic validation but also for', 'subsequent phases of compilation', '© Static semantics of programming languages o', 'specified using attribute grammars', '', ' ', '\\x0c']\n1981\n['@ Semantic consistency that cannot be handled at the', 'parsing stage is handled here', '', '© Type checking of various programming language', 'constructs is one of the most important tasks', '', '© Stores type information in the symbol table or the syntax', '', 'tree', '© Types of variables, function parameters, array dimensions,', 'ete', '«Used not only for semantic validation but also for', 'subsequent phases of compilation', '© Static semantics of programming languages o', 'specified using attribute grammars', '', ' ', '\\x0c']\n1987\n['@ Semantic consistency that cannot be handled at the', 'parsing stage is handled here', '', '© Type checking of various programming language', 'constructs is one of the most important tasks', '', '© Stores type information in the symbol table or the syntax', '', 'tree', '© Types of variables, function parameters, array dimensions,', 'ete', '«Used not only for semantic validation but also for', 'subsequent phases gf compilation', '© Static semantics of programming languages c', 'specified using attribute grammars', '', ' ', '\\x0c']\n1992\n['Semantic consistency that cannot be handled at the', 'parsing stage is handled here', '', '© Type checking of various programming language', 'constructs is one of the most important tasks', '', '© Stores type information in the symbol table or the syntax', '', 'tree', '© Types of variables, function parameters, array dimensions,', 'ete .', '«Used not only for semantic validation but also for', 'subsequent phases of compilation', '© Static semantics of programming languages c', 'specified using attribute grammars', '', ' ', '\\x0c']\n1999\n['@ Semantic consistency that cannot be handled at the', 'parsing stage is handled here', '', '© Type checking of various programming language', 'constructs is one of the most important tasks', '', '© Stores type information in the symbol table or the syntax', '', 'tree', '© Types of variables, function parameters, array dimensions,', 'etc', '«Used not only for semantic validation but also for', 'subsequent phases of compilation', '© Static semantics of programming languages c', 'specified using attribute grammars', '', ' ', '\\x0c']\n2003\n['@ Semantic consistency that cannot be handled at the', 'parsing stage is handled here', '', '© Type checking of various programming language', 'constructs is one of the most important tasks', '', '© Stores type information in the symbol table or the syntax', '', 'tree', '© Types of variables, function parameters, array dimensions,', 'ete', '«Used not only for semantic validation but also for', 'subsequent phases of compilation', '© Static semantics of programming languages c', 'specified using attribute grammars', '', ' ', '\\x0c']\n2012\n['@ Semantic consistency that cannot be handled at the', 'parsing stage is handled here', '', '© Type checking of various programming language', 'constructs is one of the most important tasks', '', '© Stores type information in the symbol table or the syntax', '', 'tree', '© Types of variables, function parameters, array dimensions,', 'ete', '«Used not only for semantic validation but also for', 'subsequent phases of compilation', '© Static semantics of programming languages c', 'specified using attribute grammars', '', ' ', '\\x0c']\n2018\n['@ Semantic consistency that cannot be handled at the', 'parsing stage is handled here', '', '© Type checking of various programming language', 'constructs is one of the most important tasks', '', '© Stores type information in the symbol table or the syntax', '', 'tree', '© Types of variables, function parameters, array dimensions,', 'etc', '«Used not only for semantic validation but also for', 'subsequent phases of compilation', '© Static semantics of programming languages ¢', 'specified using attribute grammars', '', ' ', '\\x0c']\n2024\n['@ Semantic consistency that cannot be handled at the', 'parsing stage is handled here', '', '@ Type checking of various programming language', 'constructs is one of the most important tasks', '', '@ Stores type information in the symbol table or the syntax', '', 'tree', '© Types of variables, function parameters, array dimensions,', 'ete', '«# Used not only for semantic validation but also for', 'subsequent phases of compilation', '© Static semantics of programming languages ¢', 'specified using attribute grammars', '', ' ', '\\x0c']\n2031\n['Semantic consistency that cannot be handled at the', 'parsing stage is handled here', '', '© Type checking of various programming language', 'constructs is one of the most important tasks', '', '© Stores type information in the symbol table or the syntax', '', 'tree', '© Types of variables, function parameters, array dimensions,', 'ete', '«# Used not only for semantic validation but also for', 'subsequent phases of compilation', '© Static semantics of programming languages ¢', 'specified using attribute grammars', '', ' ', '\\x0c']\n2041\n['intofloat', '', 'i 48 32', '', 'Int.Code Generator', '', 'tHeid2\" 18', '', '{2 intofloat(s2)', 'Bette', 'ides', '', 'Code Optimizer', '', ' ', '\\x0c']\n2050\n['intofloat', '', 'i 48 32', '', 'Int.Code Generator', '', 'teid2\" 18', '', '12 intofloat(s2)', 'atten', 'ides', '', 'Code Optimizer', '', ' ', '\\x0c']\n2056\n['Int.Code Generator', '', 'tneid2\" 48', '', '12 intofloat(s2)', 'atte', 'ides', '', 'Code Optimizer', '', ' ', '\\x0c']\n2063\n['2) ntotoat', '', 'id? 48 32)', '', 'Int.code Generator', '', 'teid2\" 18', '', '12 intofloats2)', 'Baten', 'ides', '', 'Code Optimizer', '', ' ', '\\x0c']\n2069\n['id', '', 'Int.Code Generator', '', 'teid2\" 18', '', '12 intofloat(s2)', 'Batten', 'ites', '', 'Code Optimizer', '', ' ', '\\x0c']\n2076\n['intofloat', '', 'i 48 32', '', 'Int.Code Generator', '', 'teid2\" 18', '', '{2 intofloats2)', 'Bette', 'ites', '', 'Code Optimizer', '', ' ', '\\x0c']\n2083\n['intofloat', '', 'i 48 32', '', 'Int.code Generator', '', 'tid\" 18', '', '12 intofloats2)', 'Bette', 'ides', '', 'Code Optimizer', '', ' ', '\\x0c']\n2088\n['( intofloat', '', 'id? 48 32)', '', 'Int.Code Generator', '', 'tei\" 18', '', '12 intofloat;s2)', 'Bette', 'ides', '', 'Code Optimizer', '', ' ', '\\x0c']\n2093\n['( intofloat', '', 'id? 48 32)', '', 'Int.Code’Generator', '', 'teid2\" 18', '', '12 intofloats2)', 'tettet', 'ites', '', 'Code Optimizer', '', ' ', '\\x0c']\n2101\n['( intofloat', '', 'id? 48 32)', '', 'Int.Code Generator', '', 'teid2\" 18', '', '{2 ntofloat(s2)', 'ete', 'ides', '', 'Code Optimizer', '', ' ', '\\x0c']\n2108\n['( intofloat', '', 'id? 48 32)', '', 'Int.Code Generator', '', 'teid2\" 18', '', '12 intofloat32)', 'Bete', 'ites', '', 'Code Optimizer', '', ' ', '\\x0c']\n2114\n['intofloat', '', 'i 48 32', '', 'Int.Code Generator', '', 'teid2\" 18', '', '{2 intofloats2)', 'Bette', 'ides', '', 'Code Optimizer', '', ' ', '\\x0c']\n2125\n['@ While generating machine code directly from source code', 'is possible, it entails two problems', '‘@ With m languages and n target machines, we need to write', 'mx ncompilers', '‘© The code optimizer which is one of the largest and', 'very-dificut-to-write components of any compiler cannot be', 'reused', '', '@ By converting source code to an intermediate code, a', 'machine-independent code optimizer may be written', '', '@ Intermediate code must be easy to produce and easy to', 'translate to machine code', '', '«© A.sort of universal assembly language', '«¢ Should not contain any machine-specitc par', '(registers, addresses, etc.)', '', ' ', '\\x0c']\n2133\n['@ While generating machine code directly from source code', 'is possible, it entails two problems', '‘@ With m languages and n target machines, we need to write', 'mx ncompilers', '‘© The code optimizer which is one of the largest and', 'very-dificut-to-write components of any compiler cannot be', 'reused', '', '© By converting source code to an intermediate code, a', 'machine-independent code optimizer may be written', '', '@ Intermediate code must be easy to produce and easy to', 'translate to machine code', '', '« A sort of universal assembly language', '‘¢ Should nat contain any machine-specifc pa', '(registers, addresses, etc.)', '', ' ', '\\x0c']\n2139\n['© While generating machine code directly from source code', 'is possible, it entails two problems', '‘@ With m languages and n target machines, we need to write', 'mx ncompilers', '‘© The code optimizer which is one of the largest and', 'very-dificut-to-write components of any compiler cannot be', 'reused', '', '@ By converting source code to an intermediate code, a', 'machine-independent code optimizer may be written', '', '@ Intermediate code must be easy to produce and easy to', 'translate to machine code', '', '«A sort of universal assembly language', '‘¢ Should nat contain any machine-specifc pa', '(registers, addresses, etc.)', '', ' ', '\\x0c']\n2148\n['@ While generating machine code directly from source code', 'is possible, it entails two problems', '«© With m languages and n target machines, we need to write', 'mx ncompilers', '‘© The code optimizer which is one of the largest and', 'very-dificu-to-write components of any compiler cannot be', 'reused', '', '@ By converting source code to an intermediate code, a', 'machine-independent code optimizer may be written', '', '@ Intermediate code must be easy to produce and easy to', 'translate to machine code', '', '«© A sort of universal assembly language', '‘@ Should not contain any machine-specitic par', '(registers, addresses, etc.)', '', ' ', '\\x0c']\n2155\n['@ While generating machine code directly from source code', 'is possible, it entails two problems', '‘@ With m languages and n target machines, we need to write', 'mx ncompilers', '‘© The code optimizer which is one of the largest and', 'very-dificut-to-write components of any compiler cannot be', 'reused', '', '© By converting source code to an intermediate code, a', 'machine-independent code optimizer may be written', '', '@ Intermediate code must be easy to produce and easy to', 'translate to machine code', '', '« A sort of universal assembly language', '‘@ Should not contain any machine-specitic pars', '(registers, addresses, etc.)', '', ' ', '\\x0c']\n2162\n['@ While generating machine code directly from source code', 'is possible, it entails two problems', '‘@ With m languages and n target machines, we need to write', 'mx ncompilers', '‘© The code optimizer which is one of the largest and', 'very-dificut-to-write components of any compiler cannot be', 'reused', '', '© By converting source code to an intermediate code, a', 'machine-independent code optimizer may be written', '', '@ Intermediate code must be easy to produce and easy to', 'translate to machine code', '', '«A sort of universal assembly language', '‘¢ Should not contain any machine-specitc par', '(registers, addresses, etc.)', '', ' ', '\\x0c']\n2168\n['© While generating machine code directly from source code', 'is possible, it entails two problems', '«© With m languages and n target machines, we need to write', 'mx ncompilers', '‘© The code optimizer which is one of the largest and', 'very-dificut-to-write components of any compiler cannot be', 'reused', '', '© By converting source code to an intermediate code, a', 'machine-independent code optimizer may be written', '', '@ Intermediate code must be easy to produce and easy to', 'translate to machine code', '', '« Asort of universal assembly language', '‘¢ Should nat contain any machine-specifc par', '(registers, addresses, etc.)', '', ' ', '\\x0c']\n2175\n['intermediate Code Generation', '', '@ While generating machine code directly from source code', 'is possible, it entails two problems', '«© With m languages and n target mechines, we need to write', 'mx ncompilers', '‘© The code optimizer which is one of the largest and', 'very-dificut-to-write components of any compiler cannot be', 'reused', '', '© By converting source code to an intermediate code, a', 'machine-independent code optimizer may be written', '', '@ Intermediate code must be easy to produce and easy to', 'translate to machine code', '', '«A sort of universal assembly language', '‘¢ Should nat contain any machine-specifc par', '(registers, addresses, etc.)', '', ' ', '\\x0c']\n2182\n['@ While generating machine code directly from source code', 'is possible, it entails two problems', '‘@ With m languages and n target machines, we need to write', 'mx ncompilers 2', '‘© The code optimizer which is one of the largest and', 'very-dificut-to-write components of any compiler cannot be', 'reused', '', '@ By converting source code to an intermediate code, a', 'machine-independent code optimizer may be written', '', '@ Intermediate code must be easy to produce and easy to', 'translate to machine code', '', '« A sort of universal assembly language', '‘¢ Should nat contain any machine-specifc par', '(registers, addresses, etc.)', '', ' ', '\\x0c']\n2187\n['@ While generating machine code directly from source code', 'is possible, it entails two problems', '‘@ With m languages and n target machines, we need to write', 'mx ncompilers', '‘© The code optimizer whictfis one of the largest and', 'very-dificut-to-write components of any compiler cannot be', 'reused', '', '@ By converting source code to an intermediate code, a', 'machine-independent code optimizer may be written', '', '@ Intermediate code must be easy to produce and easy to', 'translate to machine code', '', '« A sort of universal assembly language', '«¢ Should nat contain any machine-specitc par', '(registers, addresses, etc.)', '', ' ', '\\x0c']\n2195\n['@ While generating machine code directly from source code', 'is possible, it entails two problems', '«© With m languages and n target machines, we need to write', 'mx -ncompilers', '‘© The code optimizer which is one of the largest and', 'very-dificut-to-write components of any compiler cannot be', 'reused', '', '@ By converting source code to an intermediate code, a', 'machine-independent code optimizer may be written', '', '@ Intermediate code must be easy to produce and easy to', 'translate to machine code', '', '« A sort of universal assembly language', '‘@ Should not contain any machine-specitic par}', '(registers, addresses, etc.)', '', ' ', '\\x0c']\n2204\n['© While generating machine code directly from source code', 'is possible, it entails two problems', '«© With m languages and n target machines, we need to write', 'mx ncompilers', '‘© The code optimizer which is one of the largest and', 'very-dificut-to-write components of any compiler cannot be', 'reused', '', '© By converting source code to an intermediate code, a', 'machine-independent code optimizer may be written', '', '@ Intermediate code must be easy to produce and easy to', 'translate to machine code', '', '« A sort of universal assembly language', '‘¢ Should nat contain any machine-specifc pa', '(registers, addresses, etc.)', '', ' ', '\\x0c']\n2211\n['@ While generating machine code directly from source code', 'is possible, it entails two problems', '‘@ With m languages and n target machines, we need to write', 'mx ncompilers', '‘© The code optimizer which is one of the largest and', 'very-dificu-to-write components of any compiler cannot be', 'reused', '', '© By converting source code to an intermediate code, a', 'machine-independent code optimizer may be written', '', '@ Intermediate code must be easy to produce and easy to', 'translate to machine code', '', '«A sort of universal assembly language', '‘@ Should not contain any machine-specitic pal', '(registers, addresses, etc.)', '', ' ', '\\x0c']\n2223\n['@ While generating machine code directly from source code', 'is possible, it entails two problems', '‘@ With m languages and n target machines, we need to write', 'mx ncompilers', '‘© The code optimizer which is one of the largest and', 'very-dificult-to-write components of any compiler cannot be', 'reused', '', '© By converting source code to an intermediate code, a', 'machine-independent code optimizer may be written', '', '@ Intermediate code must be easy to produce and easy to', 'translate to machine code', '', '«A sort of universal assembly language', '‘¢ Should nat contain any machine-specifc par', '(registers, addresses, etc.)', '', ' ', '\\x0c']\n2234\n['@ While generating machine code directly from source code', 'is possible, it entails two problems', '«© With m languages and n target machines, we need to write', 'mx ncompilers', '‘© The code optimizer which is one of the largest and', 'very-dificut-to-write components of any compiler cannot be', 'reused', '', '@ By converting source code to an intermediate code, a', 'machine-independent code optimizer may be written', '', '@ Intermediate code must be easy to produce and easy to', 'translate to machine code', '', '« A sort of universal assembly language', '‘¢ Should nat contain any machine-specifc pa', '(registers, addresses, etc.)', '', ' ', '\\x0c']\n2239\n['@ While generating machine code directly from source code', 'is possible, it entails two problems', '‘@ With m languages and n target machines, we need to write', 'mx ncompilers', '‘© The code optimizer which is one of the largest and', 'very-dificu-to-write components of any compiler cannot be', 'reused', '', '© By converting source code to an intermediate code, a', 'machine-independent code optimizer may be written', '', '@ Intermediate code must be easy to produce and easy to', 'translate to machine code', '', '« A sort of universal assembly language', '‘@ Should not contain any machine-specitic par', '(registers, addresses, etc.)', '', ' ', '\\x0c']\n2246\n['© While generating machine code directly from source code', 'is possible, it entails two problems', '‘@ With m languages and n target machines, we need to write', 'mx ncompilers', '‘© The code optimizer which is one of the largest and', 'very-dificut-to-write components of any compiler cannot be', 'reused', '', '@ By converting source code to an intermediate code, a', 'machine-independent code optimizer may be written', '', '@ Intermediate code must be easy to produce and easy to', 'translate to machine code', '', '« A sort of universal assembly language', '‘¢ Should not contain any machine-specitc par', '(registers, addresses, etc.)', '', ' ', '\\x0c']\n2254\n['@ While generating machine code directly from source code', 'is possible, it entails two problems', '‘@ With m languages and n target machines, we need to write', 'mx ncompilers', '‘© The code optimizer which is one of the largest and', 'very-dificut-to-write components of any compiler cannot be', 'reused', '', '© By converting source code to an intermediate code, a', 'machine-independent code optimizer may be written', '', '@ Intermediate code must be easy to produce and easy to', 'translate to machine code', '', '« A sort of universal assembly language', '+ Should nat contain any machine-specitc p', '(registers, addresses, etc.)', '', ' ', '\\x0c']\n2261\n['@ While generating machine code directly from source code', 'is possible, it entails two problems', '‘@ With m languages and n target machines, we need to write', 'mx ncompilers', '‘© The code optimizer which is one of the largest and', 'very-dificut-to-write components of any compiler cannot be', 'reused', '', '@ By converting source code to an intermediate code, a', 'machine-independent code optimizer may be written', '', '@ Intermediate code must be easy to produce and easy to', 'translate to machine code', '', '« A sort of universal assembly language', '‘¢ Should not contain any machine-specitc par', '(registers, addresses, etc.)', '', ' ', '\\x0c']\n2269\n['@ While generating machine code directly from source code', 'is possible, it entails two problems', '«© With m languages and n target machines, we need to write', 'mx ncompilers', '‘© The code optimizer which is one of the largest and', 'very-dificut-to-write components of any compiler cannot be', 'reused', '', '@ By converting source code to an intermediate code, a', 'machine-independent code optimizer may be written', '', '@ Intermediate code must be easy to produce and easy to', 'translate to machine code', '', '« A sort of universal assembly language', '‘¢ Should nat contain any machine-specifc pa', '(registers, addresses, etc.)', '', ' ', '\\x0c']\n2275\n['@ While generating machine code directly from source code', 'is possible, it entails two problems', '‘@ With m languages and n target machines, we need to write', 'mx ncompilers', '‘© The code optimizer which is one of the largest and', 'very-dificu-to-write components of any compiler cannot be', 'reused', '', '© By converting source code to an intermediate code, a', 'machine-independent code optimizer may be written', '', '@ Intermediate code must be easy to produce and easy to', 'translate to machine code', '', '« A sort of universal assembly language', '‘¢ Should nat contain any machine-specifc pa', '(registers, addresses, etc.)', '', ' ', '\\x0c']\n2282\n['@ While generating machine code directly from source code', 'is possible, it entails two problems', '«© With m languages and n target machines, we need to write', 'mx ncompilers', '‘© The code optimizer which is one of the largest and', 'very-dificut-to-write components of any compiler cannot be', 'reused', '', '© By converting source code to an intermediate code, a', 'machine-independent code optimizer may be written', '', '@ Intermediate code must be easy to produce and easy to', 'translate to machine code', '', '«© Asort of universal assembly language', '‘¢ Should nat contain any machine-specifc par', '(registers, addresses, etc.)', '', ' ', '\\x0c']\n2289\n['@ While generating machine code directly from source code', 'is possible, it entails two problems', '‘@ With m languages and n target machines, we need to write', 'mx ncompilers', '‘© The code optimizer which is one of the largest and', 'very-dificut-to-write components of any compiler cannot be', 'reused', '', '@ By converting source code to an intermediate code, a', 'machine-independent code optimizer may be written', '', '@ Intermediate code must be easy to produce and easy to', 'translate to machine code', '', '«© A.sort of universal assembly language', '«¢ Should nat contain any machine-specifc pa', '(registers, addresses, etc.)', '', ' ', '\\x0c']\n2299\n['@ While generating machine code directly from source code', 'is possible, it entails two problems', '«© With m languages and n target machines, we need to write', 'mx ncompilers', '‘© The code optimizer which is one of the largest and', 'very-dificut-to-write components of any compiler cannot be', 'reused', '', '© By converting source code to an intermediate code, a', 'machine-independent code optimizer may be written', '', '@ Intermediate code must be easy to produce and easy to', 'translate to machine code', '', '« A sort of universal assembly language', '« Should not contain any machine-specitic parameters', '(registers, addresses, etc.)', '', ' ', '\\x0c']\n2306\n['@ While generating machine code directly from source code', 'is possible, it entails two problems', '«© With m languages and n target machines, we need to write', 'mx ncompilers', '‘© The code optimizer which is one of the largest and', 'very-dificut-to-write components of any compiler cannot be', 'reused', '', '© By converting source code to an intermediate code, a', 'machine-independent code optimizer may be written', '', '@ Intermediate code must be easy to produce and easy to', 'translate to machine code', '', '« A sort of universal assembly language', '« Should not contain any machine-specific parameters', '(registers, addresses, etc.)', '', ' ', '\\x0c']\n2313\n['@ While generating machine code directly from source code', 'is possible, it entails two problems', '«© With m languages and n target machines, we need to write', 'mx ncompilers', '‘© The code optimizer which is one of the largest and', 'very-dificu-to-write components of any compiler cannot be', 'reused', '', '@ By converting source code to an intermediate code, a', 'machine-independent code optimizer may be written', '', '@ Intermediate code must be easy to produce and easy to', 'translate to machine code', '', '« A sort of universal assembly language', '«¢ Should not contain any machine-specitic parameters', '(registers, addresses, etc.)', '', ' ', '\\x0c']\n2321\n['@ While generating machine code directly from source code', 'is possible, it entails two problems', '«© With m languages and n target machines, we need to write', 'mx ncompilers', '‘© The code optimizer which is one of the largest and', 'very-dificut-to-write components of any compiler cannot be', 'reused', '', '@ By converting source code to an intermediate code, a', 'machine-independent code optimizer may be written', '', '@ Intermediate code must be easy to produce and easy to', 'translate to machine code', '', '« A sort of universal assembly language', '«¢ Should not contain any machine-specific parameters', '(registers, addresses, etc.)', '', ' ', '\\x0c']\n2327\n['@ While generating machine code directly from source code', 'is possible, it entails two problems', '«© With m languages and n target machines, we need to write', 'mx ncompilers', '‘© The code optimizer which is one of the largest and', 'very-dificut-to-write components of any compiler cannot be', 'reused', '', '© By converting source code to an intermediate code, a', 'machine-independent code optimizer may be written', '', '@ Intermediate code must be easy to produce and easy to', 'translate to machine code', '', '« Asort of universal assembly language', '« Should not contain any machine-spectic parameters', '(registers, addresses, etc.)', '', ' ', '\\x0c']\n2334\n['intermediate Code Generation', '', '‘© While generating machine code directly from source code', 'is possible, it entails two problems', '«© With m languages and n target machines, we need to write', 'mx ncompilers', '‘© The code optimizer which is one of the largest and', 'very-dificut-to-write components of any compiler cannot be', 'reused', '', '@ By converting source code to an intermediate code, a', 'machine independent code optimizer may be written', '@ Intermediate code must be easy to produce and easy to', 'translate to machine code', '«© Asort of universal assembly language', '« Should not contain any machine-specitic parameters', '(registers, addresses, etc.)', '', ' ', '\\x0c']\n2342\n['While generating machine code directly from source code', 'is possible, it entails two problems', '‘© With m languages and n target machines, we need to write', 'mx ncompilers', '‘© The code optimizer which is one of the largest and', 'very-dificut-to-write components of any compiler cannot be', 'reused', '', '@ By converting source code to an intermediate code, a', 'machine-independent code optimizer may be written', '', '@ Intermediate code must be easy to produce and easy to', 'translate to machine code', '', '« A sort of universal assembly language', '« Should not contain any machine-specitic parameters', '(registers, addresses, etc.)', '', ' ', '\\x0c']\n2348\n['@ While generating machine code directly from source code', 'is possible, it entails two problems', '«© With m languages and n target machines, we need to write', 'mx -ncompilers', '‘© The code optimizer which is one of the largest and', 'very-dificu-to-write components of any compiler cannot be', 'reused', '', '© By converting source code to an intermediate code, a', 'machine-independent code optimizer may be written', '', '@ Intermediate code must be easy to produce and easy to', 'translate to machine code', '', '« A sort of universal assembly language', '« Should not contain any machine-specitic parameters', '(registers, addresses, etc.)', '', ' ', '\\x0c']\n2356\n['@ While generating machine code directly from source code', 'is possible, it entails two problems', '«© With m languages and n target machines, we need to write', 'mesncompilers', '‘© The code optimizer which is one of the largest and', 'very-dificut-to-write components of any compiler cannot be', 'reused', '', '© By converting source code to an intermediate code, a', 'machine-independent code optimizer may be written', '', '@ Intermediate code must be easy to produce and easy to', 'translate to machine code', '', '« A sort of universal assembly language', '« Should not contain any machine-specitic parameters', '(registers, addresses, etc.)', '', ' ', '\\x0c']\n2363\n['© While generating machine code directly from source code', 'is possible, it entails two problems', '«© With m languages and n target machines, we need to write', 'mx ncompilers', '‘© The code optimizer which is one of the largest and', 'very-dificut-to-write components of any compiler cannot be', 'reused', '', '© By converting source code to an intermediate code, a', 'machine-independent code optimizer may be written', '', '@ Intermediate code must be easy to produce and easy to', 'translate to machine code', '', '« Asort of universal assembly language', '« Should not contain any machine-spectic parameters', '(registers, addresses, etc.)', '', ' ', '\\x0c']\n2370\n['@ While generating machine code directly from source code', 'is possible, it entails two problems', '‘@ With m languages and n target machines, we need to write', 'mx -ncompilers', '‘© The code optimizer which is one of the largest and', 'very-dificu-to-write components of any compiler cannot be', 'reused', '', '© By converting source code to an intermediate code, a', 'machine-independent code optimizer may be written', '', '@ Intermediate code must be easy to produce and easy to', 'translate to machine code', '', '«A sort of universal assembly language', '« Should not contain any machine-specitic parameters', '(registers, addresses, etc.)', '', ' ', '\\x0c']\n2377\n['@ While generating machine code directly from source code', 'is possible, it entails two problems', '«© With m languages and n target machines, we need to write', 'mx ncompilers', '‘© The code optimizer which is one of the largest and', 'very-dificut-to-write components of any compiler cannot be', 'reused', '', '© By converting source code to an intermediate code, a', 'machine-independent code optimizer may be written', '', '@ Intermediate code must be easy to produce and easy to', 'translate to machine code', '', '« A sort of universal assembly language', '‘® Should not contain any machine-specitic parameters', '(registers, addresses, etc.)', '', ' ', '\\x0c']\n2383\n['@ While generating machine code directly from source code', 'is possible, it entails two problems', '«© With m languages and n target machines, we need to write', 'mx ncompilers', '‘© The code optimizer which is one of the largest and', 'very-dificut-to-write components of any compiler cannot be', 'reused', '', '© By converting source code to an intermediate code, a', 'machine-independent code optimizer may be written', '', '@ Intermediate code must be easy to produce and easy to', 'translate to machine code', '', '« Asort of universal assembly language', '«© Should not contain any machine-spectic parameters', '(registers, addresses, etc.)', '', ' ', '\\x0c']\n2389\n['@ While generating machine code directly from source code', 'is possible, it entails two problems', '«© With m languages and n target machines, we need to write', 'mx -ncompilers', '‘© The code optimizer which is one of the largest and', 'very-dificut-to-write components of any compiler cannot be', 'reused', '', '@ By converting source code to an intermediate code, a', 'machine-independent code optimizer may be written', '', '@ Intermediate code must be easy to produce and easy to', 'translate to machine code', '', '« Asort of universal assembly language', '«¢ Should not contain any machine-spectic parameters', '(registers, addresses, etc.)', '', ' ', '\\x0c']\n2394\n['© While generating machine code directly from source code', 'is possible, it entails two problems', '«© With m languages and n target machines, we need to write', 'mx ncompilers', '‘© The code optimizer which is one of the largest and', 'very-dificut-to-write components of any compiler cannot be', 'reused', '', '© By converting source code to an intermediate code, a', 'machine-independent code optimizer may be written', '', '@ Intermediate code must be easy, to produce and easy to', 'translate to machine code', '', '«A sort of universal assembly language', '« Should not contain any machine-specific parameters', '(registers, addresses, etc.)', '', ' ', '\\x0c']\n2404\n['@ While generating machine code directly from source code', 'is possible, it entails two problems', '«© With m languages and n target machines, we need to write', 'mx ncompilers', '‘© The code optimizer which is one of the largest and', 'very-dificu-to-write components of any compiler cannot be', 'reused', '', '@ By converting source code to an intermediate code, a', 'machine-independent code optimizer may be written', '', '@ Intermediate code must be easy to produce and easy to', 'translate to machine code', '', '« A sort of universal assembly language', '« Should not contain any machine-specitic parameters', '(registers, addresses, etc.)', '', ' ', '\\x0c']\n2410\n['@ While generating machine code directly from source code', 'is possible, it entails two problems', '«© With m languages and n target machines, we need to write', 'mx ncompilers', '‘© The code optimizer which is one of the largest and', 'very-dificu-to-write components of any compiler cannot be', 'reused', '', '© By converting source code to an intermediate code, a', 'machine-independent code optimizer may be written', '', '@ Intermediate code must be easy to produce and easy to', 'translate to machine code .', '', '« A sort of universal assembly language', '‘ Should not contain any machine-specific parameters', '(registers, addresses, etc.)', '', ' ', '\\x0c']\n2415\n['‘@ While generating machine code directly from source code', 'is possible, it entails two problems', '«© With m languages and n target machines, we need to write', 'mx ncompilers', '‘© The code optimizer which is one of the largest and', 'very-dificut-to-write components of any compiler cannot be', 'reused', '', '@ By converting source code to an intermediate code, a', 'machine-independent code optimizer may be written', '', '@ Intermediate code must be easy to produce and easy to', 'translate to machine code', '', '«© Asort of universal assembly language', '« Should not contain any machine-spectic parameters', '(registers, addresses, etc.)', '', ' ', '\\x0c']\n2422\n['@ While generating machine code directly from source code', 'is possible, it entails two problems', '«© With m languages and n target machines, we need to write', 'mx ncompilers', '‘© The code optimizer which is one of the largest and', 'very-dificut-to-write components of any compiler cannot be', 'reused', '', '© By converting source code to an intermediate code, a', 'machine-independent code optimizer may be written', '', '@ Intermediate code must be easy to produce and easy to', 'translate to machine code', '', '« Asort of universal assembly language', '« Should not contain any machine-spectic parameters', '(registers, addresses, etc.)', '', ' ', '\\x0c']\n2432\n['© The type of intermediate code deployed is based on the', 'application', '', '© Quadruples, triples, indirect triples, abstract syntax trees', 'are the classical forms used for machine-independent', 'optimizations and machine code generation', '', '@ Static Single Assignment form (SSA) is a recent form and', '', 'enables more effective optimizations', '# Conditional constant propagation and global value', 'numbering are more effective on SSA', '© Program Dependence Graph (PDG) is useful in automatic', 'parallelization, instruction scheduling, and software', 'pipelining', '', ' ', '\\x0c']\n2439\n['© The type of intermediate code deployed is based on the', 'application', '', '© Quadruples, triples, indirect triples, abstract syntax trees', 'are the classical forms used for machine-independent', 'optimizations and machine code generation', '', '@ Static Single Assignment form (SSA) is a recent form and', '', 'enables more effective optimizations', '# Conditional constant propagation and global value', 'numbering are more effective on SSA', '@ Program Dependence Graph (PDG) is useful in automatic', 'parallelization, instruction scheduling, and sof', 'Pipelining', '', ' ', '\\x0c']\n2446\n['© The type of intermediate code deployed is based on the', 'application', '', '© Quadruples, triples, indirect triples, abstract syntax trees', 'are the classical forms used for machine-independent', 'optimizations and machine code generation', '', '@ Static Single Assignment form (SSA) is a recent form and', '', 'enables more effective optimizations', '# Conditional constant propagation and global value', 'numbering are more effective on SSA', '© Program Dependence Graph (PDG) is useful in automatic', 'parallelization, instruction scheduling, and so', 'pipelining', '', ' ', '\\x0c']\n2452\n['© The type of intermediate code deployed is based on the', 'application', '', '© Quadruples, triples, indirect triples, abstract syntax trees', 'are the classical forms used for machine-independent', 'optimizations and machine code generation', '', '@ Static Single Assignment form (SSA) is a recent form and', '', 'enables more effective optimizations', '© Conditional constant propagation and global value', 'numbering are more effective on SSA', '© Program Dependence Graph (PDG) is useful in automatic', 'parallelization, instruction scheduling, and so', 'pipelining', '', ' ', '\\x0c']\n2459\n['© The type of intermediate code deployed is based on the', 'application', '', '© Quadruples, triples, indirect triples, abstract syntax trees', 'are the classical forms used for machine-independent', 'optimizations and machine code generation', '', '@ Static Single Assignment form (SSA) is a recent form and', '', 'enables more effective optimizations', '© Conditional constant propagation and global value', 'numbering are more effective on SSA', '© Program Dependence Graph (PDG) is useful in automatic', 'parallelization, instruction scheduling, and so', 'Pipelining', '', ' ', '\\x0c']\n2465\n['© The type of intermediate code deployed is based on the', 'application', '', '© Quadruples, triples, indirect triples, abstract syntax trees', 'are the classical forms used for machine-independent', 'optimizations and machine code generation', '', '@ Static Single Assignment form (SSA) is a recent form and', '', 'enables more effective optimizations', '# Conditional constant propagation and global value', 'numbering are more effective on SSA', '@ Program Dependence Graph (PDG) is useful in automatic', 'parallelization, instruction scheduling, and so', 'Pipelining', '', ' ', '\\x0c']\n2473\n['© The type of intermediate code deployed is based on the', 'application', '', '© Quadruples, triples, indirect triples, abstract syntax trees', 'are the classical forms used for machine-independent', 'optimizations and machine code generation', '', '@ Static Single Assignment form (SSA) is a recent form and', '', 'enables more effective optimizations', '# Conditional constant propagation and global value', 'numbering are more effective on SSA', '@ Program Dependence Graph (PDG) is useful in automatic', 'parallelization, instruction scheduling, and so', 'Pipelining', '', ' ', '\\x0c']\n2480\n['© The type of intermediate code deployed is based on the', 'application', '', '© Quadruples, triples, indirect triples, abstract syntax trees', 'are the classical forms used for machine-independent', 'optimizations and machine code generation', '', '@ Static Single Assignment form (SSA) is a recent form and', '', 'enables more effective optimizations', '«# Conditional constant propagation and global value', 'numbering are more effective on SSA', '@ Program Dependence Graph (PDG) is useful in automatic', 'parallelization, instruction scheduling, and so', 'Pipelining', '', ' ', '\\x0c']\n2488\n['© The type of intermediate code deployed is based on the', 'application', '', '© Quadruples, triples, indirect triples, abstract syntax trees', 'are the classical forms used for machine-independent', 'optimizations and machine code generation', '', '@ Static Single Assignment form (SSA) is a recent form and', '', 'enables more effective optimizations', '# Conditional constant propagation and global value', 'numbering are more effective on SSA', '© Program Dependence Graph (DG) is useful in automatic', 'parallelization, instruction scheduling, and so', 'pipelining', '', ' ', '\\x0c']\n2496\n['© The type of intermediate code deployed is based on the', 'application', '', '© Quadruples, triples, indirect triples, abstract syntax trees', 'are the classical forms used for machine-independent', 'optimizations and machine code generation', '', '@ Static Single Assignment form (SSA) is a recent form and', '', 'enables more effective optimizations', '© Conditional constant propagation and global value', 'numbering are more effective on SSA', '@ Program Dependence Graph (DG) is useful in automatic', 'parallelization, instruction scheduling, and so', 'Pipelining', '', ' ', '\\x0c']\n2504\n['© The type of intermediate code deployed is based on the', 'application', '', '© Quadruples, triples, indirect triples, abstract syntax trees', 'are the classical forms used for machine-independent', 'optimizations and machine code generation', '', '@ Static Single Assignment form (SSA) is a recent form and', '', 'enables more effective optimizations', '# Conditional constant propagation and global value', 'numbering are more effective on SSA', '@ Program Dependence Graph (PDG) is useful in automatic', 'parallelization, instruction scheduling, and so', 'Pipelining', '', ' ', '\\x0c']\n2509\n['© The type of intermediate code deployed is based on the', 'application', '', '© Quadruples, triples, indirect triples, abstract syntax trees', 'are the classical forms used for machine-independent', 'optimizations and machine code generation', '', '@ Static Single Assignment form (SSA) is a recent form and', '', 'enables more effective optimizations', '# Conditional constant propagation and global value', 'numbering are more effective on SSA', '© Program Dependence Graph (DG) is useful in automatic', 'parallelization, instruction scheduling, and so', 'Pipelining', '', ' ', '\\x0c']\n2517\n['© The type of intermediate code deployed is based on the', 'application', '', '© Quadruples, triples, indirect triples, abstract syntax trees', 'are the classical forms used for machine-independent', 'optimizations and machine code generation', '', '@ Static Single Assignment form (SSA) is a recent form and', '', 'enables more effective optimizations', '«# Conditional constant propagation and global value', 'numbering are more effective on SSA', '@ Program Dependence Graph (PDG) is useful in automatic', 'parallelization, instruction scheduling, and so', 'Pipelining', '', ' ', '\\x0c']\n2523\n['ferent Types of Intermediate Code', '', '@ The type of intermediate code deployed is based on the', 'application', '', '‘© Quadruples, triples, indirect triples, abstract syntax trees.', 'are the classical forms used for machine-independent', 'optimizations and machine code generation', '', '@ Static Single Assignment form (SSA) is a recent form and', 'enables more effective optimizations', '', '# Conditional constant propagation and global value', 'numbering are more effective on SSA', '', '@ Program Dependence Graph (PDG) is useful in automatic', 'parallelization, instruction scheduling, and sof', 'Pipelining', '', ' ', '\\x0c']\n2530\n['© The type of intermediate code deployed is based on the', 'application', '', '© Quadruples, triples, indirect triples, abstract syntax trees', 'are the classical forms used for machine-independent', 'optimizations and machine code generation', '', '@ Static Single Assignment form (SSA) is a recent form and', '', 'enables more effective optimizations', '# Conditional constant propagation and global value', 'numbering are more effective on SSA', '© Program Dependence Graph (DG) is useful in automatic', 'parallelization, instruction scheduling, and so', 'pipelining', '', ' ', '\\x0c']\n2536\n['© The type of intermediate code deployed is based on the', 'application', '', '© Quadruples, triples, indirect triples, abstract syntax trees', 'are the classical forms used for machine-independent', 'optimizations and machine code generation', '', '@ Static Single Assignment form (SSA) is a recent form and', '', 'enables more effective optimizations', '© Conditional constant propagation and global value', 'numbering are more effective on SSA', '© Program Dependence Graph (PDG) is useful in automatic', 'parallelization, instruction scheduling, and so', 'Pipelining', '', ' ', '\\x0c']\n2542\n['ferent Types of Intermediate Code', '', '@ The type of intermediate code deployed is based on the', 'application', '', '© Quadruples, triples, indirect triples, abstract syntax trees.', 'are the classical forms used for machine-independent', 'optimizations and machine code generation', '', '@ Static Single Assignment form (SSA) is a recent form and', 'enables more effective optimizations', '', '«© Conditional constant propagation and global value', 'numbering are more effective on SSA', '', '@ Program Dependence Graph (PDG) is useful in automatic', 'parallelization, instruction scheduling, and sof', 'Pipelining', '', ' ', '\\x0c']\n2547\n['© The type of intermediate code deployed is based on the', 'application', '', '© Quadruples, triples, indirect triples, abstract syntax trees', 'are the classical forms used for machine-independent', 'optimizations and machine code generation', '', '@ Static Single Assignment form (SSA) is a recent form and', '', 'enables more effective optimizations', '# Conditional constant propagation and global value', 'numbering are more effective on SSA', '@ Program Dependence Graph (PDG) is useful in automatic', 'parallelization, instruction scheduling, and sof', 'pipelining', '', ' ', '\\x0c']\n2555\n['© The type of intermediate code deployed is based on the', 'application', '', '© Quadruples, triples, indirect triples, abstract syntax trees', 'are the classical forms used for machine-independent', 'optimizations and machine code generation', '', '@ Static Single Assignment form (SSA) is a recent form and', '', 'enables more effective optimizations', '# Conditional constant propagation and global value', 'numbering are more effective on SSA', '© Program Dependence Graph (DG) is useful in automatic', 'parallelization, instruction scheduling, and software', 'pipelining', '', ' ', '\\x0c']\n2562\n['© The type of intermediate code deployed is based on the', 'application', '', '© Quadruples, triples, indirect triples, abstract syntax trees', 'are the classical forms used for machine-independent', 'optimizations and machine code generation', '', '@ Static Single Assignment form (SSA) is a recent form and', '', 'enables more effective optimizations', '«# Conditional constant propagation and global value', 'numbering are more effective on SSA', '@ Program Dependence Graph (PDG) is useful in automatic', 'parallelization, instruction scheduling, and software', 'pipelining', '', ' ', '\\x0c']\n2570\n['© The type of intermediate code deployed is based on the', 'application', '', '© Quadruples, triples, indirect triples, abstract syntax trees', 'are the classical forms used for machine-independent', 'optimizations and machine code generation', '', '@ Static Single Assignment form (SSA) is a recent form and', '', 'enables more effective optimizations', '# Conditional constant propagation and global value', 'numbering are more effective on SSA', '‘@ Program Dependence Graph (PDG) is useful in automatic', 'parallelization, instruction scheduling, and software', 'pipelining', '', ' ', '\\x0c']\n2578\n['© The type of intermediate code deployed is based on the', 'application', '', '© Quadruples, triples, indirect triples, abstract syntax trees', 'are the classical forms used for machine-independent', 'optimizations and machine code generation', '', '@ Static Single Assignment form (SSA) is a recent form and', '', 'enables more effective optimizations', '«# Conditional constant propagation and global value', 'numbering are more effective on SSA', '@ Program Dependence Graph (PDG) is useful in automatic', 'parallelization, instruction scheduling, and software', 'pipelining', '', ' ', '\\x0c']\n2584\n['© The type of intermediate code deployed is based on the', 'application', '', '© Quadruples, triples, indirect triples, abstract syntax trees', 'are the classical forms used for machine-independent', 'optimizations and machine code generation', '', '@ Static Single Assignment form (SSA) is a recent form and', '', 'enables more effective optimizations', '# Conditional constant propagation and global value', 'numbering are more effective on SSA', '© Program Dependence Graph (PDG) is useful in automatic', 'parallelization, instruction scheduling, and software', 'pipelining', '', ' ', '\\x0c']\n2590\n['© The type of intermediate code deployed is based on the', 'application', '', '© Quadruples, triples, indirect triples, abstract syntax trees', 'are the classical forms used for machine-independent', 'optimizations and machine code generation', '', '@ Static Single Assignment form (SSA) is a recent form and', '', 'enables more effective optimizations', '«© Conditional constant propagation and global value', 'numbering are more effective on SSA', '@ Program Dependence Graph (PDG) is useful in automatic', 'parallelization, instruction scheduling, and software', 'pipelining', '', ' ', '\\x0c']\n2597\n['© The type of intermediate code deployed is based on the', 'application', '', '© Quadruples, triples, indirect triples, abstract syntax trees', 'are the classical forms used for machine-independent', 'optimizations and machine code generation', '', '@ Static Single Assignment form (SSA) is a recent form and', '', 'enables more effective optimizations', '# Conditional constant propagation and global value', 'numbering are more effective on SSA', '© Program Dependence Graph (PDG) is useful in automatic', 'parallelization, instruction scheduling, and software', 'pipelining', '', ' ', '\\x0c']\n2602\n['tt=ia2\"18,', '{2 intofloats2)', 'Bene', 'ites', '', 'Code Optimizer', '', 'teid2\" 18', 'idt=t1 +320', '', 'Code Generator', '', ' ', '\\x0c']\n2612\n['tt=ia2-18,', '{2 intoftoats2)', 'Bete', 'ides', '', 'Code Optimizer', '', 'tea\" 18', 'idt=tt +320', '', 'Code Generator', '', ' ', '\\x0c']\n2618\n['tt=ia2\"18,', '{2 intoftoats2)', 'Benen', 'ites', '', 'Code Optimizer', '', 'tsid2\" 18', 'dt =t1 +320', '', 'Code Generator', '', ' ', '\\x0c']\n2625\n['tr=ia2\"18,', '{2 intofloats2)', 'Bene', 'ites', '', 'Code Optimizer', '', 'tila\" 48', 'idt=t1 +320', '', 'Code Generator', '', ' ', '\\x0c']\n2631\n['tt=ia2\"18,', '{2 intoftoats2)', 'Benen', 'ites', '', 'Code Optimizer', '', 'tia\" 18', 'idt=tt+320', '', 'Code Generator', '', ' ', '\\x0c']\n2637\n['t=ia2\"18,', '{2 intofloats2)', 'Bene', 'ites', '', 'Code Optimizer', '', 'tid?\" 18', 'idt=tt+320', '', 'Code Generator', '', ' ', '\\x0c']\n2644\n['t=ia2\"18,', '{2 intottoat32)', 'Benen', 'ides', '', 'Code Optimizer', '', 'tid2\" 18', 'idt=tt +329', '', 'Code Generator', '', ' ', '\\x0c']\n2651\n['t=ia2-18,', '{2 intoftoats2)', 'Benen', 'iets', '', 'Code Optimizer', '', 'tsid2\" 18', 'idi=tt+320', '', 'Code Generator', '', ' ', '\\x0c']\n2662\n['t=ia2\"18,', '{2 intoftoats2)', 'Bete', '', 'ig et3', '', 'Code Optimizer', '', 'teid2\" 18', 'idt=tt +320', '', 'Code Generator', '', ' ', '\\x0c']\n2668\n['tt=ia2\"18,', '{2 intoftoat32)', 'Benen', 'ides', '', 'Code Optimizer', '', 'tid2\" 18', 'idt=tt+320', '', 'Code Generator', '', ' ', '\\x0c']\n2676\n['®', '', ' ', '', '@ Intermediate code generation process introduces many', 'inefficiencies', '', '«# Extra copies of variables, using variables instead of', 'constants, repeated evaluation of expressions, ee.', '© Code optimization removes such inefficiencies and', 'improves code', '© Improvement may be time, space, or power consumption', '@ It changes the structure of programs, sometimes of beyond', 'recognition', '@ Inlines functions, unroll8 loops, eliminates some', 'programmer-defined variables, et.', '@ Code optimization consists of a bunch of heug id', 'percentage of improvement depends on prog ay be', 'zer0 also)', '\\x0c']\n2683\n['®', '', ' ', '', 'imization', '', '@ Intermediate code generation process introduces many', 'inefficiencies', '', '«@ Extra copies of variables, using variables instead of', 'constants, repeated evaluation of expressions, etc.', '© Code optimization removes such inefficiencies and', 'improves code', '@ Improvement may be time, space, or power consumption', '@ It changes the structure of programs, sometimes of beyond', 'recognition', '« lInlnes functions, unrolis loops, eliminates some', 'programmer-defined variables, et.', '© Code optimization consists of a bunch of heuy id', 'percentage of improvement depends on prog ay be', 'ze10 also)', '\\x0c']\n2690\n['©', '', ' ', '', 'imization', '', '@ Intermediate code generation process introduces many', 'inefficiencies', '', '«# Extra copies of variables, using variables instead of', 'constants, repeated evaluation of expressions, et.', '© Code optimization removes such inefficiencies and', 'improves code', '© Improvement may be time, space, or power consumption', '@ It changes the structure of programs, sometimes of beyond', 'recognition', '« Inlnes functions, unrolls loops, eliminates some', 'programmer-defined variables, et.', '@ Code optimization consists of a bunch of heug id', 'percentage of improvement depends on prog ay be', 'zer0 also)', '\\x0c']\n2698\n[' ', '', 'mization', '', '@ Intermediate code generation process introduces many', 'inefficiencies', '', '«# Extra copies of variables, using variables instead of', 'constants, repeated evaluation of expressions, ee.', '© Code optimization removes such inefficiencies and', 'improves code', '© Improvement may be time, space, or power consumption', '', '@ It changes the structure of programs, sometimes of beyond', 'recognition', '« Inlnes functions, unrolis loops, eliminates some', 'programmer-defined variables, et.', '@ Code optimization consists of a bunch of heuy id', 'percentage of improvement depends on prog ay be', '', '@ zero also)', '\\x0c']\n2704\n['©', '', ' ', '', '@ Intermediate code generation process introduces many', 'inefficiencies', '', '« Extra copies of variables, using variables instead of', 'constants, repeated evaluation of expressions, etc.', '© Code optimization removes such inefficiencies and', 'improves code', '@ Improvement may be time, space, or power consumption', '@ It changes the structure of programs, sometimes of beyond', 'recognition', '« Inlines functions, unrolls loops, eliminates some', 'programmer-defined variables, etc.', '© Code optimization consists of a bunch of heu d', 'percentage of improvement depends on prog ay be', 'zer0 also)', '\\x0c']\n2709\n['©', '', ' ', '', 'imization', '', '@ Intermediate code generation process introduces many', 'inefficiencies', '', '«@ Extra copies of variables, using variables instead of', 'constants, repeated evaluation of expressions, ete.', '© Code optimization removes such inefficiencies and', 'improves code', '© Improvement may be time, space, or power consumption', '@ It changes the structure of programs, sometimes of beyond', 'recognition', '« Inlines functions, unrolls loops, eliminates some', 'programmer-defined variables, ec.', '@ Code optimization consists of a bunch of heus id', 'percentage of improvement depends on prog ay be', 'zer0 also)', '\\x0c']\n2717\n[' ', '', 'imization', '', '@ Intermediate code generation process introduces many', 'inefficiencies', '', '«# Extra copies of variables, using variables instead of', 'constants, repeated evaluation of expressions, et.', '© Code optimization removes such inefficiencies and', 'improves code', '© Improvement may be time, space, or power consumption', '', '@ It changes the structure of programs, sometimes of beyond', 'recognition', '« Inlines functions, unrolls loops, eliminates some', 'programmer-defined variables, et.', '@ Code optimization consists of a bunch of heuy id', 'percentage of improvement depends on prog ay be', '', '@ zero also)', '\\x0c']\n2722\n['©', '', ' ', '', 'imization', '', '@ Intermediate code generation process introduces many', 'inefficiencies', '', '«# Extra copies of variables, using variables instead of', 'constants, repeated evaluation of expressions, et.', '© Code optimization removes such inefficiencies and', 'improves code', '© Improvement may be time, space, or power consumption', '© It changes the structure of programs, sometimes of beyond', 'recognition', '« Inlines functions, unroli loops, eliminates some', 'programmer-defined variables, et.', '@ Code optimization consists of a bunch of heut id', 'percentage of improvement depends on progi jay be', 'zer0 also)', '\\x0c']\n2731\n['®', '', ' ', '', 'imization', '', '@ Intermediate code generation process introduces many', 'inefficiencies', '', '« Extra copies of variables, using variables instead of', 'constants, repeated evaluation of expressions, etc.', '© Code optimization removes such inefficiencies and', 'improves code', '@ Improvement may be time, space, or power consumption', '@ It changes the structure of programs, sometimes of beyond', 'recognition', '« lInlnes functions, unroli loops, eliminates some', 'programmer-defined variables, et.', '© Code optimization consists of a bunch of het nd', 'percentage of improvement depends on pro ay be', 'zer0 also)', '\\x0c']\n2739\n[' ', '', 'mization', '', '@ Intermediate code generation process introduces many', 'inefficiencies', '', '«@ Extra copies of variables, using variables instead of', 'constants, repeated evaluation of expressions, ee.', '© Code optimization removes such inefficiencies and', 'improves code', '© Improvement may be time, space, or power consumption', '', '@ It changes the structure of programs, sometimes of beyond', 'recognition', '« Inlines functions, unroll loops, eliminates some', 'programmer-defined variables, et.', '@ Code optimization consists of a bunch of heug', 'percentage of improvement depends on prog', '', '@ zero also)', '\\x0c']\n2745\n['®', '', ' ', '', '@ Intermediate code generation process introduces many', 'inefficiencies', '', '«# Extra copies of variables, using variables instead of', 'constants, repeated evaluation of expressions, et.', '© Code optimization removes such inefficiencies and', 'improves code', '© Improvement may be time, space, or power consumption', '© It changes the structure of programs, sometimes of beyond', 'recognition', '« lInlnes functions, unrolls loops, eliminates some', 'programmer-defined variables, et.', '@ Code optimization consists of a bunch of heu', 'percentage of improvement depends on prog', 'zer0 also)', '\\x0c']\n2752\n[' ', '', 'imization', '', '@ Intermediate code generation process introduces many', 'inefficiencies', '', '«# Extra copies of variables, using variables instead of', 'constants, repeated evaluation of expressions, etc.', '© Code optimization removes such inefficiencies and', 'improves code', '© Improvement may be time, space, or power consumption', '', '@ It changes the structure of programs, sometimes of beyond', 'recognition', '« Inlnes functions, unroll loops, eliminates some', 'programmer-defined variables, et.', '@ Code optimization consists of a bunch of heuy id', 'percentage of improvement depends on prog ay be', '', '@ zero also)', '\\x0c']\n2757\n['©', '', 'aren,', '', ' ', '', 'imization', '', '@ Intermediate code generation process introduces many', 'inefficiencies', '', '«@ Extra copies of variables, using variables instead of', 'constants, repeated evaluation of expressions, et.', '© Code optimization removes such inefficiencies and', 'improves code', '© Improvement may be time, space, or power consumption', '© It changes the structure of programs, sometimes of beyond', 'recognition', '« Inlnes functions, unrolls loops, eliminates some', 'programmer-defined variables, et.', '@ Code optimization consists of a bunch of heuy id', 'percentage of improvement depends on prog ay be', 'zero also)', '\\x0c']\n2763\n['©', '', ' ', '', 'imization', '', '@ Intermediate code generation process introduces many', 'inefficiencies', '', '«@ Extra copies of variables, using variables instead of', 'constants, repeated evaluation of expressions, et.', '© Code optimization removes such inefficiencies and', 'improves code', '© Improvement may be time, space, or power consumption', '@ It changes the structure of programs, sometimes of beyond', 'recognition', '« lInlnes functions, unrolls loops, eliminates some', 'programmer-defined variables, et.', '@ Code optimization consists of a bunch of heug id', 'percentage of improvement depends on prog ay be', 'zero also)', '\\x0c']\n2766\n['®', '', ' ', '', 'imization', '', '@ Intermediate code generation process introduces many', 'inefficiencies', '', '«# Extra copies of variables, using variables instead of', 'constants, repeated evaluation of expressions, etc.', '© Code optimization removes such inefficiencies and', 'improves code', '© Improvement may be time, space, or power consumption', '@ It changes the structure of programs, sometimes of beyond', 'recognition', '« Inlnes functions, unroll loops, eliminates some', 'programmer-defined variables, et.', '@ Code optimization consists of a bunch of heug nd', 'percentage of improvement depends on pro, ay be', 'zero also)', '\\x0c']\n2772\n['®', '', ' ', '', 'mization', '', '@ Intermediate code generation process introduces many', 'inefficiencies', '', '«# Extra copies of variables, using variables instead of', 'constants, repeated evaluation of expressions, et.', '© Code optimization removes such inefficiencies and', 'improves code', '© Improvement may be time, space, or power consumption', '@ It changes the structure of programs, sometimes of beyond', 'recognition', '« lInlines functions, unrolis loops, eliminates some', 'programmer-defined variables, et.', '@ Code optimization consists of a bunch of het nd', 'percentage of improvement depends on pro, ay be', 'zer0 also)', '\\x0c']\n2777\n['®', '', ' ', '', 'mization', '', '@ Intermediate code generation process introduces many', 'inefficiencies', '', '«© Extra copies of variables, using variables instead of', 'constants, repeated evaluation of expressions, etc.', '© Code optimization removes such inefficiencies and', 'improves code', '@ Improvement may be time, space, or power consumption', '@ It changes the structure of programs, sometimes of beyond', 'recognition', '«@ Inlines functions, unrols loops, eliminates some', 'programmer-defined variables, etc.', '© Code optimization consists of a bunch of het', 'percentage of improvement depends on pro', 'zer0 also)', '\\x0c']\n2782\n['©', '', ' ', '', '@ Intermediate code generation process introduces many', 'inefficiencies', '', '«# Extra copies of variables, using variables instead of', 'constants, repeated evaluation of expressions, etc.', '© Code optimization removes such inefficiencies and', 'improves code', '© Improvement may be time, space, or power consumption', '© It changes the structure of programs, sometimes of beyond', 'recognition', '« Inlnes functions, unolls loops, eliminates some', 'programmer-defined variables, et.', '@ Code optimization consists of a bunch of heug ind', 'percentage of improvement depends on prog ay be', 'zero also)', '\\x0c']\n2789\n['©', '', 'aera.', '', ' ', '', '@ Intermediate code generation process introduces many', 'inefficiencies', '', '«# Extra copies of variables, using variables instead of', 'constants, repeated evaluation of expressions, et.', '© Code optimization removes such inefficiencies and', 'improves code', '© Improvement may be time, space, or power consumption', '@ It changes the structure of programs, sometimes of beyond', 'recognition', '« Inlines functions, unrolls loops, eliminates some', 'programmer-defined variables, et.', '@ Code optimization consists of a bunch of heuy id', 'percentage of improvement depends on prog ay be', 'zer0 also)', '\\x0c']\n2796\n[' ', '', 'imization', '', '@ Intermediate code generation process introduces many', 'inefficiencies', '', '«@ Extra copies of variables, using variables instead of', 'constants, repeated evaluation of expressions, etc.', '© Code optimization removes such inefficiencies and', 'improves code', '© Improvement may be time, space, or power consumption', '', '@ It changes the structure of programs, sometimes of beyond', 'recognition', '« lInlnes functions, unrolls loops, eliminates some', 'programmer-defined variables, et.', '@ Code optimization consists of a bunch of heuy id', 'percentage of improvement depends on prog ay be', '', '@ zero also)', '\\x0c']\n2801\n[' ', '', '@ Intermediate code generation process introduces many', 'inefficiencies', '', '«# Extra copies of variables, using variables instead of', 'constants, repeated evaluation of expressions, etc.', '© Code optimization removes such inefficiencies and', 'improves code', '© Improvement may be time, space, or power consumption', '', '@ It changes the structure of programs, sometimes of beyond', 'recognition', '« Inlines functions, unrolls loops, eliminates some', 'programmer-defined variables, et.', '@ Code optimization consists of a bunch of heuy id', 'percentage of improvement depends on prog ay be', '', '@ zero also)', '\\x0c']\n2808\n['©', '', ' ', '', 'imization', '', '@ Intermediate code generation process introduces many', 'inefficiencies', '', '«@ Extra copies of variables, using variables instead of', 'constants, repeated evaluation of expressions, et.', '© Code optimization removes such inefficiencies and', 'improves code', '© Improvement may be time, space, or power consumption', '© It changes the structure of programs, sometimes of beyond', 'recognition', '« Inlines functions, unrolls loops, eliminates some', 'programmer-defined variables, et.', '@ Code optimization consist of a bunch of heuristics and', 'percentage of improvement depends on programs (may be', 'zer0 also)', '\\x0c']\n2812\n['©', '', ' ', '', 'imization', '', '@ Intermediate code generation process introduces many', 'inefficiencies', '', '« Extra copies of variables, using variables instead of', 'constants, repeated evaluation of expressions, etc.', '@ Code optimization removes such inefficiencies and', 'improves code', '@ Improvement may be time, space, or power consumption', '@ It changes the structure of programs, sometimes of beyond', 'recognition', '« Inlines functions, unrolls loops, eliminates some', 'programmer-defined variables, etc.', '‘@ Code optimization consists 8f a bunch of heuristics and', 'percentage of improvement depends on programs (may be', 'zero also)', '\\x0c']\n2818\n['‘© Common sub-expression elimination', '© Copy propagation', '', '© Loop invariant code motion', '', '© Partial redundancy elimination', '', '@ Induction variable elimination and strength reduction', '', '© Code opimization needs information about the program', '‘ which expressions are being recomputed in a function?', 'which definitions reach a point?', '', '@ All such information is gatheyed through data-flow analysis', '', ' ', '\\x0c']\n2823\n['‘© Common sub-expression elimination', '© Copy propagation', '', '© Loop invariant code motion', '', '@ Partial redundancy elimination', '', '@ Induction variable elimination and strength reduction', '', 'Code opimization needs information about the program', '‘@ which expressions are being recomputed in a function?', 'which definitions reach a point?', '', '@ All such information is gathered through data-flow analysis', '', ' ', '\\x0c']\n2829\n['xamples of Machine-Independant Optimizations', '', '‘© Common sub-expression elimination', '', '© Copy propagation', '', '© Loop invariant code motion', '', '@ Partial redundancy elimination', '', '@ Induction variable élimination and strength reduction', '', '© Code opimization needs information about the program', '', '‘@ which expressions are being recomputed in a function?', '© which definitions reach a point?', '', '@ All such information is gathered through data-jg@manalysis', '', ' ', '\\x0c']\n2835\n['‘© Common sub-expression elimination', '© Copy propagation', '', '© Loop invariant code motion', '', '@ Partial redundancy elimination', '', '@ Induction variable elimination and strength reduction', '', '© Code opimization needs information about the program', '‘ which expressions are being recomputed in a function?', '© which definitions reach a point?', '', '@ All such information is gathered through data-jg@manalysis', '', ' ', '\\x0c']\n2841\n['‘© Common sub-expression elimination', '© Copy propagation', '', '© Loop invariant code motion', '', '@ Partial redundancy elimination', '', '@ Induction variable elimination and strength reduction', '', '© Code opimization needs information about the program', '‘¢ which expressions are being recomputed in a function?', '© which definitions reach d’point?', '', '@ All such information is gathered through data-g@analysis', '', ' ', '\\x0c']\n2846\n['‘© Common sub-expression elimination', '© Copy propagation', '', '© Loop invariant code motion', '', '@ Partial redundancy elimination', '', '@ Induction variable elimination and strength reduction', '', 'Code opimization needs information about the program', '‘@ which expressions are being recomputed in a function?', 'which definitions reach a paint?', '', '@ All such information is gathered through data-fjgmanalysis', '', ' ', '\\x0c']\n2853\n['‘© Common sub-expression elimination', '© Copy propagation', '', '© Loop invariant code motion', '', '© Partial redundancy elimination', '', '@ Induction variable elimination and strength reduction', 'Code opimization needs information about the program', '', '‘@ which expressions are being recomputed in a function?', '© which definitions reach a point?', '', '@ All such information is gathered through data-jg@manalysis', '', ' ', '\\x0c']\n2860\n['‘© Common sub-expression elimination', '© Copy propagation', '', '© Loop invariant code motion', '', '@ Partial redundancy elimination', '', '@ Induction variable elimination and strength reduction', '', 'Code opimization needs information about the program', '‘@ which expressions are being recomputed in a function?', '© which definitions reach a point? =', '', '@ All such information is gathered through data-flow analysis', '', ' ', '\\x0c']\n2866\n['Hennr48', 'idt=tt+320', '', 'Code Generator', '', 'LDF 2, id2', 'MULE R2, R2, 1.8', 'ADOF R2, R2, 32.0', 'STF id1, R2', '', ' ', '\\x0c']\n2872\n['STFidt, RZ', '', ' ', '\\x0c']\n2878\n['idt=tt+320', '', 'Code Generator', '', 'LOF 2, id2', 'MULE R2, R2, 1.8', 'ADDF R2, R2, 320', 'STF id1, R2', '', ' ', '\\x0c']\n2885\n['© Converts intermediate code to machine code', '@ Each intermediate code instruction may result in many', 'machine instructions or vice-cersa', 'Must handle all aspects of machine architecture', '« Registers, pipelining, cache, multiple function units, etc.', '', '© Generating efficient code is an NP-complete problem', '', '«@ Tree pattern matching-based strategies are among the best', '@ Needs tree intermediate code', '', '© Storage allocation decisiofis are made here', '«# Register allocation and assignment are the most important', 'problems', '', ' ', '\\x0c']\n2891\n['© Converts intermediate code to machine code', '@ Each intermediate code instruction may result in many', 'machine instructions or vice-cersa', 'Must handle all aspects of machine architecture', '«¢ Registers, pipelining, cache, muttiple function units, et.', '', '© Generating efficient code is an NP-complete problem', '', '«@ Tree pattern matching-based strategies are among the best', '@ Needs tree intermediate code', '', '© Storage allocation decisions are made here', '«@ Register allocation and assignment are the most important', 'problems', '', ' ', '\\x0c']\n2896\n['© Converts intermediate code to machine code', '@ Each intermediate code instruction may result in many', 'machine instructions or vice-cersa', '@ Must handle all aspects of machine architecture', '« Registers, pipelining, cache, multiple function units, etc.', '', '© Generating efficient code is an NP-complete problem', '', '«@ Tree pattern matching-based strategies are among the best', '@ Needs tree intermediate code', '', '© Storage allocation decisions are made here', '‘¢ Register allocation and assignment are the mggtignportant', 'problems', '', ' ', '\\x0c']\n2900\n['ode Generation', '', '© Converts intermediate code to machine code', '@ Each intermediate code instruction may result in many', 'machine instructions or vice-cersa', '© Must handle all aspects of machine architecture', '« Registers, pipelining, cache, multiple function units, etc.', '', '© Generating efficient code is an NP-complete problem', '', '«@ Tree pattern matching-based strategies are among the best', 'Needs tree intermediate code', '', '® Storage allocation decisions are made here', '‘ Register allocation and assignment are the mggejgoortant', 'problems', '', ' ', '\\x0c']\n2906\n['© Converts intermediate code to machine code', '@ Each intermediate code instruction may result in many', 'machine instructions or vice-cersa', 'Must handle all aspects of machine architecture', '« Registers, pipelining, cache, multiple function units, etc.', '', '© Generating efficient code is an NP-complete problem', '', '«@ Tree pattern matching-based strategies are among the best', '@ Needs tree intermediate code', '', '® Storage allocation decisions are made here', '‘ Register allocation and assignment are the mggeigportant', 'problems', '', ' ', '\\x0c']\n2913\n['© Converts intermediate code to machine code', '@ Each intermediate code instruction may result in many', 'machine instructions or vice-cersa', '@ Must handle all aspects of machine architecture', '« Registers, pipelining, cache, multiple function units, et.', '', '© Generating efficient code is an NP-complete problem', '', '«@ Tree pattern matching-based strategies are among the best', '@ Needs tree intermediate code', '', '© Storage allocation decisions are made here', '‘¢ Register allocation and assignment are the mggeigaportant', 'problems', '', ' ', '\\x0c']\n2916\n['© Converts intermediate code to machine code', '@ Each intermediate code instruction may result in many', 'machine instructions or vice-cersa', '@ Must handle all aspects of machine architecture', '« Registers, pipelining, cache, multiple function units, et.', '', '© Generating efficient code is an NP-complete problem', '', '«@ Tree pattern matching-based strategies are among the best', '@ Needs tree intermediate code', '', '@ Storage allocation decisions are made here', '«¢ Register allocation and assignment are the mggeiguoortant', 'problems', '', ' ', '\\x0c']\n2922\n['© Converts intermediate code to machine code', '@ Each intermediate code instruction may result in many', 'machine instructions or vice-cersa', '@ Must handle all aspects of machine architecture', '«Registers, pipelining, cache, multiple function units, ete.', '', '© Generating efficient code is an NP-complete problem', '', '«@ Tree pattern matching-based strategies are among the best', '@ Needs tree intermediate co¢e', '', '® Storage allocation decisions are made here', '‘ Register allocation and assignment are the moggiguportant', 'problems', '', ' ', '\\x0c']\n2927\n['ode Generation', '', '© Converts intermediate code to machine code', '@ Each intermediate code instruction may result in many', 'machine instructions or vice-cersa', '@ Must handle all aspects of machine architecture', '«@ Registers, pipelining, cache, multiple function units, et.', '', '‘© Generating efficient code is an NP-complete problem', '', '«@ Tree pattern matching-based strategies are among the best', '@ Needs tree intermediate code”', '', '® Storage allocation decisions are made here', '‘ Register allocation and assignment are the mggeiguoortant', 'problems', '', ' ', '\\x0c']\n2934\n['© Converts intermediate code to machine code', '@ Each intermediate code instruction may result in many', 'machine instructions or vice-cersa', '@ Must handle all aspects of machine architecture', '«Registers, pipelining, cache, multiple function units, etc.', '', '© Generating efficient code is an NP-complete problem', '', '«@ Tree pattern matching-based strategies are among the best', '@ Needs tree intermediate code', '', '@ Storage allocation decisions are made here', '', '‘ Register allocation and assignment are the mgggiguoortant', 'problems', '', ' ', '\\x0c']\n2940\n['© Converts intermediate code to machine code', '@ Each intermediate code instruction may result in many', 'machine instructions or vice-cersa', 'Must handle all aspects of machine architecture', '«Registers, pipelining, cache, multiple function units, etc.', '', '‘© Generating efficient code is an NP-complete problem', '', '«@ Tiee pattern matching-based strategies are among the best', '«# Needs tree intermediate code', '', '© Storage allocation decisions are made here', '«¢ Register allocation and assignment are the mggeignportant', 'problems', '', ' ', '\\x0c']\n2946\n['© Converts intermediate code to machine code', '@ Each intermediate code instruction may result in many', 'machine instructions or vice-cersa', 'Must handle all aspects of machine architecture', '« Registers, pipelining, cache, multiple function units, etc.', '', '© Generating efficient code is an NP-complete problem', '', '«@ Tree pattern matching-based strategies are among the best', '@ Needs tree intermediate code', '', '® Storage allocation decisions are made here', '‘ Register allocation and assignment are the most important', 'problems e', '', ' ', '\\x0c']\n2953\n['© Converts intermediate code to machine code', '@ Each intermediate code instruction may result in many', 'machine instructions or vice-cersa', '@ Must handle all aspects of machine architecture', '«© Registers, pipelining, cache, multiple function units etc.', '', '© Generating efficient code is an NP-complete problem', '', '«@ Tree pattern matching-based strategies are among the best', '@ Needs tree intermediate cade', '', '© Storage allocation decisions are made here', '«# Register allocation and assignment are the most important', 'problems', '', ' ', '\\x0c']\n2961\n['@ Peephole optimizations', '«Analyze sequence of instructions in a small window', '(peephole) and using preset patterns, replace them with a', 'more efficient sequence', '« Redundant instruction elimination', 'eg. replace the sequence [LD A.RII[ST R1,A] by (LD', 'ARI', '', '¢¢ Eliminate “jump to jump” instructions', '‘@ Use machine idioms (use INC instead of LD and ADD)', '', '¢@ Instruction scheduling (reordering) to eliminate pipeline', 'interlocks and to increase parallelism', '', '@ Trace scheduling to increase the size of basic blocks and', 'increase parallelism', '', '© Software pipelining to increase parallelism in loops', '', ' ', '\\x0c']\n2968\n['jptimizations', '', '@ Peephole optimizations', '‘@ Analyze sequence of instructions in a small window', '(peephole) and using preset patterns, replace them with a', 'more efficient sequence', '@ Redundant instruction elimination', 'eg. replace the sequence [LD A,RII[ST R1,A] by (LD', 'ARI]', '«Eliminate jump to jump instructions', '«Use machine idioms (use INC instead of LD and ADD)', '¢@ Instruction scheduling (reordefing) to eliminate pipeline', 'interlocks and to increase parallelism', '', '@ Trace scheduling to increase the size of basic blocks and', 'increase parallelism', '', '© Software pipelining to increase parallelism in loops', '', ' ', '\\x0c']\n2974\n['jptimizations', '', '@ Peephole optimizations', '«@ Analyze sequence’ instructions in a small window', '(peephole) and using preset patterns, replace them with a', 'more efficient sequence', '« Redundant instruction elimination', 'eg. replace the sequence [LD A.RII[ST R1,A] by (LD', 'ARI', '«Eliminate jump to jump instructions', '«Use machine idioms (use INC instead of LD and ADD)', '¢@ Instruction scheduling (reordering) to eliminate pipeline', 'interlocks and to increase parallelism', '', '@ Trace scheduling to increase the size of basic blocks and', 'increase parallelism', '', '© Software pipelining to increase parallelism in loops', '', ' ', '\\x0c']\n2981\n['@ Peephole optimizations', '«@ Analyze sequence of instructions in a small window', '(peephole) and using preset patterns, replace them with a', 'more efficient sequence', '« Redundant instruction elimination', 'eg. replace the sequence [LD A,RII[ST R1,A] by (LD', 'ARI', '', '¢¢ Eliminate “jump to jump” instructions', '‘@ Use machine idioms (use INC instead of LD and ADD)', '', '¢@ Instruction scheduling (reordering) to eliminate pipeline', 'interlocks and to increase parallelism', '', '@ Trace scheduling to increase the size of basic blocks and', 'increase parallelism', '', '© Software pipelining to increase parallelism in loops', '', ' ', '\\x0c']\n2990\n['© Peephole optimizations', '« Analyze sequence of instructions in a small window', '(peephole) and using preset patterns, replace them with a', 'more efficient sequence *', '«¢ Redundant instruction elimination', 'eg. replace the sequence [LD A.RI][ST R.A] by [LD', 'ARI]', '', '¢¢ Eliminate “jump to jump” instructions', '‘@ Use machine idioms (use INC instead of LD and ADD)', '', '¢@ Instruction scheduling (reordering) to eliminate pipeline', 'interlocks and to increase parallelism', '', '@ Trace scheduling to increase the size of basic blocks and', 'increase parallelism', '', '© Software pipelining to increase parallelism in loops', '', ' ', '\\x0c']\n2994\n['© Peephole optimizations', '«Analyze sequence of instructions in a small window', '(peephole) and using preset patterns, replace them with a', 'more efficient sequence', '« Redundant instruction elimination', 'eg. replace the sequence [LD A,RII[ST R1,A] by (LD', 'ARI]', '', '¢¢ Eliminate “jump to jump” instructions', '‘@ Use machine idioms (use INC instead of LD and ADD)', '', '¢@ Instruction scheduling (reordering) to eliminate pipeline', 'interlocks and to increase parallelism', '', '@ Trace scheduling to increase the size of basic blocks and', 'increase parallelism', '', '© Software pipelining to increase parallelism in loops', '', ' ', '\\x0c']\n3000\n['@ Peephole optimizations', '«Analyze sequence of instructions in a small window', '(peephole) and using preset patterns, replace them with a', 'more efficient sequence', '«¢ Redundant instruction elimination', 'eg. replace the sequence [LD A,RII[ST R1,A] by (LD', 'ARI', '', '¢¢ Eliminate “jump to jump” instructions', '‘@ Use machine idioms (use INC instead of LD and ADD)', '', '@ Instruction scheduling (reordering) to eliminate pipeline', 'interlocks and to increase parallelism', '', '@ Trace scheduling to increase the size of basic blocks and', 'increase parallelism', '', '© Software pipelining to increase parallelism in loops', '', ' ', '\\x0c']\n3005\n['@ Peephole optimizations', '«Analyze sequence of instructions in a small window', '(peephole) and using preset patterns, replace them with a', 'more efficient sequence', '« Redundant instruction elimination', 'eg. replace the sequence [LD A,RII[ST R1,A] by (LD', 'ARI', '', '«¢ Eliminate “jump to jump” instructions', '‘@ Use machine idioms (use INC instead of LD and ADD)', '', '¢@ Instruction scheduling (reordering) to eliminate pipeline', 'interlocks and to increase parallelism', '', '@ Trace scheduling to increase the size of basic blocks and', 'increase parallelism', '', '© Software pipelining to increase parallelism in loops', '', ' ', '\\x0c']\n3011\n['© Peephole optimizations', '«Analyze sequence of instructions in a small window', '(peephole) and using preset patterns, replace them with a', 'more eficient sequence', '« Redundant instruction elimination', 'eg. replace the sequence [LD A.RII|ST R1,A] by (LD', 'ARI', '', '«¢ Eliminate “jump tg jump” instructions', '‘@ Use machine idioms (use INC instead of LD and ADD)', '', '¢@ Instruction scheduling (reordering) to eliminate pipeline', 'interlocks and to increase parallelism', '', '@ Trace scheduling to increase the size of basic blocks and', 'increase parallelism', '', '© Software pipelining to increase parallelism in loops', '', ' ', '\\x0c']\n3016\n['@ Peephole optimizations', '«Analyze sequence of instructions in a small window', '(peephole) and using preset patterns, replace them with a', 'more efficient sequence', 'Redundant instruction elimination', 'eg. replace the sequence [LD A,RII[ST R1,A] by (LD', 'ARI', '', '«¢ Eliminate “jump to jump? instructions', '‘@ Use machine idioms (use INC instead of LD and ADD)', '', '¢@ Instruction scheduling (reordering) to eliminate pipeline', 'interlocks and to increase parallelism', '', '@ Trace scheduling to increase the size of basic blocks and', 'increase parallelism', '', '© Software pipelining to increase parallelism in loops', '', ' ', '\\x0c']\n3022\n['© Peephole optimizations', '«@ Analyze sequence of instructions in a small window', '(peephole) and using preset patterns, replace them with a', 'more efficient sequence', '« Redundant instruction elimination', 'eg. replace the sequence [LD A,RII[ST R1,A] by (LD', 'ARI', '', '«¢ Eliminate “jump to jump” instructions', '‘@ Use machine idioms (use INC instead of LD and ADD)', '', '¢@ Instruction scheduling (reordering) to eliminate pipeline', 'interlocks and to increase parallelism', '', '@ Trace scheduling to increase the size of basic blocks and', 'increase parallelism', '', '© Software pipelining to increase parallelism in loops', '', ' ', '\\x0c']\n3028\n['@ Peephole optimizations', '«Analyze sequence of instructions in a small window', '(peephole) and using preset patterns, replace them with a', 'more eficient sequence', '«¢ Redundant instruction elimination', 'eg. replace the sequence [LD A,RII|ST R1,A] by (LD', 'ARI', '', '«¢ Eliminate “jump to jump” instructions', '‘@ Use machine idioms (use INC instead of LD and ADD)', '', '¢@ Instruction scheduling (reordering) to eliminate pipeline', 'interlocks and to increase parallelism', '', '@ Trace scheduling to increase the size of basic blocks and', 'increase parallelism', '', '© Software pipelining to increase parallelism in loops', '', ' ', '\\x0c']\n3036\n['jptimizations', '', '@ Peephole optimizations', '«Analyze sequence of instructions in a small window', '(peephole) and using preset patterns, replace them with a', 'more efficient sequence', '«¢ Redundant instruction elimination', 'eg. replace the sequence (LD A,RII[ST R1,A] by (LD', 'ARI', '«Eliminate “jump to jump\" instructions', '«¢ Use machine idioms (use INC instead of LD and ADD)', '¢@ Instruction scheduling (reordering) to eliminate pipeline', 'interlocks and to increase parallelism', '', '@ Trace scheduling to increase the size of basic blocks and', 'increase parallelism', '', '© Software pipelining to increase parallelism in loops', '', ' ', '\\x0c']\n3043\n['@ Peephole optimizations', '«@ Analyze sequence of instructions in a small window', '(peephole) and using preset patterns, replace them with a', 'more eficient sequence', '« Redundant instruction elimination', 'eg. replace the sequence [LD A,RII[ST R1,A] by (LD', 'ARI]', '', '¢¢ Eliminate “jump to jump” instructions', '‘@ Use machine idioms (use INC instead of LD and ADD)', '', '¢@ Instruction scheduling (reordering) to eliminate pipeline', 'interlocks and to increase parallelism', '', '@ Trace scheduling to increase the size of basic blocks and', 'increase parallelism', '', '© Software pipelining to increase parallelism in loops', '', ' ', '\\x0c']\n3051\n['@ Peephole optimizations', '« Analyze sequence of instructions in a small window', '(peephole) and using preset patterns, replace them with a', 'more efficient sequence', '«¢ Redundant instruction elimination', 'e.g. replace the sequence [LD A.RIJ[ST R.A] by (LD', 'ARI]', '', '¢¢ Eliminate “jump to jump” instructions', '‘@ Use machine idioms (use INC instead of LD and ADD)', '', '¢@ Instruction scheduling (reordering) to eliminate pipeline', 'interlocks and to increase parallelism', '', '@ Trace scheduling to increase the size of basic blocks and', 'increase parallelism', '', '© Software pipelining to increase parallelism in loops', '', ' ', '\\x0c']\n3055\n['@ Peephole optimizations', '«Analyze sequence of instructions in a small window', '(peephole) and using preset patterns, replace them with a', 'more efficient sequence', '« Redundant instruction elimination', 'eg. replace the sequence [LD A,RII[ST R1,A] by (LD', 'ARI', '', '¢¢ Eliminate “jump to jump” instructions', '‘9 Use machine idioms (use INC instead of LD and ADD)', '', '¢ Instruction scheduling (reordering) to eliminate pipeline', 'interlocks and to increase parallelism', '', '@ Trace scheduling to increase the size of basic blocks and', 'increase parallelism', '', '© Software pipelining to increase parallelism in loops', '', ' ', '\\x0c']\n3061\n['@ Peephole optimizations', '«Analyze sequence of instructions in a small window', '(peephole) and using preset patterns, replace them with a', 'more efficient sequence', '« Redundant instruction elimination', 'eg. replace the sequence [LD A,RII[ST R1,A] by (LD', 'ARI]', '', '«¢ Eliminate “jump to jump” instructions', '‘@ Use machine idioms (use INC instead of LD and ADD)', '', '¢@ Instruction scheduling (reordering) to eliminate pipeline', 'interlocks and to increase parallelism', '', '@ Trace scheduling to increase the size of basf& blocks and', 'increase parallelism', '', '© Software pipelining to increase parallelism in loops', '', ' ', '\\x0c']\n3069\n['© Peephole optimizations', '«Analyze sequence of instructions in a small window', '(peephole) and using preset patterns, replace them with a', 'more efficient sequence', '« Redundant instruction elimination', 'eg. replace the sequence [LD A,RII[ST R1,A] by (LD', 'ARI', '', '¢¢ Eliminate “jump to jump” instructions', '‘@ Use machine idioms (use INC instead of LD and ADD)', '', '¢ Instruction scheduling (reordering) to eliminate pipeline', 'interlocks and to increase parallelism', '', '@ Trace scheduling to increase the size of basic blocks and', 'increase parallelism', '', '© Software pipelining to increase parallelism in loops', '', ' ', '\\x0c']\n3076\n['© Peephole optimizations', '«@ Analyze sequence of instructions in a small window', '(peephole) and using preset patterns, replace them with a', 'more eficient sequence', '« Redundant instruction elimination', 'eg. teplace the sequence [LD A,RII[ST R1,A] by (LD', 'ARI', '', '¢¢ Eliminate “jump to jump” instructions', '‘9 Use machine idioms (use INC instead of LD and ADD)', '', '¢@ Instruction scheduling (reordering) to eliminate pipeline', 'interlocks and to increase parallelism', '', '@ Trace scheduling to increase the size of basic blocks and', 'increase parallelism', '', '© Software pipelining to increase parallelism in loops', '', ' ', '\\x0c']\n3080\n['@ Peephole optimizations', '«@ Analyze sequence of instructions in a small window', '(peephole) and using preset patterns, replace them with a', 'more efficient sequence', '« Redundant instruction elimination', 'eg. teplace the sequence [LD A,RII[ST R1,A] by (LD', 'ARI]', '', '¢¢ Eliminate “jump to jump” instructions', '‘9 Use machine idioms (use INC instead of LD and ADD)', '', '¢@ Instruction scheduling (reordering) to eliminate pipeline', 'interlocks and to increase parallelism', '', '@ Trace scheduling to increase the size of basic blocks and', 'increase parallelisen', '', '© Software pipelining to increase parallelism in loops', '', ' ', '\\x0c']\n3086\n['@ Peephole optimizations', '«Analyze sequence of instructions in a small window', '(peephole) and using preset patterns, replace them with a', 'more efficient sequence', '« Redundant instruction elimination', 'eg. replace the sequence [LD A,RII[ST R1,A] by (LD', 'ARI]', '', '«¢ Eliminate “jump to jump” instructions', '‘@ Use machine idioms (use INC instead of LD and ADD)', '', '¢@ Instruction scheduling (reordering) to eliminate pipeline', 'interlocks and to increase parallelism', '', '@ Trace scheduling to increase the size of basic blocks and', 'increase parallelism', '', '© Software pipelining to increase parallelism in loops', '', ' ', '\\x0c']\n3092\n['© Peephole optimizations', '« Analyze sequence of instructions in a small window', '(peephole) and using preset patterns, replace them with a', 'more efficient sequence', '«¢ Redundant instruction elimination', 'e.g. replace the sequence [LD A.RI][ST R.A] by [LD', 'ARI]', '', '¢¢ Eliminate “jump to jump” instructions', '‘@ Use machine idioms (use INC instead of LD and ADD)', '', '¢@ Instruction scheduling (reordering) to eliminate pipeline', 'interlocks and to increase parallelism', '', '@ Trace scheduling to increase the size of basic blocks and', 'increase parallelism', '', '© Software pipelining to increase parallelism in loops', '', ' ', '\\x0c']\n3102\n['@ Peephole optimizations', '«@ Analyze sequence of instructions in a small window', '(peephole) and using preset patterns, replace them with a', 'more eficient sequence', '«¢ Redundant instruction elimination', 'eg. replace the sequence [LD A,RII[ST R1,A] by (LD', 'ARI]', '', '«¢ Eliminate “jump to jump” instructions', '‘@ Use machine idioms (use INC instead of LD and ADD)', '', '¢@ Instruction scheduling (reordering) to eliminate pipeline', 'interlocks and to increase parallelism', '', '@ Trace scheduling to increase the size of basic blocks and', 'increase parallelism', '', '© Software pipelining to increase parallelism in loops', '', ' ', '\\x0c']\n3110\n[' ', '\\x0c']\n","output_type":"stream"}]},{"cell_type":"code","source":"# from transformers import pipeline\n\n# summarizer = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\")\n\n# article = maintext\n\n# summary = summarizer(article, max_length=4000, min_length=1500)","metadata":{"execution":{"iopub.status.busy":"2023-11-02T11:33:20.303007Z","iopub.execute_input":"2023-11-02T11:33:20.303395Z","iopub.status.idle":"2023-11-02T11:33:20.308514Z","shell.execute_reply.started":"2023-11-02T11:33:20.303365Z","shell.execute_reply":"2023-11-02T11:33:20.307392Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"!git clone https://github.com/dvschultz/dataset-tools.git\n!pip install ImageHash","metadata":{"execution":{"iopub.status.busy":"2023-11-02T11:33:21.533492Z","iopub.execute_input":"2023-11-02T11:33:21.533851Z","iopub.status.idle":"2023-11-02T11:33:34.554270Z","shell.execute_reply.started":"2023-11-02T11:33:21.533823Z","shell.execute_reply":"2023-11-02T11:33:34.553032Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"Cloning into 'dataset-tools'...\nremote: Enumerating objects: 467, done.\u001b[K\nremote: Counting objects: 100% (144/144), done.\u001b[K\nremote: Compressing objects: 100% (31/31), done.\u001b[K\nremote: Total 467 (delta 124), reused 117 (delta 113), pack-reused 323\u001b[K\nReceiving objects: 100% (467/467), 688.62 KiB | 22.21 MiB/s, done.\nResolving deltas: 100% (269/269), done.\nRequirement already satisfied: ImageHash in /opt/conda/lib/python3.10/site-packages (4.3.1)\nRequirement already satisfied: PyWavelets in /opt/conda/lib/python3.10/site-packages (from ImageHash) (1.4.1)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from ImageHash) (1.23.5)\nRequirement already satisfied: pillow in /opt/conda/lib/python3.10/site-packages (from ImageHash) (9.5.0)\nRequirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from ImageHash) (1.11.2)\n","output_type":"stream"}]},{"cell_type":"code","source":"def MyTranscript(image_path):\n    image_path=image_path.replace('/kaggle/working/', '')\n    image_path=image_path.replace('.png','')\n    for i ,segment in enumerate(result['segments']):\n        start, end =segment['start'], segment['end']\n        #print(i)\n        #print(int(start))\n        if int(start)<=int(image_path) & int(image_path)<=int(end):\n            print(segment['text'].strip())\n            return segment['text'].strip()\n        ","metadata":{"execution":{"iopub.status.busy":"2023-11-02T12:06:11.654391Z","iopub.execute_input":"2023-11-02T12:06:11.654803Z","iopub.status.idle":"2023-11-02T12:06:11.662442Z","shell.execute_reply.started":"2023-11-02T12:06:11.654763Z","shell.execute_reply":"2023-11-02T12:06:11.661673Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"print(MyTranscript('/kaggle/working/311.png'))","metadata":{"execution":{"iopub.status.busy":"2023-11-02T12:06:13.730021Z","iopub.execute_input":"2023-11-02T12:06:13.730421Z","iopub.status.idle":"2023-11-02T12:06:13.736242Z","shell.execute_reply.started":"2023-11-02T12:06:13.730390Z","shell.execute_reply":"2023-11-02T12:06:13.735164Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"So, this is called simulation of the design and it is an example of compiled simulation.\nSo, this is called simulation of the design and it is an example of compiled simulation.\n","output_type":"stream"}]},{"cell_type":"code","source":"df=pd.DataFrame(columns=['Frame', 'Transcript', 'Num'])","metadata":{"execution":{"iopub.status.busy":"2023-11-02T12:06:16.557891Z","iopub.execute_input":"2023-11-02T12:06:16.558255Z","iopub.status.idle":"2023-11-02T12:06:16.568268Z","shell.execute_reply.started":"2023-11-02T12:06:16.558228Z","shell.execute_reply":"2023-11-02T12:06:16.567278Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"import os\nimport shutil  # Added to handle file operations\nimport imagehash\nfrom PIL import Image\nimport numpy as np\n\n## Creating the New dataset for images and transcript \n\ndef alpharemover(image):\n    if image.mode != 'RGBA':\n        return image\n    canvas = Image.new('RGBA', image.size, (255,255,255,255))\n    canvas.paste(image, mask=image)\n    return canvas.convert('RGB')\n\ndef with_ztransform_preprocess(hashfunc, hash_size=8):\n    def function(path):\n        image = alpharemover(Image.open(path))\n        image = image.convert(\"L\").resize((hash_size, hash_size), Image.ANTIALIAS)\n        data = image.getdata()\n        quantiles = np.arange(100)\n        quantiles_values = np.percentile(data, quantiles)\n        zdata = (np.interp(data, quantiles_values, quantiles) / 100 * 255).astype(np.uint8)\n        image.putdata(zdata)\n        return hashfunc(image)\n    return function\n\ndhash_z_transformed = with_ztransform_preprocess(imagehash.dhash, hash_size=8)\n\n# Path to the images folder\nimages_folder = '/kaggle/working'\nunique_images_folder = '/kaggle_unique_images'  # New folder for unique images\n\n# Create the unique images folder if it doesn't exist\nos.makedirs(unique_images_folder, exist_ok=True)\n\n# Create a set to store unique hashes\nunique_hashes = set()\ncount = 0\n\n# Iterate through image files in the images folder\nf1 = open(\"uniq.txt\", \"a\")\nf2 = open(\"dup.txt\", \"a\")\nlist1=os.listdir(images_folder) \nlist1.sort()\nfor filename in list1:\n    if filename.lower().endswith(('.png', '.jpg', '.jpeg', '.gif', '.bmp')):\n        image_path = os.path.join(images_folder, filename)\n        hash_value = dhash_z_transformed(image_path)\n        \n        # Check if the hash is already in the set (redundant image)\n        if hash_value in unique_hashes:\n            f2.write(f\"Redundant Image: {filename}, Hash: {hash_value}\\n\")\n        else:\n            temp=image_path\n            temp=temp.replace('/kaggle/working/', '')\n            temp=temp.replace('.png','')\n            YourTranscript=MyTranscript(image_path)\n            if(YourTranscript):\n                new_row={'Frame':(image_path), 'Transcript': YourTranscript , 'Num': int(temp)}\n                df.loc[len(df)]=new_row\n#             new_row={'Frame':(image_path), 'Transcript': YourTranscript }\n#             df.loc[len(df)]=new_row \n            unique_hashes.add(hash_value)\n            f1.write(f\"Unique Image: {filename}, Hash: {hash_value}\\n\")\n            count += 1\n\n            # Move the unique image to the unique images folder\n            unique_image_path = os.path.join(unique_images_folder, filename)\n#             shutil.move(image_path, unique_image_path)\n\nf1.close()\nf2.close()\nprint(f\"{count} images found unique and the images unique are in /kaggle/unique_images\")\n","metadata":{"execution":{"iopub.status.busy":"2023-11-02T12:06:17.131477Z","iopub.execute_input":"2023-11-02T12:06:17.132529Z","iopub.status.idle":"2023-11-02T12:06:19.631742Z","shell.execute_reply.started":"2023-11-02T12:06:17.132490Z","shell.execute_reply":"2023-11-02T12:06:19.630858Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"two. Compilers generate machine code whereas, interpreters generate you know interpret intermediate\ncode. Of course, interpreters are only 50 percent of a compiler. So, they are easier to\nexample of the theory being translated into practice and this is a wonderful example of that.\nAnd then you know even the compilation, lexical analysis parsing etcetera is all the time required\nAnd then you know even the compilation, lexical analysis parsing etcetera is all the time required\nmuch more memory much more time than machine code generated by compilers and there are very\nfamous examples per Python, Unixel, Java, Basic, List etcetera are all you know interpreter\nbased languages. Now, let us get back to the block diagram and let us look at the lexical\nis a line far and high equal to centigrade star 1.8 plus 32. This is an assignment statement\nSo, if you look at the applications of modern compiler technology pick up the browser,\nThis is the input to syntax and lizer. So, now let us look at the reasons why lexical\nfrom regular expression specifications. So, for example, lex and flex are two tools\navailable in unix and if we feed a regular expression specification we are going to study\navailable in unix and if we feed a regular expression specification we are going to study\nhomepage and that you are going to visit and so on. So, the HTML parsers are based on compiler\nit is not a good idea to distribute such input output you know issues all over a compiler\nhomepage and that you are going to visit and so on. So, the HTML parsers are based on compiler\nunder the stack then popping them off the stack and so on which are very inefficient\nWelcome to this new course on Principles of Compiler Design. So, in this lecture I will\ngiving the program to the syntax lizer. So, then once we understand lexical analysis\nto a syntax lizer. So, we have these tokens coming into a syntax\nlizer the syntax lizer looks at the tokens and finds out whether the syntax is according\nit.\nabove this was Fahrenheit equal to you know as as let us look at it.\nSo, we will learn about these specifications a little later, but right now it suffices\nSo, we will learn about these specifications a little later, but right now it suffices\nto say that the you know there are tools to do this. For example, the yawk and antler are\ntwo such tools. So, they handle what are known as you know LALR1 grammars that is yawk\nand bison and antler handles what are known as LL1 grammars. They generate C programs\non the modern compiler technology. Then of course, for the compiler itself we require machine\nor C plus plus programs which correspond to these parsers you know and they can be used\nby the compiler. So, as I already said parsers are based on pushdown automata. So, they\nwe need the next phase of analysis called semantic analysis. The reason is parsers cannot\nwe need the next phase of analysis called semantic analysis. The reason is parsers cannot\nof assignment this cannot be handled by a parser. So, there are theoretical limitations\nwe need to use compiler technology anyway. But then apart from that it has uses in software\nis here you know parameter types and number match in declaration and use. So, we declare\nengineering as well. For example, software testing and then program optimization then in the\nanalysis is supposed to take care of it. So, the next phase is the semantic analysis phase\n32. So, if there is some violation the you cannot really add floating point numbers\nsecurity domain malicious code detection design of new computer architectures. So, why are\nSo, semantic consistency that cannot be handled at the parsing stage is handled here.\nSo, I already gave you examples of this. So, I am the same thing is repeated here type\nSo, I already gave you examples of this. So, I am the same thing is repeated here type\nchecking of various programming language constructs is one of the most important task. As semantic\nthese important? For example, if you look at the development of a new processor nobody builds\nWhat are the dimensions of an array etcetera? So, these are the information that are stored\nin a symbol table by the semantic analyzer. This information is used not only for caching\nerrors semantic validation as we know it, but it is also used for subsequent phases of\na processor you know right away even if the design is 100 percent accurate and all that the\nmachine code generator needs to know the types of variables in order to generate appropriate\nperformance etcetera will all be known only after the hardware is built. Therefore, there\ncode generation phase. So, the annotated syntax tree which is output from a semantic analyzer\noriginal source level program, but it is at a much lower level compared to the source\nis a simulator which is built for a new CPU and then people also build compiler for that\noriginal source level program, but it is at a much lower level compared to the source\nlevel program, but I must you know mention that it is not a machine language. So, let us\nmachine code from directly from source code is definitely possible. There is no theoretical\nor practical limitation. There are two problems associated with this approach. The problem\nis you need to write too many compilers. Suppose you want to write compilers for m languages\nWelcome to this new course on Principles of Compiler Design. So, in this lecture I will\nsemantic analyzer and let us assume that there is an intermediate code generator. So, all\nsemantic analyzer and let us assume that there is an intermediate code generator. So, all\nwrite programs in C or C++ or any other language compile those programs and then run them\nagain you know for every language and every machine it is a waste of effort. What we\nsee whether it is C or C plus plus or 4 turn or Java, the intermediate code will be very\nin the hardware. So, that is called the compiler in the loop hardware development and it is\ntypes of intermediate code as well. So, the type of intermediate code that is deployed\nactually is based on the application. So, quadruples, triples, indirect triples, abstracts,\nindexes these are all classical forms of intermediate code they have been in existence\nSSA rather than the quadruples or triples. So, modern compilers nowadays invariably\ninstruction machine code generation. Finally, program dependence type of a graph is another\ncode for generating VLSI designs and so on and so forth that is called RTL register\nNow, the code optimizer is the next phase which takes as input the intermediate code and\ngenerates you know produces very efficient code optimizer, code intermediate code and\nequal to 82 star 1.8 remains as it is there is not much we can do in that, but it is not\nnecessary to retain the second statement which is T2 equal to into float 32. So, we might\ntransfer logic. People really write it in very high description you know high level description\nThe machine independent code optimization actually becomes necessary because intermediate code\nThe machine independent code optimization actually becomes necessary because intermediate code\nbe just 0 you never know whether there would be improvement or not. But some programs\nbe just 0 you never know whether there would be improvement or not. But some programs\nSo, there are different types of machine dependent optimizations. For example, commence\nSo, there are different types of machine dependent optimizations. For example, commence\nspectrum elimination, copy propagation, loop invariant code motion, partial redundancy\nthe end of the course. Finally, the machine code generation. So, it takes intermediate\nthe end of the course. Finally, the machine code generation. So, it takes intermediate\npoint corresponding to these two instructions are being generated here. So, it converts\ncode instructions actually give rise to only one single machine instruction. Depends on\nSo, typically a compiler is used to generate a simulator and the simulator is actually\ncode generation phase of the compiler. There are also after machine code generation even\nFor example, there are water known as machine dependent optimizations. If you are listed\nFor example, there are water known as machine dependent optimizations. If you are listed\nwhere there is a jump instruction and the target is another jump then this jump to jump\na computer program which is generated for that particular program which is being simulated.\ngive you an overview of a compiler, but before that we will also see how exactly the course\netcetera. Thank you very much.\nthan interpretations. So, about the complexity of compiler technology it is also necessary\ncomplex system software and writing it is a substantial exercise in software engineering.\nlarge software engineering exercise. The complexity of a compiler really arises from the\nactually travel a long distance it is not as if it is a very simple operation. So, there\nis a huge amount of complexity here. So, we are going to discuss this particular complexity\nSo, the course is actually a first level course. In other words, this takes a detail look at the\nas Yoc which do this. So, this enable in this enables tool building. So, tools take very\nSo, now let us look at the type of algorithms which are used inside a compiler and see\nSo, now let us look at the type of algorithms which are used inside a compiler and see\nfrom mathematical logic lattice theory linear algebra probability etcetera. So, where are\nthese used? For example, mathematical logic is used to you know in developing type checking\nDesign analysis is heavily based on linear algebra and group parallelization is based\non loop dependance analysis. So, cache analysis uses both static analysis and probability\ntheory. So, in other words a very deep mathematical background is required to develop new compiler\nalgorithms. In our course, we are going to study the existing compiler algorithms, but\nwe will also look at some of the you know the basis which actually make up this particular\nparsing, fixed point algorithms are used for data flow analysis, very complex data structures\ncompiler technology some aspects of compiler technology. For example, scanning and parsing\nyou know performs scanning and parsing and another part of a compiler performs program analysis.\nSo, program analysis techniques are useful in converting sequential programs to parallel\nprograms. And very important it can be used to determine if programs are data raise,\nProfiling programs to determine busy regions of the code well if this is done then we can\nof a program. So, data flow analysis approach to software testing is again based on program\nanalysis. If you look at a program it is very difficult to say what is the worst case\nSo, that is about you know the motivation to study this subject called compiler design.\nSo, let us begin with this block diagram which talks about a general language processing\nSo, let us begin with this block diagram which talks about a general language processing\ngoing to take this course seriously are requested to do the programming assignments.\nthis course will not be understood you know properly. The reason is a compiler is an excellent\ncompiler consists of many blocks they are all listed here.\nthis course will not be understood you know properly. The reason is a compiler is an excellent\n128 images found unique and the images unique are in /kaggle/unique_images\n","output_type":"stream"}]},{"cell_type":"code","source":"!python3 /kaggle/working/dataset-tools/dedupe.py --input_folder \"/content/kaggle/unique_images\" --output_folder \"/content/normal/\" --relative --avg_match 50.0","metadata":{"execution":{"iopub.status.busy":"2023-11-02T12:06:44.327255Z","iopub.execute_input":"2023-11-02T12:06:44.327955Z","iopub.status.idle":"2023-11-02T12:06:45.601018Z","shell.execute_reply.started":"2023-11-02T12:06:44.327913Z","shell.execute_reply":"2023-11-02T12:06:45.599995Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stdout","text":"Traceback (most recent call last):\n  File \"/kaggle/working/dataset-tools/dedupe.py\", line 4, in <module>\n    import imutils\nModuleNotFoundError: No module named 'imutils'\n","output_type":"stream"}]},{"cell_type":"code","source":"print(\"images final: \")\n!ls \"/content/normal/exclude\" | wc -l\nprint(\"total images: \")\n!ls \"/content/kaggle/unique_images\" | wc -l","metadata":{"execution":{"iopub.status.busy":"2023-11-02T12:06:45.602808Z","iopub.execute_input":"2023-11-02T12:06:45.603092Z","iopub.status.idle":"2023-11-02T12:06:47.589782Z","shell.execute_reply.started":"2023-11-02T12:06:45.603065Z","shell.execute_reply":"2023-11-02T12:06:47.588583Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stdout","text":"images final: \nls: cannot access '/content/normal/exclude': No such file or directory\n0\ntotal images: \nls: cannot access '/content/kaggle/unique_images': No such file or directory\n0\n","output_type":"stream"}]},{"cell_type":"code","source":"# if want to rerun the whole code: first remove the prev folder:\n# rm -r \"/content/normal\"\nimage_folder='/kaggle/working/'\nlist1=os.listdir(image_folder)","metadata":{"execution":{"iopub.status.busy":"2023-11-02T12:07:20.286069Z","iopub.execute_input":"2023-11-02T12:07:20.286469Z","iopub.status.idle":"2023-11-02T12:07:20.291608Z","shell.execute_reply.started":"2023-11-02T12:07:20.286431Z","shell.execute_reply":"2023-11-02T12:07:20.290570Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"df['Transcript'].isna().sum()","metadata":{"execution":{"iopub.status.busy":"2023-11-02T12:07:23.907985Z","iopub.execute_input":"2023-11-02T12:07:23.908362Z","iopub.status.idle":"2023-11-02T12:07:23.918852Z","shell.execute_reply.started":"2023-11-02T12:07:23.908335Z","shell.execute_reply":"2023-11-02T12:07:23.917789Z"},"trusted":true},"execution_count":26,"outputs":[{"execution_count":26,"output_type":"execute_result","data":{"text/plain":"0"},"metadata":{}}]},{"cell_type":"code","source":"df","metadata":{"execution":{"iopub.status.busy":"2023-11-02T12:07:25.787598Z","iopub.execute_input":"2023-11-02T12:07:25.788224Z","iopub.status.idle":"2023-11-02T12:07:25.806105Z","shell.execute_reply.started":"2023-11-02T12:07:25.788190Z","shell.execute_reply":"2023-11-02T12:07:25.805166Z"},"trusted":true},"execution_count":27,"outputs":[{"execution_count":27,"output_type":"execute_result","data":{"text/plain":"                        Frame  \\\n0    /kaggle/working/1003.png   \n1    /kaggle/working/1009.png   \n2     /kaggle/working/104.png   \n3    /kaggle/working/1047.png   \n4    /kaggle/working/1053.png   \n..                        ...   \n123   /kaggle/working/801.png   \n124    /kaggle/working/84.png   \n125    /kaggle/working/90.png   \n126   /kaggle/working/901.png   \n127    /kaggle/working/97.png   \n\n                                            Transcript   Num  \n0    two. Compilers generate machine code whereas, ...  1003  \n1    code. Of course, interpreters are only 50 perc...  1009  \n2    example of the theory being translated into pr...   104  \n3    And then you know even the compilation, lexica...  1047  \n4    And then you know even the compilation, lexica...  1053  \n..                                                 ...   ...  \n123  So, let us begin with this block diagram which...   801  \n124  going to take this course seriously are reques...    84  \n125  this course will not be understood you know pr...    90  \n126  compiler consists of many blocks they are all ...   901  \n127  this course will not be understood you know pr...    97  \n\n[128 rows x 3 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Frame</th>\n      <th>Transcript</th>\n      <th>Num</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>/kaggle/working/1003.png</td>\n      <td>two. Compilers generate machine code whereas, ...</td>\n      <td>1003</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>/kaggle/working/1009.png</td>\n      <td>code. Of course, interpreters are only 50 perc...</td>\n      <td>1009</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>/kaggle/working/104.png</td>\n      <td>example of the theory being translated into pr...</td>\n      <td>104</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>/kaggle/working/1047.png</td>\n      <td>And then you know even the compilation, lexica...</td>\n      <td>1047</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>/kaggle/working/1053.png</td>\n      <td>And then you know even the compilation, lexica...</td>\n      <td>1053</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>123</th>\n      <td>/kaggle/working/801.png</td>\n      <td>So, let us begin with this block diagram which...</td>\n      <td>801</td>\n    </tr>\n    <tr>\n      <th>124</th>\n      <td>/kaggle/working/84.png</td>\n      <td>going to take this course seriously are reques...</td>\n      <td>84</td>\n    </tr>\n    <tr>\n      <th>125</th>\n      <td>/kaggle/working/90.png</td>\n      <td>this course will not be understood you know pr...</td>\n      <td>90</td>\n    </tr>\n    <tr>\n      <th>126</th>\n      <td>/kaggle/working/901.png</td>\n      <td>compiler consists of many blocks they are all ...</td>\n      <td>901</td>\n    </tr>\n    <tr>\n      <th>127</th>\n      <td>/kaggle/working/97.png</td>\n      <td>this course will not be understood you know pr...</td>\n      <td>97</td>\n    </tr>\n  </tbody>\n</table>\n<p>128 rows × 3 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"df.sort_values(by='Num', inplace=True)","metadata":{"execution":{"iopub.status.busy":"2023-11-02T12:07:34.131975Z","iopub.execute_input":"2023-11-02T12:07:34.132391Z","iopub.status.idle":"2023-11-02T12:07:34.142661Z","shell.execute_reply.started":"2023-11-02T12:07:34.132358Z","shell.execute_reply":"2023-11-02T12:07:34.141658Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"df.reset_index()","metadata":{"execution":{"iopub.status.busy":"2023-11-02T12:07:35.977650Z","iopub.execute_input":"2023-11-02T12:07:35.978125Z","iopub.status.idle":"2023-11-02T12:07:35.992861Z","shell.execute_reply.started":"2023-11-02T12:07:35.978070Z","shell.execute_reply":"2023-11-02T12:07:35.991824Z"},"trusted":true},"execution_count":29,"outputs":[{"execution_count":29,"output_type":"execute_result","data":{"text/plain":"     index                     Frame  \\\n0       18    /kaggle/working/14.png   \n1       60    /kaggle/working/22.png   \n2       95    /kaggle/working/31.png   \n3      102    /kaggle/working/44.png   \n4      124    /kaggle/working/84.png   \n..     ...                       ...   \n123     90  /kaggle/working/2961.png   \n124     91  /kaggle/working/2968.png   \n125     92  /kaggle/working/2974.png   \n126     93  /kaggle/working/3016.png   \n127     96  /kaggle/working/3110.png   \n\n                                            Transcript   Num  \n0    Welcome to this new course on Principles of Co...    14  \n1    Welcome to this new course on Principles of Co...    22  \n2    give you an overview of a compiler, but before...    31  \n3    So, the course is actually a first level cours...    44  \n4    going to take this course seriously are reques...    84  \n..                                                 ...   ...  \n123  code generation phase of the compiler. There a...  2961  \n124  For example, there are water known as machine ...  2968  \n125  For example, there are water known as machine ...  2974  \n126  where there is a jump instruction and the targ...  3016  \n127                     etcetera. Thank you very much.  3110  \n\n[128 rows x 4 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>index</th>\n      <th>Frame</th>\n      <th>Transcript</th>\n      <th>Num</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>18</td>\n      <td>/kaggle/working/14.png</td>\n      <td>Welcome to this new course on Principles of Co...</td>\n      <td>14</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>60</td>\n      <td>/kaggle/working/22.png</td>\n      <td>Welcome to this new course on Principles of Co...</td>\n      <td>22</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>95</td>\n      <td>/kaggle/working/31.png</td>\n      <td>give you an overview of a compiler, but before...</td>\n      <td>31</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>102</td>\n      <td>/kaggle/working/44.png</td>\n      <td>So, the course is actually a first level cours...</td>\n      <td>44</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>124</td>\n      <td>/kaggle/working/84.png</td>\n      <td>going to take this course seriously are reques...</td>\n      <td>84</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>123</th>\n      <td>90</td>\n      <td>/kaggle/working/2961.png</td>\n      <td>code generation phase of the compiler. There a...</td>\n      <td>2961</td>\n    </tr>\n    <tr>\n      <th>124</th>\n      <td>91</td>\n      <td>/kaggle/working/2968.png</td>\n      <td>For example, there are water known as machine ...</td>\n      <td>2968</td>\n    </tr>\n    <tr>\n      <th>125</th>\n      <td>92</td>\n      <td>/kaggle/working/2974.png</td>\n      <td>For example, there are water known as machine ...</td>\n      <td>2974</td>\n    </tr>\n    <tr>\n      <th>126</th>\n      <td>93</td>\n      <td>/kaggle/working/3016.png</td>\n      <td>where there is a jump instruction and the targ...</td>\n      <td>3016</td>\n    </tr>\n    <tr>\n      <th>127</th>\n      <td>96</td>\n      <td>/kaggle/working/3110.png</td>\n      <td>etcetera. Thank you very much.</td>\n      <td>3110</td>\n    </tr>\n  </tbody>\n</table>\n<p>128 rows × 4 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"df.columns","metadata":{"execution":{"iopub.status.busy":"2023-11-02T12:07:38.415089Z","iopub.execute_input":"2023-11-02T12:07:38.415481Z","iopub.status.idle":"2023-11-02T12:07:38.422050Z","shell.execute_reply.started":"2023-11-02T12:07:38.415453Z","shell.execute_reply":"2023-11-02T12:07:38.421095Z"},"trusted":true},"execution_count":30,"outputs":[{"execution_count":30,"output_type":"execute_result","data":{"text/plain":"Index(['Frame', 'Transcript', 'Num'], dtype='object')"},"metadata":{}}]},{"cell_type":"code","source":"df1=pd.DataFrame(columns=['Frame', 'Transcript'])","metadata":{"execution":{"iopub.status.busy":"2023-11-02T12:07:38.712513Z","iopub.execute_input":"2023-11-02T12:07:38.712853Z","iopub.status.idle":"2023-11-02T12:07:38.719095Z","shell.execute_reply.started":"2023-11-02T12:07:38.712828Z","shell.execute_reply":"2023-11-02T12:07:38.717939Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"## Image Content \nimport os\nimport pytesseract as tess\nfrom PIL import Image \n\nfor i in range(0,len(df)):\n    image_path=df.iloc[i]['Frame']\n    img=Image.open(image_path)\n    text= tess.image_to_string(img)\n    new_row={'Frame': text, 'Transcript': df.iloc[i]['Transcript']}\n    \n    df1.loc[len(df1)]=new_row\n# print(text)\n","metadata":{"execution":{"iopub.status.busy":"2023-11-02T12:07:38.904759Z","iopub.execute_input":"2023-11-02T12:07:38.905174Z","iopub.status.idle":"2023-11-02T12:09:54.151528Z","shell.execute_reply.started":"2023-11-02T12:07:38.905129Z","shell.execute_reply":"2023-11-02T12:09:54.150476Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"df1","metadata":{"execution":{"iopub.status.busy":"2023-11-02T12:09:54.153523Z","iopub.execute_input":"2023-11-02T12:09:54.153813Z","iopub.status.idle":"2023-11-02T12:09:54.164977Z","shell.execute_reply.started":"2023-11-02T12:09:54.153788Z","shell.execute_reply":"2023-11-02T12:09:54.164139Z"},"trusted":true},"execution_count":33,"outputs":[{"execution_count":33,"output_type":"execute_result","data":{"text/plain":"                                                 Frame  \\\n0    Principles of Compiler Design\\n\\nLecture - 01\\...   \n1                                                  \\n\n   \n2    © About the course\\n‘© Why should we study com...   \n3    © A detailed look at the internals of a compil...   \n4    © A detailed look at the internals of a compil...   \n..                                                 ...   \n123  © Peephole optimizations\\n«@ Analyze sequence ...   \n124  jptimizations\\n\\n@ Peephole optimizations\\n‘@ ...   \n125  jptimizations\\n\\n@ Peephole optimizations\\n«@ ...   \n126  @ Peephole optimizations\\n«@ Analyze sequence ...   \n127                                                \\n\n   \n\n                                            Transcript  \n0    Welcome to this new course on Principles of Co...  \n1    Welcome to this new course on Principles of Co...  \n2    give you an overview of a compiler, but before...  \n3    So, the course is actually a first level cours...  \n4    going to take this course seriously are reques...  \n..                                                 ...  \n123  code generation phase of the compiler. There a...  \n124  For example, there are water known as machine ...  \n125  For example, there are water known as machine ...  \n126  where there is a jump instruction and the targ...  \n127                     etcetera. Thank you very much.  \n\n[128 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Frame</th>\n      <th>Transcript</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Principles of Compiler Design\\n\\nLecture - 01\\...</td>\n      <td>Welcome to this new course on Principles of Co...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>\\n</td>\n      <td>Welcome to this new course on Principles of Co...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>© About the course\\n‘© Why should we study com...</td>\n      <td>give you an overview of a compiler, but before...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>© A detailed look at the internals of a compil...</td>\n      <td>So, the course is actually a first level cours...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>© A detailed look at the internals of a compil...</td>\n      <td>going to take this course seriously are reques...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>123</th>\n      <td>© Peephole optimizations\\n«@ Analyze sequence ...</td>\n      <td>code generation phase of the compiler. There a...</td>\n    </tr>\n    <tr>\n      <th>124</th>\n      <td>jptimizations\\n\\n@ Peephole optimizations\\n‘@ ...</td>\n      <td>For example, there are water known as machine ...</td>\n    </tr>\n    <tr>\n      <th>125</th>\n      <td>jptimizations\\n\\n@ Peephole optimizations\\n«@ ...</td>\n      <td>For example, there are water known as machine ...</td>\n    </tr>\n    <tr>\n      <th>126</th>\n      <td>@ Peephole optimizations\\n«@ Analyze sequence ...</td>\n      <td>where there is a jump instruction and the targ...</td>\n    </tr>\n    <tr>\n      <th>127</th>\n      <td>\\n</td>\n      <td>etcetera. Thank you very much.</td>\n    </tr>\n  </tbody>\n</table>\n<p>128 rows × 2 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"df1.iloc[124]['Frame']","metadata":{"execution":{"iopub.status.busy":"2023-11-02T12:09:54.165930Z","iopub.execute_input":"2023-11-02T12:09:54.166225Z","iopub.status.idle":"2023-11-02T12:09:54.179081Z","shell.execute_reply.started":"2023-11-02T12:09:54.166199Z","shell.execute_reply":"2023-11-02T12:09:54.178051Z"},"trusted":true},"execution_count":34,"outputs":[{"execution_count":34,"output_type":"execute_result","data":{"text/plain":"'jptimizations\\n\\n@ Peephole optimizations\\n‘@ Analyze sequence of instructions in a small window\\n(peephole) and using preset patterns, replace them with a\\nmore efficient sequence\\n@ Redundant instruction elimination\\neg. replace the sequence [LD A,RII[ST R1,A] by (LD\\nARI]\\n«Eliminate jump to jump instructions\\n«Use machine idioms (use INC instead of LD and ADD)\\n¢@ Instruction scheduling (reordefing) to eliminate pipeline\\ninterlocks and to increase parallelism\\n\\n@ Trace scheduling to increase the size of basic blocks and\\nincrease parallelism\\n\\n© Software pipelining to increase parallelism in loops\\n\\n \\n\\x0c'"},"metadata":{}}]},{"cell_type":"code","source":"df1.iloc[125]['Frame']","metadata":{"execution":{"iopub.status.busy":"2023-11-02T12:11:28.552408Z","iopub.execute_input":"2023-11-02T12:11:28.552774Z","iopub.status.idle":"2023-11-02T12:11:28.558652Z","shell.execute_reply.started":"2023-11-02T12:11:28.552748Z","shell.execute_reply":"2023-11-02T12:11:28.557919Z"},"trusted":true},"execution_count":35,"outputs":[{"execution_count":35,"output_type":"execute_result","data":{"text/plain":"'jptimizations\\n\\n@ Peephole optimizations\\n«@ Analyze sequence’! instructions in a small window\\n(peephole) and using preset patterns, replace them with a\\nmore ficient sequence\\n« Redundant instruction elimination\\neg. replace the sequence [LD A,RII[ST R1,A] by (LD\\nARI\\n«# Eliminate jump to jump instructions\\n« Use machine idioms (use INC instead of LD and ADD)\\n¢@ Instruction scheduling (reordering) to eliminate pipeline\\ninterlocks and to increase parallelism\\n\\n@ Trace scheduling to increase the size of basic blocks and\\nincrease parallelism\\n\\n© Software pipelining to increase parallelism in loops\\n\\n \\n\\x0c'"},"metadata":{}}]},{"cell_type":"code","source":"import string \ntest_str = (df1.iloc[125]['Frame']).translate(str.maketrans('', '', string.punctuation))","metadata":{"execution":{"iopub.status.busy":"2023-11-02T12:11:31.936324Z","iopub.execute_input":"2023-11-02T12:11:31.937319Z","iopub.status.idle":"2023-11-02T12:11:31.942965Z","shell.execute_reply.started":"2023-11-02T12:11:31.937273Z","shell.execute_reply":"2023-11-02T12:11:31.942177Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"test_str","metadata":{"execution":{"iopub.status.busy":"2023-11-02T12:11:34.227267Z","iopub.execute_input":"2023-11-02T12:11:34.227608Z","iopub.status.idle":"2023-11-02T12:11:34.233446Z","shell.execute_reply.started":"2023-11-02T12:11:34.227584Z","shell.execute_reply":"2023-11-02T12:11:34.232486Z"},"trusted":true},"execution_count":37,"outputs":[{"execution_count":37,"output_type":"execute_result","data":{"text/plain":"'jptimizations\\n\\n Peephole optimizations\\n« Analyze sequence’ instructions in a small window\\npeephole and using preset patterns replace them with a\\nmore ficient sequence\\n« Redundant instruction elimination\\neg replace the sequence LD ARIIST R1A by LD\\nARI\\n« Eliminate jump to jump instructions\\n« Use machine idioms use INC instead of LD and ADD\\n¢ Instruction scheduling reordering to eliminate pipeline\\ninterlocks and to increase parallelism\\n\\n Trace scheduling to increase the size of basic blocks and\\nincrease parallelism\\n\\n© Software pipelining to increase parallelism in loops\\n\\n \\n\\x0c'"},"metadata":{}}]},{"cell_type":"code","source":"punc = '''!()-[]{};:'\",<>./?@#$%^&*_~'''\ntest_str=df1.iloc[125]['Frame']\nfor ele in test_str:\n    if ele in punc:\n        test_str = test_str.replace(ele, \"\")","metadata":{"execution":{"iopub.status.busy":"2023-11-02T12:11:36.192246Z","iopub.execute_input":"2023-11-02T12:11:36.192645Z","iopub.status.idle":"2023-11-02T12:11:36.198515Z","shell.execute_reply.started":"2023-11-02T12:11:36.192615Z","shell.execute_reply":"2023-11-02T12:11:36.197562Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"test_str","metadata":{"execution":{"iopub.status.busy":"2023-11-02T12:11:38.543015Z","iopub.execute_input":"2023-11-02T12:11:38.543573Z","iopub.status.idle":"2023-11-02T12:11:38.548172Z","shell.execute_reply.started":"2023-11-02T12:11:38.543546Z","shell.execute_reply":"2023-11-02T12:11:38.547552Z"},"trusted":true},"execution_count":39,"outputs":[{"execution_count":39,"output_type":"execute_result","data":{"text/plain":"'jptimizations\\n\\n Peephole optimizations\\n« Analyze sequence’ instructions in a small window\\npeephole and using preset patterns replace them with a\\nmore ficient sequence\\n« Redundant instruction elimination\\neg replace the sequence LD ARIIST R1A by LD\\nARI\\n« Eliminate jump to jump instructions\\n« Use machine idioms use INC instead of LD and ADD\\n¢ Instruction scheduling reordering to eliminate pipeline\\ninterlocks and to increase parallelism\\n\\n Trace scheduling to increase the size of basic blocks and\\nincrease parallelism\\n\\n© Software pipelining to increase parallelism in loops\\n\\n \\n\\x0c'"},"metadata":{}}]},{"cell_type":"code","source":"import re\nfor i in range(0, len(df1)):\n    review=re.sub('[^a-zA-Z]', ' ',df1.loc[i]['Frame'])\n    df1.loc[i,['Frame']]=review","metadata":{"execution":{"iopub.status.busy":"2023-11-02T12:11:40.817454Z","iopub.execute_input":"2023-11-02T12:11:40.818421Z","iopub.status.idle":"2023-11-02T12:11:40.978866Z","shell.execute_reply.started":"2023-11-02T12:11:40.818388Z","shell.execute_reply":"2023-11-02T12:11:40.978151Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"df1.loc[4]['Frame']","metadata":{"execution":{"iopub.status.busy":"2023-11-02T12:11:42.658578Z","iopub.execute_input":"2023-11-02T12:11:42.659440Z","iopub.status.idle":"2023-11-02T12:11:42.666860Z","shell.execute_reply.started":"2023-11-02T12:11:42.659409Z","shell.execute_reply":"2023-11-02T12:11:42.665993Z"},"trusted":true},"execution_count":41,"outputs":[{"execution_count":41,"output_type":"execute_result","data":{"text/plain":"'  A detailed look at the internals of a compiler    Does not assume any background but is intensive   Doing programming assignments and solving theoretical  problems are both essential    A compiler is an excellent example of theory translated into practice in a remarkable way     '"},"metadata":{}}]},{"cell_type":"code","source":"import re\nreview=re.sub('[^a-zA-Z\\n]', ' ',df1.iloc[3]['Frame'])\ndf1.loc[3,['Frame']]=review","metadata":{"execution":{"iopub.status.busy":"2023-11-02T12:11:44.651263Z","iopub.execute_input":"2023-11-02T12:11:44.651599Z","iopub.status.idle":"2023-11-02T12:11:44.659321Z","shell.execute_reply.started":"2023-11-02T12:11:44.651574Z","shell.execute_reply":"2023-11-02T12:11:44.658304Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"len(df1)","metadata":{"execution":{"iopub.status.busy":"2023-11-02T12:11:47.002529Z","iopub.execute_input":"2023-11-02T12:11:47.002916Z","iopub.status.idle":"2023-11-02T12:11:47.009396Z","shell.execute_reply.started":"2023-11-02T12:11:47.002886Z","shell.execute_reply":"2023-11-02T12:11:47.008373Z"},"trusted":true},"execution_count":43,"outputs":[{"execution_count":43,"output_type":"execute_result","data":{"text/plain":"128"},"metadata":{}}]},{"cell_type":"code","source":"df1","metadata":{"execution":{"iopub.status.busy":"2023-11-02T12:11:48.770954Z","iopub.execute_input":"2023-11-02T12:11:48.771989Z","iopub.status.idle":"2023-11-02T12:11:48.783266Z","shell.execute_reply.started":"2023-11-02T12:11:48.771946Z","shell.execute_reply":"2023-11-02T12:11:48.782351Z"},"trusted":true},"execution_count":44,"outputs":[{"execution_count":44,"output_type":"execute_result","data":{"text/plain":"                                                 Frame  \\\n0    Principles of Compiler Design  Lecture       A...   \n1                                                        \n2      About the course    Why should we study comp...   \n3      A detailed look at the internals of a compil...   \n4      A detailed look at the internals of a compil...   \n..                                                 ...   \n123    Peephole optimizations    Analyze sequence o...   \n124  jptimizations    Peephole optimizations    Ana...   \n125  jptimizations    Peephole optimizations    Ana...   \n126    Peephole optimizations    Analyze sequence o...   \n127                                                      \n\n                                            Transcript  \n0    Welcome to this new course on Principles of Co...  \n1    Welcome to this new course on Principles of Co...  \n2    give you an overview of a compiler, but before...  \n3    So, the course is actually a first level cours...  \n4    going to take this course seriously are reques...  \n..                                                 ...  \n123  code generation phase of the compiler. There a...  \n124  For example, there are water known as machine ...  \n125  For example, there are water known as machine ...  \n126  where there is a jump instruction and the targ...  \n127                     etcetera. Thank you very much.  \n\n[128 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Frame</th>\n      <th>Transcript</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Principles of Compiler Design  Lecture       A...</td>\n      <td>Welcome to this new course on Principles of Co...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td></td>\n      <td>Welcome to this new course on Principles of Co...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>About the course    Why should we study comp...</td>\n      <td>give you an overview of a compiler, but before...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>A detailed look at the internals of a compil...</td>\n      <td>So, the course is actually a first level cours...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>A detailed look at the internals of a compil...</td>\n      <td>going to take this course seriously are reques...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>123</th>\n      <td>Peephole optimizations    Analyze sequence o...</td>\n      <td>code generation phase of the compiler. There a...</td>\n    </tr>\n    <tr>\n      <th>124</th>\n      <td>jptimizations    Peephole optimizations    Ana...</td>\n      <td>For example, there are water known as machine ...</td>\n    </tr>\n    <tr>\n      <th>125</th>\n      <td>jptimizations    Peephole optimizations    Ana...</td>\n      <td>For example, there are water known as machine ...</td>\n    </tr>\n    <tr>\n      <th>126</th>\n      <td>Peephole optimizations    Analyze sequence o...</td>\n      <td>where there is a jump instruction and the targ...</td>\n    </tr>\n    <tr>\n      <th>127</th>\n      <td></td>\n      <td>etcetera. Thank you very much.</td>\n    </tr>\n  </tbody>\n</table>\n<p>128 rows × 2 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"df1.loc[124]['Frame']","metadata":{"execution":{"iopub.status.busy":"2023-11-02T12:11:51.123399Z","iopub.execute_input":"2023-11-02T12:11:51.123777Z","iopub.status.idle":"2023-11-02T12:11:51.130290Z","shell.execute_reply.started":"2023-11-02T12:11:51.123748Z","shell.execute_reply":"2023-11-02T12:11:51.129337Z"},"trusted":true},"execution_count":45,"outputs":[{"execution_count":45,"output_type":"execute_result","data":{"text/plain":"'jptimizations    Peephole optimizations    Analyze sequence of instructions in a small window  peephole  and using preset patterns  replace them with a more efficient sequence   Redundant instruction elimination eg  replace the sequence  LD A RII ST R  A  by  LD ARI   Eliminate jump to jump instructions  Use machine idioms  use INC instead of LD and ADD     Instruction scheduling  reordefing  to eliminate pipeline interlocks and to increase parallelism    Trace scheduling to increase the size of basic blocks and increase parallelism    Software pipelining to increase parallelism in loops     '"},"metadata":{}}]},{"cell_type":"code","source":"df1.loc[125]['Frame']","metadata":{"execution":{"iopub.status.busy":"2023-11-02T12:11:53.503946Z","iopub.execute_input":"2023-11-02T12:11:53.504763Z","iopub.status.idle":"2023-11-02T12:11:53.510877Z","shell.execute_reply.started":"2023-11-02T12:11:53.504727Z","shell.execute_reply":"2023-11-02T12:11:53.509984Z"},"trusted":true},"execution_count":46,"outputs":[{"execution_count":46,"output_type":"execute_result","data":{"text/plain":"'jptimizations    Peephole optimizations    Analyze sequence   instructions in a small window  peephole  and using preset patterns  replace them with a more ficient sequence   Redundant instruction elimination eg  replace the sequence  LD A RII ST R  A  by  LD ARI    Eliminate jump to jump instructions   Use machine idioms  use INC instead of LD and ADD     Instruction scheduling  reordering  to eliminate pipeline interlocks and to increase parallelism    Trace scheduling to increase the size of basic blocks and increase parallelism    Software pipelining to increase parallelism in loops     '"},"metadata":{}}]},{"cell_type":"code","source":"df1.shape","metadata":{"execution":{"iopub.status.busy":"2023-11-02T12:11:55.305052Z","iopub.execute_input":"2023-11-02T12:11:55.305462Z","iopub.status.idle":"2023-11-02T12:11:55.311524Z","shell.execute_reply.started":"2023-11-02T12:11:55.305434Z","shell.execute_reply":"2023-11-02T12:11:55.310657Z"},"trusted":true},"execution_count":47,"outputs":[{"execution_count":47,"output_type":"execute_result","data":{"text/plain":"(128, 2)"},"metadata":{}}]},{"cell_type":"code","source":"df1","metadata":{"execution":{"iopub.status.busy":"2023-11-02T12:11:57.158811Z","iopub.execute_input":"2023-11-02T12:11:57.159161Z","iopub.status.idle":"2023-11-02T12:11:57.170328Z","shell.execute_reply.started":"2023-11-02T12:11:57.159134Z","shell.execute_reply":"2023-11-02T12:11:57.169454Z"},"trusted":true},"execution_count":48,"outputs":[{"execution_count":48,"output_type":"execute_result","data":{"text/plain":"                                                 Frame  \\\n0    Principles of Compiler Design  Lecture       A...   \n1                                                        \n2      About the course    Why should we study comp...   \n3      A detailed look at the internals of a compil...   \n4      A detailed look at the internals of a compil...   \n..                                                 ...   \n123    Peephole optimizations    Analyze sequence o...   \n124  jptimizations    Peephole optimizations    Ana...   \n125  jptimizations    Peephole optimizations    Ana...   \n126    Peephole optimizations    Analyze sequence o...   \n127                                                      \n\n                                            Transcript  \n0    Welcome to this new course on Principles of Co...  \n1    Welcome to this new course on Principles of Co...  \n2    give you an overview of a compiler, but before...  \n3    So, the course is actually a first level cours...  \n4    going to take this course seriously are reques...  \n..                                                 ...  \n123  code generation phase of the compiler. There a...  \n124  For example, there are water known as machine ...  \n125  For example, there are water known as machine ...  \n126  where there is a jump instruction and the targ...  \n127                     etcetera. Thank you very much.  \n\n[128 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Frame</th>\n      <th>Transcript</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Principles of Compiler Design  Lecture       A...</td>\n      <td>Welcome to this new course on Principles of Co...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td></td>\n      <td>Welcome to this new course on Principles of Co...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>About the course    Why should we study comp...</td>\n      <td>give you an overview of a compiler, but before...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>A detailed look at the internals of a compil...</td>\n      <td>So, the course is actually a first level cours...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>A detailed look at the internals of a compil...</td>\n      <td>going to take this course seriously are reques...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>123</th>\n      <td>Peephole optimizations    Analyze sequence o...</td>\n      <td>code generation phase of the compiler. There a...</td>\n    </tr>\n    <tr>\n      <th>124</th>\n      <td>jptimizations    Peephole optimizations    Ana...</td>\n      <td>For example, there are water known as machine ...</td>\n    </tr>\n    <tr>\n      <th>125</th>\n      <td>jptimizations    Peephole optimizations    Ana...</td>\n      <td>For example, there are water known as machine ...</td>\n    </tr>\n    <tr>\n      <th>126</th>\n      <td>Peephole optimizations    Analyze sequence o...</td>\n      <td>where there is a jump instruction and the targ...</td>\n    </tr>\n    <tr>\n      <th>127</th>\n      <td></td>\n      <td>etcetera. Thank you very much.</td>\n    </tr>\n  </tbody>\n</table>\n<p>128 rows × 2 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"df1.drop(df1[df1['Frame']=='   '].index, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2023-11-02T12:12:00.110707Z","iopub.execute_input":"2023-11-02T12:12:00.111055Z","iopub.status.idle":"2023-11-02T12:12:00.117199Z","shell.execute_reply.started":"2023-11-02T12:12:00.111027Z","shell.execute_reply":"2023-11-02T12:12:00.116183Z"},"trusted":true},"execution_count":49,"outputs":[]},{"cell_type":"code","source":"df1.drop_duplicates(inplace=True)","metadata":{"execution":{"iopub.status.busy":"2023-11-02T12:12:02.559329Z","iopub.execute_input":"2023-11-02T12:12:02.559706Z","iopub.status.idle":"2023-11-02T12:12:02.566941Z","shell.execute_reply.started":"2023-11-02T12:12:02.559678Z","shell.execute_reply":"2023-11-02T12:12:02.565866Z"},"trusted":true},"execution_count":50,"outputs":[]},{"cell_type":"code","source":"df1","metadata":{"execution":{"iopub.status.busy":"2023-11-02T12:12:05.043637Z","iopub.execute_input":"2023-11-02T12:12:05.044009Z","iopub.status.idle":"2023-11-02T12:12:05.055321Z","shell.execute_reply.started":"2023-11-02T12:12:05.043977Z","shell.execute_reply":"2023-11-02T12:12:05.054664Z"},"trusted":true},"execution_count":51,"outputs":[{"execution_count":51,"output_type":"execute_result","data":{"text/plain":"                                                 Frame  \\\n0    Principles of Compiler Design  Lecture       A...   \n2      About the course    Why should we study comp...   \n3      A detailed look at the internals of a compil...   \n4      A detailed look at the internals of a compil...   \n5      A detailed look at the internals of a compil...   \n..                                                 ...   \n122    Converts intermediate code to machine code  ...   \n123    Peephole optimizations    Analyze sequence o...   \n124  jptimizations    Peephole optimizations    Ana...   \n125  jptimizations    Peephole optimizations    Ana...   \n126    Peephole optimizations    Analyze sequence o...   \n\n                                            Transcript  \n0    Welcome to this new course on Principles of Co...  \n2    give you an overview of a compiler, but before...  \n3    So, the course is actually a first level cours...  \n4    going to take this course seriously are reques...  \n5    this course will not be understood you know pr...  \n..                                                 ...  \n122  code instructions actually give rise to only o...  \n123  code generation phase of the compiler. There a...  \n124  For example, there are water known as machine ...  \n125  For example, there are water known as machine ...  \n126  where there is a jump instruction and the targ...  \n\n[124 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Frame</th>\n      <th>Transcript</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Principles of Compiler Design  Lecture       A...</td>\n      <td>Welcome to this new course on Principles of Co...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>About the course    Why should we study comp...</td>\n      <td>give you an overview of a compiler, but before...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>A detailed look at the internals of a compil...</td>\n      <td>So, the course is actually a first level cours...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>A detailed look at the internals of a compil...</td>\n      <td>going to take this course seriously are reques...</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>A detailed look at the internals of a compil...</td>\n      <td>this course will not be understood you know pr...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>122</th>\n      <td>Converts intermediate code to machine code  ...</td>\n      <td>code instructions actually give rise to only o...</td>\n    </tr>\n    <tr>\n      <th>123</th>\n      <td>Peephole optimizations    Analyze sequence o...</td>\n      <td>code generation phase of the compiler. There a...</td>\n    </tr>\n    <tr>\n      <th>124</th>\n      <td>jptimizations    Peephole optimizations    Ana...</td>\n      <td>For example, there are water known as machine ...</td>\n    </tr>\n    <tr>\n      <th>125</th>\n      <td>jptimizations    Peephole optimizations    Ana...</td>\n      <td>For example, there are water known as machine ...</td>\n    </tr>\n    <tr>\n      <th>126</th>\n      <td>Peephole optimizations    Analyze sequence o...</td>\n      <td>where there is a jump instruction and the targ...</td>\n    </tr>\n  </tbody>\n</table>\n<p>124 rows × 2 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"df1.loc[5]['Transcript']","metadata":{"execution":{"iopub.status.busy":"2023-11-02T12:12:07.508753Z","iopub.execute_input":"2023-11-02T12:12:07.509173Z","iopub.status.idle":"2023-11-02T12:12:07.515750Z","shell.execute_reply.started":"2023-11-02T12:12:07.509138Z","shell.execute_reply":"2023-11-02T12:12:07.514699Z"},"trusted":true},"execution_count":52,"outputs":[{"execution_count":52,"output_type":"execute_result","data":{"text/plain":"'this course will not be understood you know properly. The reason is a compiler is an excellent'"},"metadata":{}}]},{"cell_type":"code","source":"df1.loc[3]['Transcript']","metadata":{"execution":{"iopub.status.busy":"2023-11-02T12:12:09.841981Z","iopub.execute_input":"2023-11-02T12:12:09.842351Z","iopub.status.idle":"2023-11-02T12:12:09.849014Z","shell.execute_reply.started":"2023-11-02T12:12:09.842321Z","shell.execute_reply":"2023-11-02T12:12:09.848061Z"},"trusted":true},"execution_count":53,"outputs":[{"execution_count":53,"output_type":"execute_result","data":{"text/plain":"'So, the course is actually a first level course. In other words, this takes a detail look at the'"},"metadata":{}}]},{"cell_type":"code","source":"df1.loc[4]['Transcript']","metadata":{"execution":{"iopub.status.busy":"2023-11-02T12:12:10.535512Z","iopub.execute_input":"2023-11-02T12:12:10.535902Z","iopub.status.idle":"2023-11-02T12:12:10.542819Z","shell.execute_reply.started":"2023-11-02T12:12:10.535870Z","shell.execute_reply":"2023-11-02T12:12:10.541820Z"},"trusted":true},"execution_count":54,"outputs":[{"execution_count":54,"output_type":"execute_result","data":{"text/plain":"'going to take this course seriously are requested to do the programming assignments.'"},"metadata":{}}]},{"cell_type":"code","source":"df1.loc[3]['Frame']","metadata":{"execution":{"iopub.status.busy":"2023-11-02T12:12:11.081644Z","iopub.execute_input":"2023-11-02T12:12:11.082386Z","iopub.status.idle":"2023-11-02T12:12:11.088317Z","shell.execute_reply.started":"2023-11-02T12:12:11.082351Z","shell.execute_reply":"2023-11-02T12:12:11.087390Z"},"trusted":true},"execution_count":55,"outputs":[{"execution_count":55,"output_type":"execute_result","data":{"text/plain":"'  A detailed look at the internals of a compiler    Does not assume any background but is intensive   Doing programming assignments and solving theoretical  problems are both essential    A compiler is an excellent example of theory translated into practice in a remarkable way     '"},"metadata":{}}]},{"cell_type":"code","source":"df1.reset_index(inplace=True)","metadata":{"execution":{"iopub.status.busy":"2023-11-02T12:12:11.254737Z","iopub.execute_input":"2023-11-02T12:12:11.255079Z","iopub.status.idle":"2023-11-02T12:12:11.260485Z","shell.execute_reply.started":"2023-11-02T12:12:11.255050Z","shell.execute_reply":"2023-11-02T12:12:11.259471Z"},"trusted":true},"execution_count":56,"outputs":[]},{"cell_type":"code","source":"df1.columns","metadata":{"execution":{"iopub.status.busy":"2023-11-02T12:12:11.492075Z","iopub.execute_input":"2023-11-02T12:12:11.492466Z","iopub.status.idle":"2023-11-02T12:12:11.499003Z","shell.execute_reply.started":"2023-11-02T12:12:11.492436Z","shell.execute_reply":"2023-11-02T12:12:11.498156Z"},"trusted":true},"execution_count":57,"outputs":[{"execution_count":57,"output_type":"execute_result","data":{"text/plain":"Index(['index', 'Frame', 'Transcript'], dtype='object')"},"metadata":{}}]},{"cell_type":"code","source":"df1.drop(['index'],axis=1, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2023-11-02T12:12:11.677743Z","iopub.execute_input":"2023-11-02T12:12:11.678103Z","iopub.status.idle":"2023-11-02T12:12:11.683979Z","shell.execute_reply.started":"2023-11-02T12:12:11.678074Z","shell.execute_reply":"2023-11-02T12:12:11.683027Z"},"trusted":true},"execution_count":58,"outputs":[]},{"cell_type":"code","source":"df1","metadata":{"execution":{"iopub.status.busy":"2023-11-02T18:44:32.954313Z","iopub.execute_input":"2023-11-02T18:44:32.955252Z","iopub.status.idle":"2023-11-02T18:44:32.967414Z","shell.execute_reply.started":"2023-11-02T18:44:32.955218Z","shell.execute_reply":"2023-11-02T18:44:32.966627Z"},"trusted":true},"execution_count":231,"outputs":[{"execution_count":231,"output_type":"execute_result","data":{"text/plain":"                                                 Frame  \\\n0    Principles of Compiler Design Lecture An Overv...   \n1    About the course Why should we study compiler ...   \n2    A detailed look at the internals of a compiler...   \n3    Compilers are everywhere Many applications for...   \n4    Compilers are everywhere Many applications for...   \n..                                                 ...   \n112  Converts intermediate code to machine code Eac...   \n113  Peephole optimizations Analyze sequence of ins...   \n114  jptimizations Peephole optimizations Analyze s...   \n115  jptimizations Peephole optimizations Analyze s...   \n116  Peephole optimizations Analyze sequence of ins...   \n\n                                            Transcript  \n0    Welcome to this new course on Principles of Co...  \n1    give you an overview of a compiler, but before...  \n2    So, the course is actually a first level cours...  \n3    So, if you look at the applications of modern ...  \n4    homepage and that you are going to visit and s...  \n..                                                 ...  \n112  code instructions actually give rise to only o...  \n113  code generation phase of the compiler. There a...  \n114  For example, there are water known as machine ...  \n115  For example, there are water known as machine ...  \n116  where there is a jump instruction and the targ...  \n\n[117 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Frame</th>\n      <th>Transcript</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Principles of Compiler Design Lecture An Overv...</td>\n      <td>Welcome to this new course on Principles of Co...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>About the course Why should we study compiler ...</td>\n      <td>give you an overview of a compiler, but before...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>A detailed look at the internals of a compiler...</td>\n      <td>So, the course is actually a first level cours...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Compilers are everywhere Many applications for...</td>\n      <td>So, if you look at the applications of modern ...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Compilers are everywhere Many applications for...</td>\n      <td>homepage and that you are going to visit and s...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>112</th>\n      <td>Converts intermediate code to machine code Eac...</td>\n      <td>code instructions actually give rise to only o...</td>\n    </tr>\n    <tr>\n      <th>113</th>\n      <td>Peephole optimizations Analyze sequence of ins...</td>\n      <td>code generation phase of the compiler. There a...</td>\n    </tr>\n    <tr>\n      <th>114</th>\n      <td>jptimizations Peephole optimizations Analyze s...</td>\n      <td>For example, there are water known as machine ...</td>\n    </tr>\n    <tr>\n      <th>115</th>\n      <td>jptimizations Peephole optimizations Analyze s...</td>\n      <td>For example, there are water known as machine ...</td>\n    </tr>\n    <tr>\n      <th>116</th>\n      <td>Peephole optimizations Analyze sequence of ins...</td>\n      <td>where there is a jump instruction and the targ...</td>\n    </tr>\n  </tbody>\n</table>\n<p>117 rows × 2 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"print(df1.loc[113]['Transcript']+\"\\n\")\nprint(df1.loc[114]['Transcript']+\"\\n\")\nprint(df1.loc[115]['Transcript']+\"\\n\")\nprint(df1.loc[116]['Transcript'])","metadata":{"execution":{"iopub.status.busy":"2023-11-02T18:44:53.159873Z","iopub.execute_input":"2023-11-02T18:44:53.160743Z","iopub.status.idle":"2023-11-02T18:44:53.169377Z","shell.execute_reply.started":"2023-11-02T18:44:53.160702Z","shell.execute_reply":"2023-11-02T18:44:53.168055Z"},"trusted":true},"execution_count":232,"outputs":[{"name":"stdout","text":"code generation phase of the compiler. There are also after machine code generation even\n\nFor example, there are water known as machine dependent optimizations. If you are listed\n\nFor example, there are water known as machine dependent optimizations. If you are listed\n\nwhere there is a jump instruction and the target is another jump then this jump to jump\n","output_type":"stream"}]},{"cell_type":"code","source":"df1.loc[5]['Frame']","metadata":{"execution":{"iopub.status.busy":"2023-11-02T12:12:12.041706Z","iopub.execute_input":"2023-11-02T12:12:12.042060Z","iopub.status.idle":"2023-11-02T12:12:12.048086Z","shell.execute_reply.started":"2023-11-02T12:12:12.042030Z","shell.execute_reply":"2023-11-02T12:12:12.047402Z"},"trusted":true},"execution_count":60,"outputs":[{"execution_count":60,"output_type":"execute_result","data":{"text/plain":"'     Compilers are everywhere    Many applications for compiler technology   Parsers for HTML in web browser Interpreters for javascriptlash Machine code generation for high level languages Software testing  Program optimization Malicious code detection Design of new computer architectures     Compilerinthe loop hardware development    Hardware synthesis  VHDL to RTL translation Compiled simulation    Used to simulate designs writen in VHOL  No inlerpretaton of design  hence faster  '"},"metadata":{}}]},{"cell_type":"code","source":"df1.loc[5]['Transcript']","metadata":{"execution":{"iopub.status.busy":"2023-11-02T12:12:15.621062Z","iopub.execute_input":"2023-11-02T12:12:15.621466Z","iopub.status.idle":"2023-11-02T12:12:15.628070Z","shell.execute_reply.started":"2023-11-02T12:12:15.621435Z","shell.execute_reply":"2023-11-02T12:12:15.626997Z"},"trusted":true},"execution_count":61,"outputs":[{"execution_count":61,"output_type":"execute_result","data":{"text/plain":"'So, if you look at the applications of modern compiler technology pick up the browser,'"},"metadata":{}}]},{"cell_type":"code","source":"print(df1.loc[6]['Frame'])\nprint(\"\\n\")\nprint(df1.loc[6]['Transcript'])","metadata":{"execution":{"iopub.status.busy":"2023-11-02T12:12:17.854232Z","iopub.execute_input":"2023-11-02T12:12:17.854605Z","iopub.status.idle":"2023-11-02T12:12:17.860992Z","shell.execute_reply.started":"2023-11-02T12:12:17.854576Z","shell.execute_reply":"2023-11-02T12:12:17.860064Z"},"trusted":true},"execution_count":62,"outputs":[{"name":"stdout","text":"     Compilers are everywhere     Many applications for compiler technology   Parsers for HTML in web browser    Interpreters for javascripttiash    Machine code generation for high level languages    Software testing     Program optimization    Malicious code detection    Design of new computer architectures    Compiler in the loop hardware development    Hardware synthesis  VHDL to RTL translation   Compiled simulation  Used to simulate designs writen in VHDL  No interpretation of design  hence faster  \n\n\nhomepage and that you are going to visit and so on. So, the HTML parsers are based on compiler\n","output_type":"stream"}]},{"cell_type":"code","source":"for i in range(0, len(df1)):\n    \n    df1.loc[i]['Frame']= re.sub(r'\\s+', ' ', df1.loc[i]['Frame']).strip()\n    df1.loc[i]['Transcript']= re.sub(r'\\s+', ' ', df1.loc[i]['Transcript']).strip()","metadata":{"execution":{"iopub.status.busy":"2023-11-02T14:36:20.014164Z","iopub.execute_input":"2023-11-02T14:36:20.014566Z","iopub.status.idle":"2023-11-02T14:36:20.066517Z","shell.execute_reply.started":"2023-11-02T14:36:20.014539Z","shell.execute_reply":"2023-11-02T14:36:20.065440Z"},"trusted":true},"execution_count":127,"outputs":[]},{"cell_type":"markdown","source":"## To check if two strings are 70% similar, you can use various algorithms such as Levenshtein distance, Jaccard similarity, or SequenceMatcher from the difflib module. Here's an example using the SequenceMatcher:","metadata":{}},{"cell_type":"code","source":"\nfrom difflib import SequenceMatcher\n\ndef are_similar(str1, str2, threshold=0.7):\n    similarity_ratio = SequenceMatcher(None, str1, str2).ratio()\n    return similarity_ratio >= threshold\nprint(are_similar(combined_df.loc[3]['Frame'], combined_df.loc[4]['Frame']))","metadata":{"execution":{"iopub.status.busy":"2023-11-02T19:05:44.429356Z","iopub.execute_input":"2023-11-02T19:05:44.429753Z","iopub.status.idle":"2023-11-02T19:05:44.438243Z","shell.execute_reply.started":"2023-11-02T19:05:44.429719Z","shell.execute_reply":"2023-11-02T19:05:44.437206Z"},"trusted":true},"execution_count":240,"outputs":[{"name":"stdout","text":"True\n","output_type":"stream"}]},{"cell_type":"code","source":"text=pd.DataFrame(columns=['Frame', 'Transcript'])\n\nfor i in range(0, len(df1)-1):\n    \n    if are_similar(df1.loc[i]['Frame'], df1.loc[i+1]['Frame']): \n        if are_similar( df1.loc[i]['Transcript'],df1.loc[i+1]['Transcript']) and  len(text)>0 and are_similar( df1.loc[i]['Frame'],text.loc[len(text)-1]['Frame'] ):\n            if len(text)>0 and are_similar(df1.loc[i]['Transcript'],text.loc[len(text)-1]['Transcript']):\n#                 i=i+1\n                continue\n            elif len(text)>0:\n                num=len(text)-1\n                s = text.loc[num, 'Transcript'] + (df1.loc[i, 'Transcript'])\n\n                 #Update the 'Transcript' column in the 'text' DataFrame\n                text.loc[num, 'Transcript'] = s\n                    \n        elif (are_similar( df1.loc[i]['Transcript'],df1.loc[i+1]['Transcript'])):\n            new_row={ 'Frame': df1.loc[i]['Frame'] ,'Transcript': df1.loc[i]['Transcript']}\n            text.loc[len(text)]=new_row\n            \n        elif len(text)>0 and are_similar( df1.loc[i]['Frame'],text.loc[len(text)-1]['Frame'] ):\n            \n            num=len(text)-1\n            # Get values from df1 and df2\n            s = text.loc[num, 'Transcript'] + (df1.loc[i, 'Transcript'] + df1.loc[i+1, 'Transcript'])\n            # Update the 'Transcript' column in the 'text' DataFrame\n            text.loc[num, 'Transcript'] = s\n        \n        else:\n            new_row={ 'Frame': df1.loc[i]['Frame'] ,'Transcript': df1.loc[i]['Transcript']}\n            text.loc[len(text)]=new_row\n    elif len(text)>0 and are_similar( df1.loc[i]['Frame'],text.loc[len(text)-1]['Frame'] ):\n        s=text.loc[len(text)-1]['Transcript'] +df1.loc[i]['Transcript']\n        text.loc[len(text)-1]['Transcript']=s\n        \n    else :\n        new_row={ 'Frame': df1.loc[i]['Frame'] ,'Transcript': df1.loc[i]['Transcript']}\n        text.loc[len(text)]=new_row\n","metadata":{"execution":{"iopub.status.busy":"2023-11-02T19:38:23.303414Z","iopub.execute_input":"2023-11-02T19:38:23.304067Z","iopub.status.idle":"2023-11-02T19:38:23.742031Z","shell.execute_reply.started":"2023-11-02T19:38:23.304036Z","shell.execute_reply":"2023-11-02T19:38:23.741243Z"},"trusted":true},"execution_count":280,"outputs":[]},{"cell_type":"code","source":"text","metadata":{"execution":{"iopub.status.busy":"2023-11-02T19:38:26.448050Z","iopub.execute_input":"2023-11-02T19:38:26.448414Z","iopub.status.idle":"2023-11-02T19:38:26.462357Z","shell.execute_reply.started":"2023-11-02T19:38:26.448385Z","shell.execute_reply":"2023-11-02T19:38:26.461249Z"},"trusted":true},"execution_count":281,"outputs":[{"execution_count":281,"output_type":"execute_result","data":{"text/plain":"                                                Frame  \\\n0   Principles of Compiler Design Lecture An Overv...   \n1   About the course Why should we study compiler ...   \n2   A detailed look at the internals of a compiler...   \n3   Compilers are everywhere Many applications for...   \n4   About the Complexity of Compiler Technology A ...   \n5   Draws results from mathematical logic lattice ...   \n6   ie Nature of Compiler Algorithms Draws results...   \n7   About the Nature of Compiler Algorithms Draws ...   \n8   Parsing Techniques Assembler implementation On...   \n9   Program Analysis Techniques Converting a seque...   \n10  anguage Processing System source program ands ...   \n11  ompller Overview character stream i optimized ...   \n12  Compilers generate machine code whereas interp...   \n13  fahrenheit centigrade Lexical Analyzer id assi...   \n14  LA can be generated automatically trom regular...   \n15  id assign id multop fconst addop iconst Syntax...   \n16  Parsing or Syntax analyzers parsers can be gen...   \n17                                 Int code Generator   \n18  Semantic consistency that cannot be handled at...   \n19  intofloat i Int Code Generator tHeid intofloat...   \n20  While generating machine code directly from so...   \n21  The type of intermediate code deployed is base...   \n22  t ia intoftoat Bene ites Code Optimizer teid i...   \n23  Intermediate code generation process introduce...   \n24  Common sub expression elimination Copy propaga...   \n25  xamples of Machine Independant Optimizations C...   \n26  Henne dt tt Code Generator LDF id MULF R ADOF ...   \n27  Converts intermediate code to machine code Eac...   \n28  Peephole optimizations Analyze sequence of ins...   \n29  jptimizations Peephole optimizations Analyze s...   \n\n                                           Transcript  \n0   Welcome to this new course on Principles of Co...  \n1   give you an overview of a compiler, but before...  \n2   So, the course is actually a first level cours...  \n3   So, if you look at the applications of modern ...  \n4   than interpretations. So, about the complexity...  \n5   So, now let us look at the type of algorithms ...  \n6   these used? For example, mathematical logic is...  \n7   on loop dependance analysis. So, cache analysi...  \n8   compiler technology some aspects of compiler t...  \n9   you know performs scanning and parsing and ano...  \n10  So, that is about you know the motivation to s...  \n11  compiler consists of many blocks they are all ...  \n12  two. Compilers generate machine code whereas, ...  \n13  based languages. Now, let us get back to the b...  \n14  from regular expression specifications. So, fo...  \n15  giving the program to the syntax lizer. So, th...  \n16  So, we will learn about these specifications a...  \n17  analysis is supposed to take care of it. So, t...  \n18  So, semantic consistency that cannot be handle...  \n19  code generation phase. So, the annotated synta...  \n20  original source level program, but it is at a ...  \n21  types of intermediate code as well. So, the ty...  \n22  Now, the code optimizer is the next phase whic...  \n23  The machine independent code optimization actu...  \n24  So, there are different types of machine depen...  \n25  spectrum elimination, copy propagation, loop i...  \n26  the end of the course. Finally, the machine co...  \n27  point corresponding to these two instructions ...  \n28  code generation phase of the compiler. There a...  \n29  For example, there are water known as machine ...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Frame</th>\n      <th>Transcript</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Principles of Compiler Design Lecture An Overv...</td>\n      <td>Welcome to this new course on Principles of Co...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>About the course Why should we study compiler ...</td>\n      <td>give you an overview of a compiler, but before...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>A detailed look at the internals of a compiler...</td>\n      <td>So, the course is actually a first level cours...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Compilers are everywhere Many applications for...</td>\n      <td>So, if you look at the applications of modern ...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>About the Complexity of Compiler Technology A ...</td>\n      <td>than interpretations. So, about the complexity...</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Draws results from mathematical logic lattice ...</td>\n      <td>So, now let us look at the type of algorithms ...</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>ie Nature of Compiler Algorithms Draws results...</td>\n      <td>these used? For example, mathematical logic is...</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>About the Nature of Compiler Algorithms Draws ...</td>\n      <td>on loop dependance analysis. So, cache analysi...</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>Parsing Techniques Assembler implementation On...</td>\n      <td>compiler technology some aspects of compiler t...</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>Program Analysis Techniques Converting a seque...</td>\n      <td>you know performs scanning and parsing and ano...</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>anguage Processing System source program ands ...</td>\n      <td>So, that is about you know the motivation to s...</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>ompller Overview character stream i optimized ...</td>\n      <td>compiler consists of many blocks they are all ...</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>Compilers generate machine code whereas interp...</td>\n      <td>two. Compilers generate machine code whereas, ...</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>fahrenheit centigrade Lexical Analyzer id assi...</td>\n      <td>based languages. Now, let us get back to the b...</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>LA can be generated automatically trom regular...</td>\n      <td>from regular expression specifications. So, fo...</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>id assign id multop fconst addop iconst Syntax...</td>\n      <td>giving the program to the syntax lizer. So, th...</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>Parsing or Syntax analyzers parsers can be gen...</td>\n      <td>So, we will learn about these specifications a...</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>Int code Generator</td>\n      <td>analysis is supposed to take care of it. So, t...</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>Semantic consistency that cannot be handled at...</td>\n      <td>So, semantic consistency that cannot be handle...</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>intofloat i Int Code Generator tHeid intofloat...</td>\n      <td>code generation phase. So, the annotated synta...</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>While generating machine code directly from so...</td>\n      <td>original source level program, but it is at a ...</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>The type of intermediate code deployed is base...</td>\n      <td>types of intermediate code as well. So, the ty...</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>t ia intoftoat Bene ites Code Optimizer teid i...</td>\n      <td>Now, the code optimizer is the next phase whic...</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>Intermediate code generation process introduce...</td>\n      <td>The machine independent code optimization actu...</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>Common sub expression elimination Copy propaga...</td>\n      <td>So, there are different types of machine depen...</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>xamples of Machine Independant Optimizations C...</td>\n      <td>spectrum elimination, copy propagation, loop i...</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>Henne dt tt Code Generator LDF id MULF R ADOF ...</td>\n      <td>the end of the course. Finally, the machine co...</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>Converts intermediate code to machine code Eac...</td>\n      <td>point corresponding to these two instructions ...</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>Peephole optimizations Analyze sequence of ins...</td>\n      <td>code generation phase of the compiler. There a...</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>jptimizations Peephole optimizations Analyze s...</td>\n      <td>For example, there are water known as machine ...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"print(text.loc[10]['Frame'])\nprint(text.loc[11]['Frame']+\"\\n\")\nprint(text.loc[10]['Transcript']+\"\\n\")\nprint(text.loc[28]['Transcript'] +\"\\n\")\n\nprint(are_similar(text.loc[13]['Frame'], text.loc[14]['Frame']))","metadata":{"execution":{"iopub.status.busy":"2023-11-02T19:38:29.676319Z","iopub.execute_input":"2023-11-02T19:38:29.676768Z","iopub.status.idle":"2023-11-02T19:38:29.685655Z","shell.execute_reply.started":"2023-11-02T19:38:29.676732Z","shell.execute_reply":"2023-11-02T19:38:29.684577Z"},"trusted":true},"execution_count":282,"outputs":[{"name":"stdout","text":"anguage Processing System source program ands mace modified source program Compiler A LANGUAGE PROCESSING target assembly program py Assembler relocatable machine code a library files inker Loader relocatable object fil target machine code\nompller Overview character stream i optimized Lexical Analyze target machine code token stream syntax Analyzer Symbol syntax tree Table Semantic Analyzer target machine code Code Generator optimized annotated syntax tree intermediate representation Machine tndependent Intermediate Code Generator Code Optimizer intermediate representation\n\nSo, that is about you know the motivation to study this subject called compiler design.So, let us begin with this block diagram which talks about a general language processing\n\ncode generation phase of the compiler. There are also after machine code generation even\n\nFalse\n","output_type":"stream"}]},{"cell_type":"code","source":"from IPython.display import HTML\nimport pandas as pd\nimport numpy as np\nimport base64\n\ndf.to_csv(\"data.csv\", index=False)\n\ndef create_download_link(df, title = \"Download CSV file\", filename = \"data.csv\"):  \n    csv = df.to_csv()\n    b64 = base64.b64encode(csv.encode())\n    payload = b64.decode()\n    html = '<a download=\"{filename}\" href=\"data:text/csv;base64,{payload}\" target=\"_blank\">{title}</a>'\n    html = html.format(payload=payload,title=title,filename=filename)\n    return HTML(html)\ncreate_download_link(df)\n","metadata":{"execution":{"iopub.status.busy":"2023-11-02T19:27:10.666030Z","iopub.execute_input":"2023-11-02T19:27:10.666440Z","iopub.status.idle":"2023-11-02T19:27:10.684153Z","shell.execute_reply.started":"2023-11-02T19:27:10.666409Z","shell.execute_reply":"2023-11-02T19:27:10.683085Z"},"trusted":true},"execution_count":272,"outputs":[{"execution_count":272,"output_type":"execute_result","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<a download=\"data.csv\" href=\"data:text/csv;base64,,Frame,Transcript
0,Principles of Compiler Design Lecture An Overview of a compiler Y N SRIKANT Computer Science and Automation Indian Institute of Science Bangalore,"Welcome to this new course on Principles of Compiler Design. So, in this lecture I will"
1,About the course Why should we study compiler design Compiler overview with block diagrams,"give you an overview of a compiler, but before that we will also see how exactly the course"
2,A detailed look at the internals of a compiler Does not assume any background but is intensive Doing programming assignments and solving theoretical problems are both essential A compiler is an excellent example of theory translated into practice in a remarkable way,"So, the course is actually a first level course. In other words, this takes a detail look at the going to take this course seriously are requested to do the programming assignments. this course will not be understood you know properly. The reason is a compiler is an excellent"
3,Compilers are everywhere Many applications for compiler technology Parsers for HTML in web browser Interpreters for javascripttiash Machine code generation for high level languages Software testing Program optimization Malicious code detection Design of new computer architectures Compiler in the loop hardware development Hardware synthesis VHDL to RTL translation Compiled simulation Used to simulate designs writen in VHDL No interpretation of design hence faster,"homepage and that you are going to visit and so on. So, the HTML parsers are based on compiler"
4,We Study Compiler Design Compilers are everywhere Many applications for compiler technology Parsers for HTML in web browser Interpreters for javascriptfash Machine code generation for high level languages Software testing Program optimization Malicious code detection Design of new computer architectures Compierin the loop hardware development Hardware synthesis VHDL to ATL translation Compiled simulation Used to simulate designs writen in VHOL No inlerprtaton of design hence faster,a computer program which is generated for that particular program which is being simulated.
5,A compiler is possibly the most complex system software and writing it is a substantial exercise in software engineering The complexity arises from the fact that itis required to map a programmer s requirements in a HLL program to architectural details Ituses algorithms and techniques from a very large number of areas in computer science Translates intricate theory into practice enables tool building,"as Yoc which do this. So, this enable in this enables tool building. So, tools take very"
6,Draws results from mathematical logic lattice theory linear algebra probability etc type checking static analysis dependence analysis and loop parallelization cache analysis etc Makes practical application of Greedy algorithms register allocation Heuristic search ist scheduling Graph algorithms dead code elimination register allocation Dynamic programming instruction selection Optimization techniques instruction scheduling Finite automata lexical analysis Pushdown automata parsing Fixed point algorithms data low aralysis Complex data structures symbol tables par dependence graphs Computer architecture machine code gen,"So, now let us look at the type of algorithms which are used inside a compiler and see"
7,ie Nature of Compiler Algorithms Draws results from mathematical logic lattice theory linear algebra probability etc type checking static analysis dependence analysis and loop parallelization cache analysis etc Makes practical application of Greedy algorithms register allocation Heuristic search ist scheduling Graph algorithms dead code elimination register allocation Dynamic programming instruction selection Optimization techniques instruction scheduling Finite automata lexical analysis Pushdown automata parsing Fixed point algorithms data low analysis Complex data structures symbol tables pa dependence graphs Computer architecture machine code gene,"these used? For example, mathematical logic is used to you know in developing type checking"
8,About the Nature of Compiler Algorithms Draws results from mathematical logic lattice theory linear algebra probability etc type checking static analysis dependence analysis and loop parallelization cache analysis etc Makes practical application of Greedy algorithms register allocation Heuristic search lst scheduling Graph algorithms dead code elimination register allocation Dynamic programming instruction selection Optimization techniques instruction scheduling Finite automata lexical analysis Pushdown automata parsing Fixed point algorithms data low analysis Complex data structures symbol tables par dependence graphs Computer architecture machine code gener,"on loop dependance analysis. So, cache analysis uses both static analysis and probability"
9,ie Nature of Compiler Algorithms Draws results from mathematical logic lattice theory linear algebra probability etc type checking static analysis dependence analysis and loop parallelization cache analysis etc Makes practical application of Greedy algorithms register allocation Heuristic search ist scheduling Graph algorithms dead code elimination register allocation Dynamic programming instruction selection Optimization techniques instruction scheduling Finite automata lexical analysis Pushdown automata parsing Fixed point algorithms data low analysis Complex data structures symbol tables pa dependence graphs Computer architecture machine code gene,"algorithms. In our course, we are going to study the existing compiler algorithms, but"
10,Draws results from mathematical logic lattice theory linear algebra probability etc type checking static analysis dependence analysis and loop parallelization cache analysis etc Makes practical application of Greedy algorithms register allocation Heuristic search list scheduling Graph algorithms dead code elimination register allocation Dynamic programming instruction selection Optimization techniques instruction scheduling Finite automata lexical analysis Pushdown automata parsing Fixed point algorithms data low analysis Complex data structures symbol tables parse trees data dependence graphs Computer architecture machine code generation,"parsing, fixed point algorithms are used for data flow analysis, very complex data structures"
11,Parsing Techniques Assembler implementation Online text searching GREP AWK and word processing Website filtering Command language interpreters Scripting language interpretation Unix shell Perl Python XML parsing and document tree construction Database query interpreters,"compiler technology some aspects of compiler technology. For example, scanning and parsing"
12,Program Analysis Techniques Converting a sequential loop to a parallel loop Program analysis to determine if programs are data race free Profiling programs to determine busy regions Program slicing Data flow analysis approach to software testing Uncovering errors along all paths Dereterencing null pointers Butfer overtiows and memory leaks Worst Case Execution Time WCET estimat energy analysis,analysis. If you look at a program it is very difficult to say what is the worst case
13,anguage Processing System source program ands mace modified source program Compiler A LANGUAGE PROCESSING target assembly program py Assembler relocatable machine code a library files inker Loader relocatable object fil target machine code,"So, that is about you know the motivation to study this subject called compiler design."
14,anguage Processing System source program Preprocessor Scarcsmacrs modified source program Compiler A LANGUAGE PROCESSING target assembly program Pasay Assembler relocatable machine code ee rary les relocatable object files target machine code,"So, let us begin with this block diagram which talks about a general language processing"
15,ompller Overview character stream i optimized Lexical Analyze target machine code token stream syntax Analyzer Symbol syntax tree Table Semantic Analyzer target machine code Code Generator optimized annotated syntax tree intermediate representation Machine tndependent Intermediate Code Generator Code Optimizer intermediate representation,compiler consists of many blocks they are all listed here.
16,Compilers generate machine code whereas interpreters interpret intermediate code Interpreters are easier to write and can provide better error messages symbol table is still available Interpreters are at least times slower than machine code generated by compilers Interpreters also require much more memory than machine code generated by compilers Examples Perl Python Unix Shell Java BASIC LISP,"And then you know even the compilation, lexical analysis parsing etcetera is all the time required"
17,Compilers generate machine code whereas interpreters interpret intermediate code Interpreters are easier to write and can provide better error messages symbol table is still available Interpreters are at least times slower than machine code generated by compilers Interpreters also require much more memory than machine code generated by compilers Examples Perl Python Unix Shell Java BASJG LISP,"much more memory much more time than machine code generated by compilers and there are very famous examples per Python, Unixel, Java, Basic, List etcetera are all you know interpreter"
18,fahrenheit centigrade Lexical Analyzer id assign id multop fconst addop iconst Syntax Analyzer,"based languages. Now, let us get back to the block diagram and let us look at the lexical is a line far and high equal to centigrade star 1.8 plus 32. This is an assignment statement This is the input to syntax and lizer. So, now let us look at the reasons why lexical"
19,LA can be generated automatically trom regular expression specifications LEX and Flex are two such tools LAis a deterministic finite state automaton Why is LA separate from parsing Simplification of design software engineering reason issues are limited LA alone LAbased on finite automata are more efficient to implement than pushdown automata used for parsing due to stack,available in unix and if we feed a regular expression specification we are going to study
20,exical Analysis LA can be generated automatically trom regular expression specifications LEX and Flex are two such tools LAis a deterministic finite state automaton Why is LA separate from parsing Simplification of design software engineering reason issues are limited LA alone LAbased on finite automata are more efficient to implement than pushdown automata used for parsing due to stack,under the stack then popping them off the stack and so on which are very inefficient
21,fahrenheit centigrade Lexical Analyzer id assign id multop fconst addop iconst Syntax Analyzer,above this was Fahrenheit equal to you know as as let us look at it.
22,Parsing or Syntax analyzers parsers can be generated automatically from several variants of context free grammar specifications LL and LALR are the most popular ones ANTLR for LL YACC and Bison for LALR are such tools Parsers are deterministic push down automata Parsers cannot handle context sensitive features of programming languages g Variables are declared before use Types match on both sides of assignments Parameter types and number match in declar,"So, we will learn about these specifications a little later, but right now it suffices"
23,Parsing or Syntax analyzers parsers can be generated automatically from several variants of context free grammar specifications LL and LALR are the most popular ones ANTLR for LL YACC and Bison for LALR are such tools Parsers are deterministic push down automata Parsers cannot handle context sensitive features of programming languages g Variables are deciared before use Types match on both sides of assignments Parameter types and number match in declaration and use,"is here you know parameter types and number match in declaration and use. So, we declare"
24,Int code Generator,"analysis is supposed to take care of it. So, the next phase is the semantic analysis phase 32. So, if there is some violation the you cannot really add floating point numbers"
25,Semantic consistency that cannot be handled at the parsing stage is handled here Type checking of various programming language constructs is one of the most important tasks Stores type information in the symbol table or the syntax tree Types of variables function parameters array dimensions ete Used not only for semantic validation but also for subsequent phases of compilation Static semantics of programming languages can be specitied using attribute grammars,"So, I already gave you examples of this. So, I am the same thing is repeated here type"
26,Semantic consistency that cannot be handled at the parsing stage is handled here Type checking of various programming language constructs is one of the most important tasks Stores type information in the symbol table or the syntax tree Types of variables function parameters array dimensions etc Used not only for semantic validation but also for subsequent phases of compilation Static semantics of programming languages specified using attribute grammars,machine code generator needs to know the types of variables in order to generate appropriate
27,intofloat i Int Code Generator tHeid intofloat s Bette ides Code Optimizer,"code generation phase. So, the annotated syntax tree which is output from a semantic analyzer"
28,While generating machine code directly from source code is possible it entails two problems With m languages and n target machines we need to write mx ncompilers The code optimizer which is one of the largest and very dificut to write components of any compiler cannot be reused By converting source code to an intermediate code a machine independent code optimizer may be written Intermediate code must be easy to produce and easy to translate to machine code Asort of universal assembly language Should nat contain any machine specitc par registers addresses etc,"original source level program, but it is at a much lower level compared to the source"
29,While generating machine code directly from source code is possible it entails two problems With m languages and n target machines we need to write mx ncompilers The code optimizer which is one of the largest and very dificu to write components of any compiler cannot be reused By converting source code to an intermediate code a machine independent code optimizer may be written Intermediate code must be easy to produce and easy to translate to machine code A sort of universal assembly language Should not contain any machine specitic parameters registers addresses etc,"see whether it is C or C plus plus or 4 turn or Java, the intermediate code will be very"
30,The type of intermediate code deployed is based on the application Quadruples triples indirect triples abstract syntax trees are the classical forms used for machine independent optimizations and machine code generation Static Single Assignment form SSA is a recent form and enables more effective optimizations Conditional constant propagation and global value numbering are more effective on SSA Program Dependence Graph PDG is useful in automatic parallelization instruction scheduling and software pipelining,"instruction machine code generation. Finally, program dependence type of a graph is another"
31,t ia intottoat Benen ides Code Optimizer tid idt tt Code Generator,"necessary to retain the second statement which is T2 equal to into float 32. So, we might"
32,Intermediate code generation process introduces many inefficiencies Extra copies of variables using variables instead of constants repeated evaluation of expressions ee Code optimization removes such inefficiencies and improves code Improvement may be time space or power consumption It changes the structure of programs sometimes of beyond recognition Innes functions unroll loops eliminates some programmer defined variables et Code optimization consists of a bunch of heug id percentage of improvement depends on prog ay be zer also,The machine independent code optimization actually becomes necessary because intermediate code
33,imization Intermediate code generation process introduces many inefficiencies Extra copies of variables using variables instead of constants repeated evaluation of expressions etc Code optimization removes such inefficiencies and improves code Improvement may be time space or power consumption It changes the structure of programs sometimes of beyond recognition Inlines functions unrolls loops eliminates some programmer defined variables etc Code optimization consists f a bunch of heuristics and percentage of improvement depends on programs may be zero also,be just 0 you never know whether there would be improvement or not. But some programs
34,Common sub expression elimination Copy propagation Loop invariant code motion Partial redundancy elimination Induction variable elimination and strength reduction Code opimization needs information about the program which expressions are being recomputed in a function which definitions reach a point All such information is gathered through data fiow analysis,"So, there are different types of machine dependent optimizations. For example, commence"
35,xamples of Machine Independant Optimizations Common sub expression elimination Copy propagation Loop invariant code motion Partial redundancy elimination Induction variable limination and strength reduction Code opimization needs information about the program which expressions are being recomputed in a function which definitions reach a point All such information is gathered through data jg manalysis,"spectrum elimination, copy propagation, loop invariant code motion, partial redundancy"
36,Common sub expression elimination Copy propagation Loop invariant code motion Partial redundancy elimination Induction variable elimination and strength reduction Code opimization needs information about the program which expressions are being recomputed in a function which definitions reach a point All such information is gathered through data flow analysis,"the end of the course. Finally, the machine code generation. So, it takes intermediate"
37,Henne dt tt Code Generator LDF id MULF R ADOF R R STF id R,"the end of the course. Finally, the machine code generation. So, it takes intermediate"
38,Converts intermediate code to machine code Each intermediate code instruction may result in many machine instructions or vice cersa Must handle all aspects of machine architecture Registers pipelining cache multiple function units etc Generating efficient code is an NP complete problem Tree pattern matching based strategies are among the best Needs tree intermediate code Storage allocation decisions are made here Register allocation and assignment are the mggbignportant problems,code instructions actually give rise to only one single machine instruction. Depends on
39,jptimizations Peephole optimizations Analyze sequence of instructions in a small window peephole and using preset patterns replace them with a more efficient sequence Redundant instruction elimination eg replace the sequence LD A RII ST R A by LD ARI Eliminate jump to jump instructions Use machine idioms use INC instead of LD and ADD Instruction scheduling reordefing to eliminate pipeline interlocks and to increase parallelism Trace scheduling to increase the size of basic blocks and increase parallelism Software pipelining to increase parallelism in loops,"For example, there are water known as machine dependent optimizations. If you are listed"
\" target=\"_blank\">Download CSV file</a>"},"metadata":{}}]},{"cell_type":"code","source":"with open(, 'wb') as csvfile","metadata":{"execution":{"iopub.status.busy":"2023-11-02T15:24:27.116332Z","iopub.execute_input":"2023-11-02T15:24:27.116697Z","iopub.status.idle":"2023-11-02T15:24:27.121951Z","shell.execute_reply.started":"2023-11-02T15:24:27.116654Z","shell.execute_reply":"2023-11-02T15:24:27.120723Z"},"trusted":true},"execution_count":194,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\ndata=pd.DataFrame(columns=['Combined_Text'])\n# Assuming df is your DataFrame with 'Transcript' and 'Frame' columns\ndata['Combined_Text'] = text['Transcript'] + ' ' + text['Frame']\n","metadata":{"execution":{"iopub.status.busy":"2023-11-02T19:39:52.074021Z","iopub.execute_input":"2023-11-02T19:39:52.074457Z","iopub.status.idle":"2023-11-02T19:39:52.081874Z","shell.execute_reply.started":"2023-11-02T19:39:52.074422Z","shell.execute_reply":"2023-11-02T19:39:52.081172Z"},"trusted":true},"execution_count":285,"outputs":[]},{"cell_type":"code","source":"from transformers import BertTokenizer, BertModel\nimport torch\n\n# Load pre-trained BERT model and tokenizer\ntokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\nmodel = BertModel.from_pretrained('bert-base-uncased')\n\n# Encode the combined text\nencoded_text = tokenizer(data['Combined_Text'].tolist(), padding=True, truncation=True, return_tensors='pt')\n\n# Get BERT embeddings\nwith torch.no_grad():\n    outputs = model(**encoded_text)\n\n# Use the CLS token representation as the summary\nsummary_embeddings = outputs.last_hidden_state[:, 0, :]\n","metadata":{"execution":{"iopub.status.busy":"2023-11-02T19:40:07.740808Z","iopub.execute_input":"2023-11-02T19:40:07.741225Z","iopub.status.idle":"2023-11-02T19:40:42.145694Z","shell.execute_reply.started":"2023-11-02T19:40:07.741192Z","shell.execute_reply":"2023-11-02T19:40:42.144640Z"},"trusted":true},"execution_count":287,"outputs":[]},{"cell_type":"code","source":"# from sklearn.cluster import KMeans\n\n# # Cluster the embeddings\n# num_clusters = 3  # Choose the number of clusters\n# kmeans = KMeans(n_clusters=num_clusters, random_state=42)\n# cluster_labels = kmeans.fit_predict(summary_embeddings.numpy())\n\n# # Generate summaries for each cluster\n# summaries = {}\n# for cluster_id in range(num_clusters):\n#     cluster_indices = (cluster_labels == cluster_id)\n#     cluster_text = data.loc[cluster_indices, 'Combined_Text'].tolist()\n#     cluster_summary = \" \".join(cluster_text[:5])  # Choose the first 5 sentences as the summary\n#     summaries[cluster_id] = cluster_summary\n\n# # Print summaries for each cluster\n# for cluster_id, summary in summaries.items():\n#     print(f\"Cluster {cluster_id} Summary: {summary} Length : {len(summary)}\")\n","metadata":{"execution":{"iopub.status.busy":"2023-11-02T19:42:10.902832Z","iopub.execute_input":"2023-11-02T19:42:10.903241Z","iopub.status.idle":"2023-11-02T19:42:11.040428Z","shell.execute_reply.started":"2023-11-02T19:42:10.903199Z","shell.execute_reply":"2023-11-02T19:42:11.039229Z"},"trusted":true},"execution_count":289,"outputs":[{"name":"stdout","text":"Cluster 0 Summary: than interpretations. So, about the complexity of compiler technology it is also necessarycomplex system software and writing it is a substantial exercise in software engineering.large software engineering exercise. The complexity of a compiler really arises from thelarge software engineering exercise. The complexity of a compiler really arises from theactually travel a long distance it is not as if it is a very simple operation. So, thereactually travel a long distance it is not as if it is a very simple operation. So, thereis a huge amount of complexity here. So, we are going to discuss this particular complexityis a huge amount of complexity here. So, we are going to discuss this particular complexityas Yoc which do this. So, this enable in this enables tool building. So, tools take very About the Complexity of Compiler Technology A compiler is possibly the most complex system software and writing it is a substantial exercise in software engineering The complexity arises from the fact that its required to map a programmer s requirements in a HLL program to architectural details Ituses algorithms and techniques from a very large number of areas in computer science Translates intricate theory into practice enables tool building So, now let us look at the type of algorithms which are used inside a compiler and seeSo, now let us look at the type of algorithms which are used inside a compiler and seefrom mathematical logic lattice theory linear algebra probability etcetera. So, where arefrom mathematical logic lattice theory linear algebra probability etcetera. So, where arethese used? For example, mathematical logic is used to you know in developing type checking Draws results from mathematical logic lattice theory linear algebra probability etc type checking static analysis dependence analysis and loop parallelization cache analysis etc Makes practical application of Greedy algorithms register allocation Heuristic search ist scheduling Graph algorithms dead code elimination register allocation Dynamic programming instruction selection Optimization techniques instruction scheduling Finite automata lexical analysis Pushdown automata parsing Fixed point algorithms data low aralysis Complex data structures symbol tables par dependence graphs Computer architecture machine code gen these used? For example, mathematical logic is used to you know in developing type checkingDesign analysis is heavily based on linear algebra and group parallelization is basedon loop dependance analysis. So, cache analysis uses both static analysis and probability ie Nature of Compiler Algorithms Draws results from mathematical logic lattice theory linear algebra probability etc type checking static analysis dependence analysis and loop parallelization cache analysis etc Makes practical application of Greedy algorithms register allocation Heuristic search ist scheduling Graph algorithms dead code elimination register allocation Dynamic programming instruction selection Optimization techniques instruction scheduling Finite automata lexical analysis Pushdown automata parsing Fixed point algorithms data low analysis Complex data structures symbol tables pa dependence graphs Computer architecture machine code gene on loop dependance analysis. So, cache analysis uses both static analysis and probabilitytheory. So, in other words a very deep mathematical background is required to develop new compileralgorithms. In our course, we are going to study the existing compiler algorithms, butwe will also look at some of the you know the basis which actually make up this particularparsing, fixed point algorithms are used for data flow analysis, very complex data structures About the Nature of Compiler Algorithms Draws results from mathematical logic lattice theory linear algebra probability etc type checking static analysis dependence analysis and loop parallelization cache analysis etc Makes practical application of Greedy algorithms register allocation Heuristic search lst scheduling Graph algorithms dead code elimination register allocation Dynamic programming instruction selection Optimization techniques instruction scheduling Finite automata lexical analysis Pushdown automata parsing Fixed point algorithms data low analysis Complex data structures symbol tables par dependence graphs Computer architecture machine code gener you know performs scanning and parsing and another part of a compiler performs program analysis.So, program analysis techniques are useful in converting sequential programs to parallelprograms. And very important it can be used to determine if programs are data raise,programs. And very important it can be used to determine if programs are data raise,Profiling programs to determine busy regions of the code well if this is done then we canProfiling programs to determine busy regions of the code well if this is done then we canof a program. So, data flow analysis approach to software testing is again based on programof a program. So, data flow analysis approach to software testing is again based on programanalysis. If you look at a program it is very difficult to say what is the worst case Program Analysis Techniques Converting a sequential loop to a parallel loop Program analysis to determine it programs are data race free Profiling programs to determine busy regions Program slicing Data flow analysis approach to software testing Uncovering errors along all paths Dereferencing null pointers Butfer overflows and memory leaks Worst Case Execution Time WCET estimati energy analysis Length : 5562\nCluster 1 Summary: Welcome to this new course on Principles of Compiler Design. So, in this lecture I will Principles of Compiler Design Lecture An Overview of a compiler Y N SRIKANT Computer Science and Automation Indian Institute of Science Bangalore give you an overview of a compiler, but before that we will also see how exactly the course About the course Why should we study compiler design Compiler overview with block diagrams So, the course is actually a first level course. In other words, this takes a detail look at the going to take this course seriously are requested to do the programming assignments. this course will not be understood you know properly. The reason is a compiler is an excellent A detailed look at the internals of a compiler Does not assume any background but is intensive Doing programming assignments and solving theoretical problems are both essential A compiler is an excellent example of theory translated into practice in a remarkable way compiler technology some aspects of compiler technology. For example, scanning and parsing Parsing Techniques Assembler implementation Online text searching GREP AWK and word processing Website filtering Command language interpreters Scripting language interpretation Unix shell Perl Python XML parsing and document tree construction Database query interpreters So, that is about you know the motivation to study this subject called compiler design.So, let us begin with this block diagram which talks about a general language processing anguage Processing System source program ands mace modified source program Compiler A LANGUAGE PROCESSING target assembly program py Assembler relocatable machine code a library files inker Loader relocatable object fil target machine code Length : 1738\nCluster 2 Summary: So, if you look at the applications of modern compiler technology pick up the browser,homepage and that you are going to visit and so on. So, the HTML parsers are based on compilerhomepage and that you are going to visit and so on. So, the HTML parsers are based on compileron the modern compiler technology. Then of course, for the compiler itself we require machineon the modern compiler technology. Then of course, for the compiler itself we require machinewe need to use compiler technology anyway. But then apart from that it has uses in softwarewe need to use compiler technology anyway. But then apart from that it has uses in softwareengineering as well. For example, software testing and then program optimization then in theengineering as well. For example, software testing and then program optimization then in thesecurity domain malicious code detection design of new computer architectures. So, why aresecurity domain malicious code detection design of new computer architectures. So, why arethese important? For example, if you look at the development of a new processor nobody buildsthese important? For example, if you look at the development of a new processor nobody buildsa processor you know right away even if the design is 100 percent accurate and all that thea processor you know right away even if the design is 100 percent accurate and all that theperformance etcetera will all be known only after the hardware is built. Therefore, thereperformance etcetera will all be known only after the hardware is built. Therefore, thereis a simulator which is built for a new CPU and then people also build compiler for thatis a simulator which is built for a new CPU and then people also build compiler for thatwrite programs in C or C++ or any other language compile those programs and then run themwrite programs in C or C++ or any other language compile those programs and then run themin the hardware. So, that is called the compiler in the loop hardware development and it isin the hardware. So, that is called the compiler in the loop hardware development and it iscode for generating VLSI designs and so on and so forth that is called RTL registercode for generating VLSI designs and so on and so forth that is called RTL registertransfer logic. People really write it in very high description you know high level descriptiontransfer logic. People really write it in very high description you know high level descriptionSo, typically a compiler is used to generate a simulator and the simulator is actuallySo, typically a compiler is used to generate a simulator and the simulator is actuallya computer program which is generated for that particular program which is being simulated. Compilers are everywhere Many applications for compiler technology Parsers for HTML in web browser Interpreters for javascriptlash Machine code generation for high level languages Software testing Program optimization Malicious code detection Design of new computer architectures Compilerinthe loop hardware development Hardware synthesis VHDL to RTL translation Compiled simulation Used to simulate designs writen in VHOL No inlerpretaton of design hence faster So, we will learn about these specifications a little later, but right now it sufficesSo, we will learn about these specifications a little later, but right now it sufficesto say that the you know there are tools to do this. For example, the yawk and antler areto say that the you know there are tools to do this. For example, the yawk and antler aretwo such tools. So, they handle what are known as you know LALR1 grammars that is yawktwo such tools. So, they handle what are known as you know LALR1 grammars that is yawkand bison and antler handles what are known as LL1 grammars. They generate C programsand bison and antler handles what are known as LL1 grammars. They generate C programsor C plus plus programs which correspond to these parsers you know and they can be usedor C plus plus programs which correspond to these parsers you know and they can be usedby the compiler. So, as I already said parsers are based on pushdown automata. So, theyby the compiler. So, as I already said parsers are based on pushdown automata. So, theywe need the next phase of analysis called semantic analysis. The reason is parsers cannotwe need the next phase of analysis called semantic analysis. The reason is parsers cannotwe need the next phase of analysis called semantic analysis. The reason is parsers cannotof assignment this cannot be handled by a parser. So, there are theoretical limitationsof assignment this cannot be handled by a parser. So, there are theoretical limitationsis here you know parameter types and number match in declaration and use. So, we declare Parsing or Syntax analyzers parsers can be generated automatically from several variants of context free grammar specifications LL and LALR are the most popular ones ANTLR for LL YACC and Bison for LALR are such tools Parsers are deterministic push down automata Parsers cannot handle context sensitive features of programming languages g Variables are declared before use Types match on both sides of assignments Parameter types and number match in declar So, semantic consistency that cannot be handled at the parsing stage is handled here.So, I already gave you examples of this. So, I am the same thing is repeated here typeSo, I already gave you examples of this. So, I am the same thing is repeated here typechecking of various programming language constructs is one of the most important task. As semanticchecking of various programming language constructs is one of the most important task. As semanticWhat are the dimensions of an array etcetera? So, these are the information that are storedWhat are the dimensions of an array etcetera? So, these are the information that are storedin a symbol table by the semantic analyzer. This information is used not only for cachingin a symbol table by the semantic analyzer. This information is used not only for cachingerrors semantic validation as we know it, but it is also used for subsequent phases oferrors semantic validation as we know it, but it is also used for subsequent phases ofmachine code generator needs to know the types of variables in order to generate appropriate Semantic consistency that cannot be handled at the parsing stage is handled here Type checking of various programming language constructs is one of the most important tasks Stores type information in the symbol table or the syntax tree Types of variables function parameters array dimensions ete Used not only for semantic validation but also for subsequent phases of compilation Static semantics of programming languages can be specified using attribute grammars Length : 6739\n","output_type":"stream"}]},{"cell_type":"code","source":"# Cluster the embeddings (example with K-means)\nfrom sklearn.cluster import KMeans\n\nnum_clusters = 3  # Choose the number of clusters\nkmeans = KMeans(n_clusters=num_clusters, random_state=42)\ncluster_labels = kmeans.fit_predict(summary_embeddings.numpy())\n\n# Generate and limit summaries for each cluster\nmax_summary_length = 600  # Limit the summary to 50 tokens\n\nsummaries = {}\nfor cluster_id in range(num_clusters):\n    cluster_indices = (cluster_labels == cluster_id)\n    cluster_text = data.loc[cluster_indices, 'Combined_Text'].tolist()\n    cluster_summary = \" \".join(cluster_text[:5])  # Choose the first 5 sentences as the summary\n    # Truncate summary to max_summary_length tokens\n    summary_tokens = tokenizer.encode(cluster_summary, max_length=max_summary_length, truncation=True)\n    summaries[cluster_id] = tokenizer.decode(summary_tokens)\n\n# Print summaries for each cluster\nfor cluster_id, summary in summaries.items():\n    print(f\"Cluster {cluster_id} Summary: {summary}\")","metadata":{"execution":{"iopub.status.busy":"2023-11-02T19:47:37.142692Z","iopub.execute_input":"2023-11-02T19:47:37.143632Z","iopub.status.idle":"2023-11-02T19:47:37.528137Z","shell.execute_reply.started":"2023-11-02T19:47:37.143595Z","shell.execute_reply":"2023-11-02T19:47:37.527132Z"},"trusted":true},"execution_count":294,"outputs":[{"name":"stdout","text":"Cluster 0 Summary: [CLS] than interpretations. so, about the complexity of compiler technology it is also necessarycomplex system software and writing it is a substantial exercise in software engineering. large software engineering exercise. the complexity of a compiler really arises from thelarge software engineering exercise. the complexity of a compiler really arises from theactually travel a long distance it is not as if it is a very simple operation. so, thereactually travel a long distance it is not as if it is a very simple operation. so, thereis a huge amount of complexity here. so, we are going to discuss this particular complexityis a huge amount of complexity here. so, we are going to discuss this particular complexityas yoc which do this. so, this enable in this enables tool building. so, tools take very about the complexity of compiler technology a compiler is possibly the most complex system software and writing it is a substantial exercise in software engineering the complexity arises from the fact that its required to map a programmer s requirements in a hll program to architectural details ituses algorithms and techniques from a very large number of areas in computer science translates intricate theory into practice enables tool building so, now let us look at the type of algorithms which are used inside a compiler and seeso, now let us look at the type of algorithms which are used inside a compiler and seefrom mathematical logic lattice theory linear algebra probability etcetera. so, where arefrom mathematical logic lattice theory linear algebra probability etcetera. so, where arethese used? for example, mathematical logic is used to you know in developing type checking draws results from mathematical logic lattice theory linear algebra probability etc type checking static analysis dependence analysis and loop parallelization cache analysis etc makes practical application of greedy algorithms register allocation heuristic search ist scheduling graph algorithms dead code elimination register allocation dynamic programming instruction selection optimization techniques instruction scheduling finite automata lexical analysis pushdown automata parsing fixed point algorithms data low aralysis complex data structures symbol tables par dependence graphs computer architecture machine code gen these used? for example, mathematical logic is used to you know in developing type checkingdesign analysis is heavily based on linear algebra and group parallelization is basedon loop dependance analysis. so, cache analysis uses both static analysis and probability ie nature of compiler algorithms draws results from mathematical logic lattice theory linear algebra probability etc type checking static analysis dependence analysis and loop parallelization cache analysis etc makes practical application of greedy algorithms register allocation heuristic search ist scheduling graph algorithms dead code elimination register allocation dynamic programming instruction selection optimization techniques instruction scheduling finite automata lexical analysis pushdown automata parsing fixed point algorithms data low analysis complex data structures symbol tables pa dependence graphs computer architecture machine code gene on loop dependance analysis. so, cache analysis uses both static analysis and probabilitytheory. so, in other words a very deep mathematical background is required to develop new compileralgorithms. in our course, we are going to study the existing compiler algorithms, butwe [SEP]\nCluster 1 Summary: [CLS] welcome to this new course on principles of compiler design. so, in this lecture i will principles of compiler design lecture an overview of a compiler y n srikant computer science and automation indian institute of science bangalore give you an overview of a compiler, but before that we will also see how exactly the course about the course why should we study compiler design compiler overview with block diagrams so, the course is actually a first level course. in other words, this takes a detail look at the going to take this course seriously are requested to do the programming assignments. this course will not be understood you know properly. the reason is a compiler is an excellent a detailed look at the internals of a compiler does not assume any background but is intensive doing programming assignments and solving theoretical problems are both essential a compiler is an excellent example of theory translated into practice in a remarkable way compiler technology some aspects of compiler technology. for example, scanning and parsing parsing techniques assembler implementation online text searching grep awk and word processing website filtering command language interpreters scripting language interpretation unix shell perl python xml parsing and document tree construction database query interpreters so, that is about you know the motivation to study this subject called compiler design. so, let us begin with this block diagram which talks about a general language processing anguage processing system source program ands mace modified source program compiler a language processing target assembly program py assembler relocatable machine code a library files inker loader relocatable object fil target machine code [SEP]\nCluster 2 Summary: [CLS] so, if you look at the applications of modern compiler technology pick up the browser, homepage and that you are going to visit and so on. so, the html parsers are based on compilerhomepage and that you are going to visit and so on. so, the html parsers are based on compileron the modern compiler technology. then of course, for the compiler itself we require machineon the modern compiler technology. then of course, for the compiler itself we require machinewe need to use compiler technology anyway. but then apart from that it has uses in softwarewe need to use compiler technology anyway. but then apart from that it has uses in softwareengineering as well. for example, software testing and then program optimization then in theengineering as well. for example, software testing and then program optimization then in thesecurity domain malicious code detection design of new computer architectures. so, why aresecurity domain malicious code detection design of new computer architectures. so, why arethese important? for example, if you look at the development of a new processor nobody buildsthese important? for example, if you look at the development of a new processor nobody buildsa processor you know right away even if the design is 100 percent accurate and all that thea processor you know right away even if the design is 100 percent accurate and all that theperformance etcetera will all be known only after the hardware is built. therefore, thereperformance etcetera will all be known only after the hardware is built. therefore, thereis a simulator which is built for a new cpu and then people also build compiler for thatis a simulator which is built for a new cpu and then people also build compiler for thatwrite programs in c or c + + or any other language compile those programs and then run themwrite programs in c or c + + or any other language compile those programs and then run themin the hardware. so, that is called the compiler in the loop hardware development and it isin the hardware. so, that is called the compiler in the loop hardware development and it iscode for generating vlsi designs and so on and so forth that is called rtl registercode for generating vlsi designs and so on and so forth that is called rtl registertransfer logic. people really write it in very high description you know high level descriptiontransfer logic. people really write it in very high description you know high level descriptionso, typically a compiler is used to generate a simulator and the simulator is actuallyso, typically a compiler is used to generate a simulator and the simulator is actuallya computer program which is generated for that particular program which is being simulated. compilers are everywhere many applications for compiler technology parsers for html in web browser interpreters for javascriptlash machine code generation for high level languages software testing program optimization malicious code detection design of new computer architectures [SEP]\n","output_type":"stream"}]},{"cell_type":"code","source":"# Cluster the embeddings (example with K-means)\nfrom sklearn.cluster import KMeans\n\nnum_clusters = 3  # Choose the number of clusters\nkmeans = KMeans(n_clusters=num_clusters, random_state=42)\ncluster_labels = kmeans.fit_predict(summary_embeddings.numpy())\n\n# Generate summaries for each cluster\nsummaries = {}\nfor cluster_id in range(num_clusters):\n    cluster_indices = (cluster_labels == cluster_id)\n    cluster_text = data.loc[cluster_indices, 'Combined_Text'].tolist()\n    cluster_summary = \" \".join(cluster_text[:5])  # Choose the first 5 sentences as the summary\n    summaries[cluster_id] = cluster_summary\n\n# Calculate average summary length\naverage_summary_length = sum(len(summary.split()) for summary in summaries.values()) // num_clusters\n\n# Limit summaries for each cluster to the average length\nlimited_summaries = {}\nfor cluster_id, summary in summaries.items():\n    summary_tokens = tokenizer.encode(summary, max_length=average_summary_length, truncation=True)\n    limited_summaries[cluster_id] = tokenizer.decode(summary_tokens)\n\n# Print limited summaries for each cluster\nfor cluster_id, summary in limited_summaries.items():\n    print(f\"Cluster {cluster_id} Summary: {summary}\")","metadata":{"execution":{"iopub.status.busy":"2023-11-02T19:51:09.662140Z","iopub.execute_input":"2023-11-02T19:51:09.662552Z","iopub.status.idle":"2023-11-02T19:51:09.968482Z","shell.execute_reply.started":"2023-11-02T19:51:09.662522Z","shell.execute_reply":"2023-11-02T19:51:09.961716Z"},"trusted":true},"execution_count":296,"outputs":[{"name":"stdout","text":"Cluster 0 Summary: [CLS] than interpretations. so, about the complexity of compiler technology it is also necessarycomplex system software and writing it is a substantial exercise in software engineering. large software engineering exercise. the complexity of a compiler really arises from thelarge software engineering exercise. the complexity of a compiler really arises from theactually travel a long distance it is not as if it is a very simple operation. so, thereactually travel a long distance it is not as if it is a very simple operation. so, thereis a huge amount of complexity here. so, we are going to discuss this particular complexityis a huge amount of complexity here. so, we are going to discuss this particular complexityas yoc which do this. so, this enable in this enables tool building. so, tools take very about the complexity of compiler technology a compiler is possibly the most complex system software and writing it is a substantial exercise in software engineering the complexity arises from the fact that its required to map a programmer s requirements in a hll program to architectural details ituses algorithms and techniques from a very large number of areas in computer science translates intricate theory into practice enables tool building so, now let us look at the type of algorithms which are used inside a compiler and seeso, now let us look at the type of algorithms which are used inside a compiler and seefrom mathematical logic lattice theory linear algebra probability etcetera. so, where arefrom mathematical logic lattice theory linear algebra probability etcetera. so, where arethese used? for example, mathematical logic is used to you know in developing type checking draws results from mathematical logic lattice theory linear algebra probability etc type checking static analysis dependence analysis and loop parallelization cache analysis etc makes practical application of greedy algorithms register allocation heuristic search ist scheduling graph algorithms dead code elimination register allocation dynamic programming instruction selection optimization techniques instruction scheduling finite automata lexical analysis pushdown automata parsing fixed point algorithms data low aralysis complex data structures symbol tables par dependence graphs computer architecture machine code gen these used? for example, mathematical logic is used to you know in developing type checkingdesign analysis is heavily based on linear algebra and group parallelization is basedon loop dependance analysis. so, cache analysis uses both static analysis and probability ie nature of compiler algorithms draws results from mathematical logic lattice theory linear algebra probability etc type checking static analysis dependence analysis and loop parallelization cache analysis etc makes practical application of greedy algorithms register allocation heuristic search ist scheduling graph algorithms dead code elimination register allocation dynamic programming instruction selection optimization techniques instruction scheduling finite automata lexical analysis pushdown automata parsing fixed point algorithms data low analysis complex data structures symbol tables pa dependence graphs computer architecture machine code gene on loop dependance analysis. so, cache analysis uses both static analysis and probabilitytheory. so, in other words a very deep mathematical background is required to develop new compileralgorithms. in our course, we are going to study the existing compiler algorithms, butwe will also look at some of the you know the basis which actually make up this particularparsing, fixed point algorithms are used for data flow analysis, very complex data structures about the nature of compiler algorithms draws results from mathematical logic lattice theory linear algebra probability etc type checking static analysis dependence analysis and loop parallelization cache analysis etc makes practical application of greedy algorithms register allocation heuristic search lst scheduling graph algorithms dead code elimination register allocation dynamic programming instruction selection optimization techniques instruction scheduling finite automata lexical analysis pushdown automata parsing fixed point algorithms data low analysis complex data structures symbol tables par dependence graphs computer architecture machine code gene [SEP]\nCluster 1 Summary: [CLS] welcome to this new course on principles of compiler design. so, in this lecture i will principles of compiler design lecture an overview of a compiler y n srikant computer science and automation indian institute of science bangalore give you an overview of a compiler, but before that we will also see how exactly the course about the course why should we study compiler design compiler overview with block diagrams so, the course is actually a first level course. in other words, this takes a detail look at the going to take this course seriously are requested to do the programming assignments. this course will not be understood you know properly. the reason is a compiler is an excellent a detailed look at the internals of a compiler does not assume any background but is intensive doing programming assignments and solving theoretical problems are both essential a compiler is an excellent example of theory translated into practice in a remarkable way compiler technology some aspects of compiler technology. for example, scanning and parsing parsing techniques assembler implementation online text searching grep awk and word processing website filtering command language interpreters scripting language interpretation unix shell perl python xml parsing and document tree construction database query interpreters so, that is about you know the motivation to study this subject called compiler design. so, let us begin with this block diagram which talks about a general language processing anguage processing system source program ands mace modified source program compiler a language processing target assembly program py assembler relocatable machine code a library files inker loader relocatable object fil target machine code [SEP]\nCluster 2 Summary: [CLS] so, if you look at the applications of modern compiler technology pick up the browser, homepage and that you are going to visit and so on. so, the html parsers are based on compilerhomepage and that you are going to visit and so on. so, the html parsers are based on compileron the modern compiler technology. then of course, for the compiler itself we require machineon the modern compiler technology. then of course, for the compiler itself we require machinewe need to use compiler technology anyway. but then apart from that it has uses in softwarewe need to use compiler technology anyway. but then apart from that it has uses in softwareengineering as well. for example, software testing and then program optimization then in theengineering as well. for example, software testing and then program optimization then in thesecurity domain malicious code detection design of new computer architectures. so, why aresecurity domain malicious code detection design of new computer architectures. so, why arethese important? for example, if you look at the development of a new processor nobody buildsthese important? for example, if you look at the development of a new processor nobody buildsa processor you know right away even if the design is 100 percent accurate and all that thea processor you know right away even if the design is 100 percent accurate and all that theperformance etcetera will all be known only after the hardware is built. therefore, thereperformance etcetera will all be known only after the hardware is built. therefore, thereis a simulator which is built for a new cpu and then people also build compiler for thatis a simulator which is built for a new cpu and then people also build compiler for thatwrite programs in c or c + + or any other language compile those programs and then run themwrite programs in c or c + + or any other language compile those programs and then run themin the hardware. so, that is called the compiler in the loop hardware development and it isin the hardware. so, that is called the compiler in the loop hardware development and it iscode for generating vlsi designs and so on and so forth that is called rtl registercode for generating vlsi designs and so on and so forth that is called rtl registertransfer logic. people really write it in very high description you know high level descriptiontransfer logic. people really write it in very high description you know high level descriptionso, typically a compiler is used to generate a simulator and the simulator is actuallyso, typically a compiler is used to generate a simulator and the simulator is actuallya computer program which is generated for that particular program which is being simulated. compilers are everywhere many applications for compiler technology parsers for html in web browser interpreters for javascriptlash machine code generation for high level languages software testing program optimization malicious code detection design of new computer architectures compilerinthe loop hardware development hardware synthesis vhdl to rtl translation compiled simulation used to simulate designs writen in vhol no inlerpretaton of design hence faster so, we will learn about these specifications a little later, but right now it sufficesso, we will learn about these specifications a little later, but right now it sufficesto say that the you know there are tools to do this. for example, the yawk and antler areto say that the you know there are tools to do this. for example, the yawk and antler aretwo such tools. [SEP]\n","output_type":"stream"}]},{"cell_type":"code","source":"# G = nx.Graph()\n\n# for row in len(df1):\n#     transcript = text[row]['Transcript']\n#     frame_content =text[row]['Frame']\n    \n#     # Perform NER, POS tagging, and Dependency Parsing\n#     transcript_doc = nlp(transcript)\n#     frame_doc = nlp(frame_content)\n\n#     # Extract entities and relationships from the transcripts and frame content\n#     # Add entities and relationships to the graph\n#     # ...\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# source_entity = \"source_entity\"\n# target_entity = \"target_entity\"\n# shortest_path = nx.shortest_path(G, source=source_entity, target=target_entity)\n\n# print(\"Shortest Path between\", source_entity, \"and\", target_entity, \":\", shortest_path)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}